{"meta":{"title":"Sam的个人博客","subtitle":"一个程序员的成长记录","description":"一个程序员的成长记录","author":"Sam","url":"https://blog.ydstudio.net","root":"/"},"pages":[{"title":"","date":"2019-12-16T07:19:54.000Z","updated":"2020-03-10T09:10:07.000Z","comments":true,"path":"about/index.html","permalink":"https://blog.ydstudio.net/about/index.html","excerpt":"","text":"我的个人信息 学历专业：本科 / 滁州学院 计算机科学与技术专业 英语水平：CET-4 其他证书：全国计算机等级考试四级网络工程师 个人优势： 15年正式参加工作，主要涉及食品和旅游电商业务。熟悉支付宝、微信支付。熟悉常见数据库建模工具，了解阿里云相关产品，熟悉Linux操作，熟悉MySQL以及Redis。熟悉Spring Boot以及Spring Cloud 的微服务体系，了解Dubbo。熟悉Elastic Search搜索引擎，熟悉Svn、Git，对SEO也有了解。 技能清单以下均为我熟练使用的技能 Web开发：Spring Boot、Yii2 数据库相关：MySQL NoSQL: Redis 版本管理：Svn/Git 服务器相关：Linux/Apache/Nginx/Tomcat 搜索引擎：Elastic Search 消息队列： RabbitMQ 工作经历南京达而美国际旅游社有限公司（2016年4月~2019年3月）数据中心 (2018/03-2019/03)&#8195;旅游电商平台，业务类似马蜂窝。采用Spring Boot+Mybatis+Redis的Spring Cloud技术栈。我主要在其中负责全部功能的数据库设计，并负责搜索引擎的评估，最终选择Elastic Search实现产品的检索等功能。数据中心提供数据，进行数据输出。利用数据中心输出的数据，完成天行假期产品列表展示、产品的搜索和产品的筛选验证等功能。 同时负责利用数据中心输出的数据完成海德地接的订单中心，使用SnowFlake算法生成订单ID，并对接之前的支付中心实现订单支付，打通整个流程。 达美支付中心(2018/01-2018/03)&#8195;基于Spring Boot+Mybatis+Redis的Spring Cloud微服务项目，目前整合支付宝和微信两种支付方式，完成支付宝和 微信的支付、退款、财务对账等功能。支付全部对接支付中心，第三方支付平台完成支付，回调通知支付中心，支付中心将通知整合处理进入消息队列，然后支付中心通知调用应用支付完成。 主要负责部分数据库的设计，并完成支付宝相应接口的实现，之后维护支付中心，并重构微信支付相关功能。 达美教育 (2017/11-2018/01)&#8195;基于新达美网开发达美教育站，前端使用Node.js，后端使用Spring Boot框架+Jpa，部署时使用Nginx反向代理Node.js。项目主要功绩就是学会使用Spring Boot框架。 新达美网（2017/06-2017/11）&#8195;老达美网越来越不能满足业务部的需求，重构达美网。项目基于LNMP架构，采用Yii2框架，Redis做缓存，Elastic Search做搜索，手机端采用Vue。我在其中负责部分资源中心、整站促销工具（促销和优惠券）、购物车、订单、库存管理等功能，以及以上功能的数据库设计，并参与其他功能的数据库设计，还负责Redis主从复制架构的搭建。 最终项目完成获得业务部门的一致好评，因此部门获得2017年度的优秀部门奖。 达美旅行网（2016/04-2017/06）&#8195;负责网站bug修复，新功能的开发。例如个性定制模块手机版、网站支付宝、微信等支付的整改等。 由于负责开发的个性定制模块受到了公司业务部门的一致认可，因此获得2016年度的最佳员工的奖励。 btsearch365&#8195;本项目是LNMP架构的个人小项目，基于Yii2框架。使用Python编写爬虫采集数据，数据通过Elastic Search完成检索，实现数据的入库、查询、聚合等功能，后续在学习Spring Cloud和Dubbo的时候，分别重写这个项目，对Spring Cloud和Dubbo有了一定的认识。 南京雅趣网络科技有限公司（2014年11月 ~2016年4月）供销管理系统（2015/09-2016/04）&#8195;本项目是LAMP架构，基于ZendFramework1框架、Smarty模板。这是公司内部的一个库存ERP系统，主要就是供公司内部人员使用。功能主要包括商品的采购、退货、收货、发货和相应的商品销售的统计等功能。我主要负责修改业务反馈的bug、业务提出新功能的开发和基础功能测试。 乐药网项目 (2015/01-2015/09)&#8195;本项目是LAMP架构，前端使用Bootstrap后端使用ThinkPHP框架，项目是个关于医药招聘网站。中有简历的创建编辑，Pdf和Word格式的简历导出和公司端简历打包下载功能。我负责项目结构的搭建，数据库的设计，绝大数功能的实现和相应功能的基础测试。开发过程中遇到不少困难，在同事帮组和自己的努力下解决了。让我对项目架构搭建、数据库设计和Linux都有了一定的了解。 个人爱好 爱看电影 喜爱美食 喜欢阅读历史方面的书籍"},{"title":"友情链接","date":"2020-01-11T17:54:54.000Z","updated":"2020-01-11T10:25:22.000Z","comments":true,"path":"links/index.html","permalink":"https://blog.ydstudio.net/links/index.html","excerpt":"","text":"heyangli.com 排名不分先后，欢迎访问(～￣▽￣)～ 友链申请要求： 博客可以被稳定访问，原则上只与原创技术类博客进行友链互换 页面无繁杂广告推广"}],"posts":[{"title":"利用Mac电脑自带应用将iPhone投屏到Mac电脑的教程","slug":"利用Mac电脑自带应用将iPhone投屏到Mac电脑的教程","date":"2020-03-10T12:40:32.000Z","updated":"2020-03-10T07:01:03.000Z","comments":true,"path":"post/29afd8a9.html","link":"","permalink":"https://blog.ydstudio.net/post/29afd8a9.html","excerpt":"你只需要准备一根USB数据线，也就是手机的充电线即可，最好是原装的USB线。","text":"你只需要准备一根USB数据线，也就是手机的充电线即可，最好是原装的USB线。 手机通过USB线连接电脑如果手机是第一次插上这台电脑可能会弹出信任等弹框，手机端点击【信任】，电脑端点击【继续】。总的来说，就是允许电脑访问手机。 打开Mac 系统自带的播放器QuickTime Player直接command + 空格键 调出SpotLight 搜索 “QuickTime”，即可调出QuickTime Player播放器。 菜单栏【文件】–&gt;【新建影片录制】打开【QuickTime Player】后，在左上角的菜单栏中【文件】菜单，找到第一项【新建影片录制】。 更改摄像头选项，选中手机即可。点击【新建影片录制】后，此时默认是打开的电脑自带的摄像头，此时可以更新摄像头的来源和麦克风来源。推荐相机选择iPhone的，麦克风选择内置麦克风。","categories":[],"tags":[{"name":"MAC","slug":"MAC","permalink":"https://blog.ydstudio.net/tags/MAC/"},{"name":"iPhone","slug":"iPhone","permalink":"https://blog.ydstudio.net/tags/iPhone/"},{"name":"投屏","slug":"投屏","permalink":"https://blog.ydstudio.net/tags/%E6%8A%95%E5%B1%8F/"}]},{"title":"JVM配置参数的类型","slug":"JVM配置参数的类型","date":"2020-02-06T15:55:13.000Z","updated":"2020-02-06T07:57:04.000Z","comments":true,"path":"post/ea8be9c5.html","link":"","permalink":"https://blog.ydstudio.net/post/ea8be9c5.html","excerpt":"参数名称的说明JVM配置参数分别用于跟踪监控JVM状态，分配堆内存以及分配栈内存。按照类型分为三类标准参数、非标准参数和非稳定参数","text":"参数名称的说明JVM配置参数分别用于跟踪监控JVM状态，分配堆内存以及分配栈内存。按照类型分为三类标准参数、非标准参数和非稳定参数 标准参数(-)所有 JVM 都必须支持这些参数的功能, 而且向后兼容, 如: -client : 设置 JVM 使用 client 模式, 特点是启动速度比较快, 但运行时性能和内存管理效率不高. 通常用于客户端应用程序或开发调试; 在32位环境下直接运行 Java 程序默认启用该模式. -server : 设置 JVM 使 server 模式, 特点是启动速度比较慢, 但运行时性能和内存管理效率很高, 适用于生产环境; 在具有64位能力的JDK环境下默认启用该模式. 123456Sam-Mac:hexo-blog Sam$ java -versionjava version \"1.8.0_74\"Java(TM) SE Runtime Environment (build 1.8.0_74-b02)Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode)Sam-Mac:hexo-blog Sam$ 非标准参数(-X)各 JVM 厂商应该都实现这些参数的功能, 但是并不保证所有的 JVM 实现都满足, 且不保证向后兼容。这些用的不多，看看就好。 12345678// 解释执行-Xint// 第一次使用就编译成本地代码-Xcomp// 混合模式-Xmixed 非稳定参数(-XX)此类参数各个JVM实现会有所不同, 将来可能会不被支持, 需要慎重使用。这种类型的参数自己又可分为两种，分别如下： 布尔类型。 -XX:+ 或者 - 某个属性值，+ 表示开启，-表示关闭。例如： 12345// 打印GC详细信息-XX:+PrintGCDetails// 不打印GC详细信息-XX:-PrintGCDetails KV类型。-XX:属性key=属性值value，例如： 12// 设置Metaspace的大小-XX:MetaspaceSize=1024m 注意: 在”-XX:”后的参数若不需要赋值, 即只是用来配置开启或关闭相应选项, 则需要有 “+” (开启) 或 “-“ (禁止) , 否则应用程序将在日志文件 (如 Tomcat 的日志文件 catalina.out ) 中抛出如下错误: 123Missing +/- setting for VM option 'UseConcMarkSweepGC'. Error: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit. 可以看出, 这里缺少了 “+/-“ 符号, 导致虚拟机启动异常, 修改后即可正常启动. 我们常设置的JVM参数Xms和Xmx,属于哪种类型的JVM参数？-Xms等价于-XX:InitialHeapSize,-Xmx等价于-XX:MaxHeapSize，所以他们都是XX类型参数。","categories":[],"tags":[{"name":"Jvm","slug":"Jvm","permalink":"https://blog.ydstudio.net/tags/Jvm/"}]},{"title":"Spring配置文件中的classpath:和classpath*:的区别","slug":"Spring配置文件中的classpath-和classpath-的区别","date":"2020-01-28T22:46:48.000Z","updated":"2020-01-28T14:53:41.000Z","comments":true,"path":"post/38b6491c.html","link":"","permalink":"https://blog.ydstudio.net/post/38b6491c.html","excerpt":"classpath是spring的写法，classpath是指WEB-INF文件夹下的classes目录，对应源代码src目录，用于存放从src中拷贝过去的各种配置文件，以及编译过后的class文件。Spring可以通过指定classpath*:与classpath:前缀加上路径的方式从classpath加载配置文件。","text":"classpath是spring的写法，classpath是指WEB-INF文件夹下的classes目录，对应源代码src目录，用于存放从src中拷贝过去的各种配置文件，以及编译过后的class文件。Spring可以通过指定classpath*:与classpath:前缀加上路径的方式从classpath加载配置文件。 classpath: 的具体含义classpath:表示从类路径中加载资源，classpath:和classpath:/是等价的，都是相对于类的根路径。资源文件库标准的在文件系统中，也可以在JAR或ZIP的类包中。 classpath*: 的具体含义classpath*:：假设多个JAR包或文件系统类路径都有一个相同的配置文件，classpath:只会在第一个加载的类路径下查找，而classpath:会扫描所有这些JAR包及类路径下出现的同名文件。 具体例子如下 classpath:applicationContext.xml，匹配classpath下的指定文件 classpath:/spring/applicationContext.xml，匹配classpath子目录下的指定文件 classpath:spring-*.xml，匹配classpath下的指定前缀的文件 classpath:*/spring-.xml，匹配classpath下所有目录下的指定前缀的文件 classpath:**/spring-.xml，匹配当前classpath和jar中classpath下所有目录下的指定前缀的文件","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"https://blog.ydstudio.net/tags/spring/"}]},{"title":"利用Docker Compose管理服务","slug":"利用Docker-Compose管理服务","date":"2020-01-14T22:17:18.000Z","updated":"2020-01-14T14:57:32.000Z","comments":true,"path":"post/a5d4c4d4.html","link":"","permalink":"https://blog.ydstudio.net/post/a5d4c4d4.html","excerpt":"docker-compose 简介Compose是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YML文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。","text":"docker-compose 简介Compose是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YML文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 docker-compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 执行 docker-compose up 命令来启动并运行整个应用程序。 docker-compose 安装123#以centos为例yum install -y docker-compose 使用docker-compose编排一个jdk8、tomcat7、mysql5.7和redis3.2的实例准备的材料和目录结构如下： ├── docker-compose.yml└── tomcat7 ├── apache-tomcat-7.0.99.zip ├── Dockerfile ├── jdk-8u131-linux-x64.tar.gz └── my.cnf #挂在到容器的目录├── mysql│ ├── conf│ │ └── my.cnf│ ├── data│ ├── init│ │ ├── init.sh│ │ └── mysql_init.sql│ └── log└── tomcat7 ├── conf │ ├── Catalina │ │ └── localhost │ ├── catalina.policy │ ├── catalina.properties │ ├── context.xml │ ├── logging.properties │ ├── server.xml │ ├── tomcat-users.xml │ ├── tomcat-users.xsd │ └── web.xml ├── data ├── logs └── webapps docker-compose.yml 的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: \"3\"services: samjavawebenv: container_name: javawebenv build: context: ./tomcat7/ dockerfile: Dockerfile image: compose-javawebenv:v1 depends_on: - mysql links: - mysql - redis ports: - \"80:80\" - \"443:443\" - \"8080:8080\" privileged: true environment: - Dspring.profiles.active=prod restart: always volumes: - \"../../docker-compose/tomcat7/conf:/usr/local/tomcat7/conf\" - \"../../docker-compose/tomcat7/data:/usr/local/tomcat7/data\" - \"../../docker-compose/tomcat7/logs:/usr/local/tomcat7/logs\" - \"../../docker-compose/tomcat7/webapps:/usr/local/tomcat7/webapps\" mysql: container_name: mysql5.7 environment: MYSQL_ROOT_HOST: \"%\" MYSQL_HOST: \"localhost\" MYSQL_ROOT_PASSWORD: \"xxxx\" image: \"mysql:5.7\" ports: - \"3306:3306\" restart: always volumes: - \"../../docker-compose/mysql/data:/var/lib/mysql\" - \"../../docker-compose/mysql/conf:/etc/mysql/conf.d\" - \"../../docker-compose/mysql/init:/docker-entrypoint-initdb.d\" command: --default-authentication-plugin=mysql_native_password redis: container_name: redis3.2 image: \"redis:3.2\" ports: - \"6380:6379\" restart: always command: \"redis-server --appendonly yes\" init.sh中的内容 123#!/bin/bashmysql -uroot -pxxx &lt;&lt; EOFsource /docker-entrypoint-initdb.d/mysql_init.sql; mysql_init.sql中的内容 123456789101112use mysql;update user set authentication_string=password('xxxx') where user='root' and host='localhost'; INSERT INTO `mysql`.`user` (`Host`, `User`, `Select_priv`, `Insert_priv`, `Update_priv`, `Delete_priv`, `Create_priv`, `Drop_priv`, `Reload_priv`, `Shutdown_priv`, `Process_priv`, `File_priv`, `Grant_priv`, `References_priv`, `Index_priv`, `Alter_priv`, `Show_db_priv`, `Super_priv`, `Create_tmp_table_priv`, `Lock_tables_priv`, `Execute_priv`, `Repl_slave_priv`, `Repl_client_priv`, `Create_view_priv`, `Show_view_priv`, `Create_routine_priv`, `Alter_routine_priv`, `Create_user_priv`, `Event_priv`, `Trigger_priv`, `Create_tablespace_priv`, `ssl_type`, `ssl_cipher`, `x509_issuer`, `x509_subject`, `max_questions`, `max_updates`, `max_connections`, `max_user_connections`, `plugin`, `authentication_string`, `password_expired`, `password_last_changed`, `password_lifetime`, `account_locked`) VALUES ('%', 'xx', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', '', '', '', '', '0', '0', '0', '0', 'mysql_native_password', password('xxx'), 'N', '2020-01-09 11:41:17', NULL, 'N');flush privileges; 容器间访问mysql和redis的链接地址要修改 1234# 把主机地址换成service的名字jbdc.url=jdbc:mysql://mysql:3306/flash_sale?useUnicode=true&amp;characterEncoding=utf-8#mysql的用户主机为 javawebenv.compose_default 即 container_name + compose_default docker-compose 命令1234567891011121314#构建docker-compose build# 启动docker-compose up#如果你想在后台执行该服务可以加上 -d 参数docker-compose up -d#关闭docker-compose stop#删除docker-compose rm 以上的docker-compose命令都是在 docker-compose.yml 文件目录下执行","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.ydstudio.net/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://blog.ydstudio.net/tags/docker-compose/"}]},{"title":"我常用的docker基本命令","slug":"我常用的docker基本命令","date":"2020-01-13T22:00:51.000Z","updated":"2020-01-14T14:45:55.000Z","comments":true,"path":"post/c9b0a620.html","link":"","permalink":"https://blog.ydstudio.net/post/c9b0a620.html","excerpt":"docker 客户端非常简单 ,我们可以直接输入 docker 命令来查看到 Docker 客户端的所有命令选项。可以通过命令 docker command –help 更深入的了解指定的 Docker 命令使用方法。例如我们要查看 docker stats 指令的具体使用方法： 1docker stats --help","text":"docker 客户端非常简单 ,我们可以直接输入 docker 命令来查看到 Docker 客户端的所有命令选项。可以通过命令 docker command –help 更深入的了解指定的 Docker 命令使用方法。例如我们要查看 docker stats 指令的具体使用方法： 1docker stats --help docker查找镜像1234567# 查询镜像docker search 镜像名称#docker查找官方原版镜像docker search --filter \"is-official=true\" centos#或者docker search -f is-official=true centos docker 安装镜像12345678#命令语法docker pull 镜像名称:标签#安装 tomcat8 docker pull tomcat:8#安装 mysql5.7 docker pull mysql:5.7 删除images123456789#若删除不掉，说明有容器正在使用此 imagesdocker rmi imgId#先执行 docker rm containerId#再执行 docker rmi imgId 启动容器以下命令使用 ubuntu 镜像启动一个容器，参数为以命令行模式进入该容器： 1234567891011#命令语法docker run &lt;相关参数&gt; &lt;镜像 ID&gt; &lt;初始命令&gt; docker run -itd --name 自定义容器名称 镜像名称:标签 shell#运行tomcat8 docker run -p 8080:8080 --name mytomcat tomcat:8#运行ubuntu镜像docker run -itd ubuntu /bin/bash 参数说明： -i: 交互式操作。 -t: 终端。 -d：指定容器的运行模式为后台运行。 -P:是容器内部端口随机映射到主机的高端口。 -p: 是容器内部端口绑定到指定的主机端口。 –name: 标识来命名容器。 ubuntu: ubuntu 镜像。 /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。 -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; 需要说明的是，不一定要使用“镜像 ID”，也可以使用“仓库名:标签名”，例如：centos:latest。初始命令表示一旦容器启动，需要运行的命令，此时使用“/bin/bash”，表示什么也不做，只需进入命令行即可。 123456docker run -d --name mysql5.7 -p 3306:3306 -v /usr/local/mysql/data:/var/lib/mysql -v /usr/local/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7.25#将windows下F盘的目录javaResource挂载到docker中centos中的/usr/local/src下，docker中可以先设置分享盘符docker run -it --privileged=true -v /F/javaResource/:/usr/local/src/ 5e35e350aded /bin/bash 要退出终端，直接输入 exit:通过 docker inspect 命令，我们可以获取镜像的详细信息，其中，包括创建者，各层的数字摘要等。123456docker inspect repository:tagdocker inspect mysql:5.7docker inspect 返回的是 JSON 格式的信息，如果您想获取其中指定的一项内容，可以通过 -f 来指定，如获取镜像大小：docker inspect -f &#123;&#123;\".Size\"&#125;&#125; mysql:5.7 容器其他命令1234567891011121314#查看正在运行的容器docker ps#查看所有的容器docker ps -a#停止容器docker stop containerId#启动容器docker start containerId#重启容器docker restart containerId 进入容器在使用 -d 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入： docker attach docker exec：推荐大家使用 docker exec 命令，因为此退出容器终端，不会导致容器的停止。 1docker exec -it mytomcat bash #在这里用到了上面提到的容器别名mytomcat 什么是 DockerfileDockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 FROM 和 RUN 指令的作用 FROM：定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 RUN：用于执行后面跟着的命令行命令。有以下俩种格式： 12345678#shell格式RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。#exec 格式RUN [\"可执行文件\", \"参数1\", \"参数2\"]# 例如：# RUN [\"./test.php\", \"dev\", \"offline\"] 等价于 RUN ./test.php dev offline 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 1234FROM centosRUN yum install wgetRUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\"RUN tar -xvf redis.tar.gz 以上执行会创建 3 层镜像。可简化为以下格式： 1234FROM centosRUN yum install wget \\ &amp;&amp; wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\ &amp;&amp; tar -xvf redis.tar.gz 如上，以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 tomcat和jdk整合的镜像:v1（镜像名称:镜像标签）注：最后的 . 代表本次执行的上下文路径，下一节会介绍。 构建镜像命令123456#命令语法 docker build -t name:tag .-t 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。# 例如docker build -t javawebenv:v1 . Dockerfile内容1234567891011121314151617181920212223FROM centos:7 #使用centos7最新的官方镜像MAINTAINER samdockerdeveloperRUN mkdir -p /usr/local/tomcat7 \\&amp;&amp;mkdir -p /usr/local/jdk8WORKDIR /usr/local/src/ #使用该目录作为工作目录COPY apache-tomcat-7.0.99.zip /usr/local/src/COPY jdk-8u131-linux-x64.tar.gz /usr/local/src/COPY my.cnf /usr/local/src/RUN yum update -y \\&amp;&amp;yum install -y unzip \\&amp;&amp;unzip apache-tomcat-7.0.99.zip \\&amp;&amp;rpm --import /etc/pki/rpm-gpg/RPM* \\&amp;&amp;cp -R apache-tomcat-7.0.99/* /usr/local/tomcat7 \\&amp;&amp;chmod +x /usr/local/tomcat7/bin/*.sh \\&amp;&amp;tar -xf jdk-8u131-linux-x64.tar.gz -C /usr/local/jdk8 --strip-components 1 # 放弃上级目录解压到/usr/local/jdk8目录下ENV JAVA_HOME /usr/local/jdk8ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/tomcat7ENV CATALINA_BASE /usr/local/tomcat7ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080 #暴露8080端口ENTRYPOINT [\"/usr/local/tomcat7/bin/catalina.sh\",\"run\"] 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker引擎是S。实际的构建过程是在docker引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 使用的过程中遇到的问题123456789101112Docker报错“Dockerfile parse error line 1: FROM requires either one or three arguments” 看官方文档Format：以'#' 开头一行被视为评论，出现在其他位置视为参数,也就不难理解报错原因：将写在同一行的注释视为参数了。Failed to get D-Bus connection: Operation not permitted /etc/init.d/mysqld:启动命令 docker run -d -p 8080:8080 -v /root/webapps:/usr/local/tomcat7/webapps --name mycentos mycentos:7 /bin/bash以特权模式运行容器启动命令改成 docker run -d -p 8080:8080 -v /root/webapps:/usr/local/tomcat7/webapps --name mycentos mycentos:7 /usr/sbin/init/etc/sysconfig/network 文件夹不存在编辑/etc/init.d/mysqld 中的 . /etc/sysconfig/network修改成/etc/sysconfig/network-scripts/ifcfg-lo或者用软连接 ln -s /etc/sysconfig/network-scripts/ifcfg-lo /etc/sysconfig/network","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.ydstudio.net/tags/docker/"}]},{"title":"以centos7镜像为基础构建一个jdk8和tomcat7的镜像","slug":"以centos7镜像为基础构建一个jdk8和tomcat7的镜像","date":"2020-01-04T23:22:55.000Z","updated":"2020-01-05T03:14:41.000Z","comments":true,"path":"post/97b746d3.html","link":"","permalink":"https://blog.ydstudio.net/post/97b746d3.html","excerpt":"首先我简单说一下容器的一些知识点 一个容器只跑一个进程，并且该进程只能前台运行。 容器有层的概念，如果需要定制容器，应该尽量通过Dockerfile来构建容器。","text":"首先我简单说一下容器的一些知识点 一个容器只跑一个进程，并且该进程只能前台运行。 容器有层的概念，如果需要定制容器，应该尽量通过Dockerfile来构建容器。 什么是 Dockerfile Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 1234567891011121314151617181920FROM centos:7 MAINTAINER samdockerdeveloperRUN mkdir -p /usr/local/tomcat7 \\&amp;&amp;mkdir -p /usr/local/jdk8WORKDIR /usr/local/src/COPY apache-tomcat-7.0.99.zip /usr/local/src/COPY jdk-8u131-linux-x64.tar.gz /usr/local/src/RUN yum update -y \\&amp;&amp;yum install -y unzip \\&amp;&amp;unzip apache-tomcat-7.0.99.zip \\&amp;&amp;cp -R apache-tomcat-7.0.99/* /usr/local/tomcat7 \\&amp;&amp;chmod +x /usr/local/tomcat7/bin/*.sh \\&amp;&amp;tar -xf jdk-8u131-linux-x64.tar.gz -C /usr/local/jdk8 --strip-components 1ENV JAVA_HOME /usr/local/jdk8 \\ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar \\ENV CATALINA_HOME /usr/local/tomcat7 \\ENV CATALINA_BASE /usr/local/tomcat7 \\ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080ENTRYPOINT [\"/usr/local/tomcat7/bin/catalina.sh\",\"run\"] 在Dockerfile同级目录里存放已经下载好的apache-tomcat-7.0.99.zip、jdk-8u131-linux-x64.tar.gz。 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 123456789FROM centosRUN yum install wgetRUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\"RUN tar -xvf redis.tar.gz以上执行会创建 3 层镜像。可简化为以下格式：FROM centosRUN yum install wget \\ &amp;&amp; wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\ &amp;&amp; tar -xvf redis.tar.gz 如上，以 &amp;&amp; 符号连接命令，这样执行后，只会创建 1 层镜像。 开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 samjavawebenv:v2（镜像名称:镜像标签）。 注：最后的 . 代表本次执行的上下文路径 12# docker build -t name:tag .docker build -t samjavawebenv:v2 .","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"docker","slug":"docker","permalink":"https://blog.ydstudio.net/tags/docker/"}]},{"title":"SpringMvc使用@Async注解实现有返回值和无返回值的异步处理","slug":"SpringMvc使用-Async注解实现有返回值和无返回值的异步处理","date":"2020-01-03T23:12:21.000Z","updated":"2020-01-11T13:01:38.000Z","comments":true,"path":"post/e7e78673.html","link":"","permalink":"https://blog.ydstudio.net/post/e7e78673.html","excerpt":"SpringMvc使用@Async注解实现有返回值和无返回值的异步处理 异步调用对应的是同步调用，同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。","text":"SpringMvc使用@Async注解实现有返回值和无返回值的异步处理 异步调用对应的是同步调用，同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。 同步方式调用代码 相关代码 12345678910111213141516171819202122232425262728@Servicepublic class TaskService &#123; public void doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(2000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125; public void doTaskTwo() throws Exception &#123; System.out.println(\"开始做任务二\"); long start = System.currentTimeMillis(); Thread.sleep(3000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125; public void doTaskThree() throws Exception &#123; System.out.println(\"开始做任务三\"); long start = System.currentTimeMillis(); Thread.sleep(4000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125;&#125; 同步调用 1234567891011@Autowiredprivate TaskService task;public String test() &#123; try &#123; task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); &#125;catch (Exception e)&#123; &#125;&#125; 下面是运行结果，可以看到三个方法是依次执行的，分别耗时2秒、3秒、4秒、总耗时9秒 123456开始做任务一完成任务一，耗时：2001毫秒开始做任务二完成任务二，耗时：3000毫秒开始做任务三完成任务三，耗时：4001毫秒 上面的同步调用，虽然顺利地完成了三个任务，但是执行时间比较长，如果这三个任务没有依赖关系，可以并发执行的话，可以考虑使用异步调用的方法。 异步方式调用代码无返回值 首先在spring中配置相关参数开启异步调用 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:task=\"http://www.springframework.org/schema/task\" xsi:schemaLocation=\" http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd\"&gt; &lt;task:annotation-driven executor=\"taskExecutor\" /&gt; &lt;task:executor id=\"taskExecutor\" pool-size=\"20\" queue-capacity=\"1000\"/&gt;&lt;/beans&gt; 在方法上加上 @Async 注解就能将同步函数变成异步函数，改造后的代码 123456789101112131415161718192021222324252627282930import java.util.concurrent.Future;@Servicepublic class TaskService &#123; @Async public void doTaskOne() throws Exception &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(2000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125; @Async public void doTaskTwo() throws Exception &#123; System.out.println(\"开始做任务二\"); long start = System.currentTimeMillis(); Thread.sleep(3000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125; @Async public void doTaskThree() throws Exception &#123; System.out.println(\"开始做任务三\"); long start = System.currentTimeMillis(); Thread.sleep(4000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); &#125;&#125; 重新调用之后的运行结果如下： 123456开始做任务三开始做任务二开始做任务一完成任务一，耗时：2000毫秒完成任务二，耗时：3001毫秒完成任务三，耗时：4000毫秒 注意事项 @Async 所修饰的函数不要定义为 static 类型，这样异步调用不会生效。 调用方法和异步函数不能在一个 class 中。 异步方式调用代码有返回值如果想知道异步函数什么时候执行完，那就需要使用 Future (AsyncResult是Future的子类)来返回异步调用的结果。改造后的代码如下： 12345678910111213141516171819202122232425262728293031323334@Servicepublic class TaskService &#123; @Async public Future&lt;String&gt; doTaskOne() &#123; System.out.println(\"开始做任务一\"); long start = System.currentTimeMillis(); Thread.sleep(2000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); return new AsyncResult&lt;&gt;(\"任务一完成\"); &#125; @Async public Future&lt;String&gt; doTaskTwo() &#123; System.out.println(\"开始做任务二\"); long start = System.currentTimeMillis(); Thread.sleep(3000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); return new AsyncResult&lt;&gt;(\"任务二完成\"); &#125; @Async public Future&lt;String&gt; doTaskThree() &#123; System.out.println(\"开始做任务三\"); long start = System.currentTimeMillis(); Thread.sleep(4000); long end = System.currentTimeMillis(); System.out.println(\"完成任务二，耗时：%s\" , (end - start) + \"毫秒\"); return new AsyncResult&lt;&gt;(\"任务三完成\"); &#125;&#125; 异步方式调用代码有返回值 123456789101112131415161718192021222324252627282930@Autowiredprivate TaskService task;public List&lt;String&gt; test() &#123; List&lt;String&gt; result = new ArrayList(16); StopWatch stopWatch = new StopWatch(); stopWatch.start(\"接口速度统计\"); // 3秒超时 int timeout = 3; try &#123; Future&lt;String&gt; task1 = task.doTaskOne(); Future&lt;String&gt; task2 = task.doTaskTwo(); Future&lt;String&gt; task3 = task.doTaskThree(); String taskString1= task1.get(timeout, TimeUnit.SECONDS); String taskString2= task2.get(timeout, TimeUnit.SECONDS); String taskString3= task3.get(timeout, TimeUnit.SECONDS); result.add(taskString1); result.add(taskString2); result.add(taskString3); &#125;catch (TimeoutException | InterruptedException | ExecutionException e)&#123; return result; &#125; finally &#123; stopWatch.stop(); log.info(stopWatch.prettyPrint()); &#125; return result;&#125; 12345678910111213开始做任务三开始做任务二开始做任务一完成任务一，耗时：2001毫秒完成任务二，耗时：3000毫秒完成任务三，耗时：4001毫秒StopWatch '': running time (millis) = 248-----------------------------------------ms % Task name-----------------------------------------04036 100% 接口速度统计 刚开始想利用CountDownLatch来实现等待所有线程结束整合结果，后来调整为 Future 的 get(long timeout, TimeUnit unit) 来实现线程的超时控制，我看有些的例子使用死循环来阻塞整合线程的执行结果，这样做是有些问题的，如果有个线程一直没有结束运行，那就完犊子了！ 这是一种常见的场景将一个大的任务切分为数个子任务，并行处理所有子任务，当所有子任务都成功结束时再继续处理后面的逻辑。还有一种做法是利用CountDownLatch, 主线程构造countDownLatch对象，latch的大小为子任务的总数，每一个任务持有countDownLatch的引用，任务完成时对latch减1，主线程阻塞在countDownLatch.await方法上，当所有子任务都成功执行完后，latch=0, 主线程继续执行。 总结异步调用可以提升接口性能。比如导出下载、发送邮件短信等代码，可以使用异步执行。 参考 https://blog.csdn.net/qqfo24/article/details/81383022","categories":[],"tags":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"https://blog.ydstudio.net/tags/SpringMvc/"},{"name":"Async","slug":"Async","permalink":"https://blog.ydstudio.net/tags/Async/"}]},{"title":"在CentOS7上使用yum安装Docker","slug":"在CentOS7上使用yum安装Docker","date":"2019-12-23T22:30:18.000Z","updated":"2020-01-13T14:39:01.000Z","comments":true,"path":"post/ef24ce2b.html","link":"","permalink":"https://blog.ydstudio.net/post/ef24ce2b.html","excerpt":"目前在 Linux 操作系统上安装 Docker，对系统版本有以下要求： CentOS：7 Debian：7.7（Wheezy LTS）、8.0（Jessie LTS）、9（Stretch） Fedora：24、25 Ubuntu：16.04（Xenial LTS）、14.04（Trusty LTS）、17.04（Zesty）","text":"目前在 Linux 操作系统上安装 Docker，对系统版本有以下要求： CentOS：7 Debian：7.7（Wheezy LTS）、8.0（Jessie LTS）、9（Stretch） Fedora：24、25 Ubuntu：16.04（Xenial LTS）、14.04（Trusty LTS）、17.04（Zesty） 使用 yum 进行安装12345678910111213141516171819202122232425262728293031# step 1: 安装必要的一些系统工具sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装Docker-CEsudo yum makecache fastsudo yum -y install docker-ce# Step 4: 开启Docker服务sudo service docker start# 开机启动systemctl enable docker# 注意：# 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。# 例如官方并没有将测试版本的软件源置为可用，您可以通过以下方式开启。同理可以开启各种测试版本等。# vim /etc/yum.repos.d/docker-ee.repo# 将[docker-ce-test]下方的enabled=0修改为enabled=1## 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r# Loading mirror speeds from cached hostfile# Loaded plugins: branch, fastestmirror, langpacks# docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable# docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable# docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# Available Packages# Step2: 安装指定版本的Docker-CE: (VERSION例如上面的17.03.0.ce.1-1.el7.centos)# sudo yum -y install docker-ce-[VERSION] 安装校验12345678910111213141516171819202122232425262728[root@izuf6gp8l1zfgu3hmvia6gz ~]# docker versionClient: Docker Engine - Community Version: 19.03.5 API version: 1.40 Go version: go1.12.12 Git commit: 633a0ea Built: Wed Nov 13 07:25:41 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 19.03.5 API version: 1.40 (minimum version 1.12) Go version: go1.12.12 Git commit: 633a0ea Built: Wed Nov 13 07:24:18 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.10 GitCommit: b34a5c8af56e510852c35414db4c1f4fa6172339 runc: Version: 1.0.0-rc8+dev GitCommit: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init: Version: 0.18.0 GitCommit: fec3683 至此docker安装完成。 参考资料","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.ydstudio.net/tags/docker/"},{"name":"centos","slug":"centos","permalink":"https://blog.ydstudio.net/tags/centos/"}]},{"title":"Mac下安装zookeeper","slug":"Mac下安装zookeeper","date":"2019-12-07T22:15:07.000Z","updated":"2019-12-15T15:50:49.000Z","comments":true,"path":"post/d97b6c63.html","link":"","permalink":"https://blog.ydstudio.net/post/d97b6c63.html","excerpt":"从zookeeper下载，注意下载带-bin后缀的安装包，不然安装之后启动会出现以下的错误。","text":"从zookeeper下载，注意下载带-bin后缀的安装包，不然安装之后启动会出现以下的错误。 12错误: 找不到或无法加载主类org.apache.zookeeper.server.quorum.QuorumPeerMain 解决方案原来是因为从版本3.5.5开始，带有bin名称的包才是我们想要的下载可以直接使用的里面有编译后的二进制的包，而之前的普通的tar.gz的包里面是只是源码的包无法直接使用。 将下载后的安装包解压到 /usr/local/zookeeper 目录下，进行后续的安装配置。 编辑配置文件在conf目录下拷贝 zoo_sample.cfg 文件新建 zoo.cfg配置文件，修改或者新加以下内容： 1234567891011121314151617181920# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/usr/local/zookeeper/data# the port at which the clients will connectclientPort=2181#tickTime: zookeeper中使用的基本时间单位, 毫秒值.#dataDir: 数据目录. 可以是任意目录.#dataLogDir: log目录, 同样可以是任意目录. 如果没有设置该参数, 将使用和#dataDir相同的设置.此目录可以不加#clientPort: 监听client连接的端口号. 将zookeeper加入系统环境变量中12345678910111213141516171819202122sudo vim /etc/profilePATH=$PATH:/usr/local/sphinx/bin:/usr/local/elasticsearch/bin:/usr/local/mycat/bin:/usr/local/zookeeper/binexport PATH#让环境变量立马生效source /etc/profile# 启动Sam-Mac-2:~ Sam$ zkServer.sh start/usr/bin/javaZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgStarting zookeeper ... STARTED# 关闭Sam-Mac-2:~ Sam$ zkServer.sh stop/usr/bin/javaZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.ydstudio.net/tags/zookeeper/"},{"name":"mac","slug":"mac","permalink":"https://blog.ydstudio.net/tags/mac/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-11-10T13:19:35.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4a17b156.html","link":"","permalink":"https://blog.ydstudio.net/post/4a17b156.html","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"解决nested exception is java.lang.IllegalArgumentException Could not resolve placeholder alipay.appId in string value  $ {alipay.appId}","slug":"解决nested-exception-is-java-lang-IllegalArgumentException-Could-not-resolve-placeholder-alipay-appId-in-string-value-alipay-appId","date":"2019-09-18T23:52:05.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/cf36aee2.html","link":"","permalink":"https://blog.ydstudio.net/post/cf36aee2.html","excerpt":"开发的时候出现了这种错误 nested exception is java .lang.IllegalArgumentException: Could not resolve placeholder ‘alipay.appId’ in string value “${alipay.appId}”","text":"开发的时候出现了这种错误 nested exception is java .lang.IllegalArgumentException: Could not resolve placeholder ‘alipay.appId’ in string value “${alipay.appId}” 大意是Spring不能处理第二个属性文件中的配置信息，因为Spring不允许定义多个PropertyPlaceholderConfigurer或context:property-placeholder。Spring用反射扫描的发现机制，在探测到Spring容器中有一个org.springframework.beans.factory.config.PropertyPlaceholderConfigurer的Bean就会停止对剩余PropertyPlaceholderConfigurer的扫描（Spring 3.1已经使用PropertySourcesPlaceholderConfigurer替代 PropertyPlaceholderConfigurer了）。换句话说，即Spring容器仅允许最多定义一个PropertyPlaceholderConfigurer(或context:property-placeholder)，其余的会被Spring忽略掉（其实Spring如果提供一个警告就好了）。 问题的解决方案 通配符解决、逗号分隔 使用通配符让spring一次性读取多个属性文件到一个 PropertyPlaceholderConfigurer bean中12&lt;context:property-placeholder location=\"classpath:conf/*.properties\"/&gt; 或者使用 1&lt;context:property-placeholder location=\"classpath:conf/db.properties,conf/alipay.properties\"/&gt; 使用多个context:property-placeholder 分开定义，注意要加上 ignore-unresolvable 属性12&lt;context:property-placeholder location=\"classpath:conf/db.properties\" ignore-unresolvable=\"true\"/&gt;&lt;context:property-placeholder location=\"classpath:conf/alipay.properties\" ignore-unresolvable=\"true\"/&gt; 在每个PropertySourcesPlaceholderConfigurer配置中添加 或者在每个context:property-placeholder中都加上ignore-unresolvable=”true” 因为在你使用@Value(“${xx}”)或在xml中使用${xx}获取属性时，Spring会在第一个读取到的属性文件中去找，如果没有就直接抛出异常，而不会继续去第二个属性文件中找 一个PropertySourcesPlaceholderConfigurer中包含多个属性文件，和方案1原理相同1234567&lt;bean id=\"propertyConfigurer\" class=\"org.springframework.context.support.PropertySourcesPlaceholderConfigurer\"&gt;&lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;classpath:db.properties&lt;/value&gt; &lt;value&gt;classpath:alipay.properties&lt;/value&gt; &lt;/list&gt;&lt;/property&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.ydstudio.net/tags/spring/"}]},{"title":"Java获取一天的最大时间23:59:59和最小时间00:00:00","slug":"Java获取一天的最大时间23-59-59和最小时间00-00-00","date":"2019-09-04T23:49:24.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/1ef2d20f.html","link":"","permalink":"https://blog.ydstudio.net/post/1ef2d20f.html","excerpt":"Java获取一天的最大时间23:59:59和最小时间00:00:00","text":"Java获取一天的最大时间23:59:59和最小时间00:00:00 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Test &#123; public static void main(String[] args) &#123; // 加上毫秒数 SimpleDateFormat sDateFormat=new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\"); System.out.println(sDateFormat.format(getAfterYearDateMaxTime(3))); &#125; /** * 若干年之后的23:59:59 * * @param year * @return */ public static Date getAfterYearDateMaxTime(int year)&#123; Calendar calendarEnd = Calendar.getInstance(); calendarEnd.setTime(new Date()); calendarEnd.add(Calendar.YEAR,year); calendarEnd.set(Calendar.HOUR_OF_DAY, 23); calendarEnd.set(Calendar.MINUTE, 59); calendarEnd.set(Calendar.SECOND, 59); // MySQL数据库对于毫秒大于500的数据进行进位，所有就造成的MySQL中的时间多一秒,防止mysql自动加一秒,毫秒设为0 calendarEnd.set(Calendar.MILLISECOND, 0); return calendarEnd.getTime(); &#125; /** * 当天的最大时间23:59:59 * * @return */ public static Date getDayMaxTime()&#123; Calendar calendarEnd = Calendar.getInstance(); calendarEnd.setTime(new Date()); calendarEnd.set(Calendar.HOUR_OF_DAY, 23); calendarEnd.set(Calendar.MINUTE, 59); calendarEnd.set(Calendar.SECOND, 59); // MySQL数据库对于毫秒大于500的数据进行进位，所有就造成的MySQL中的时间多一秒,防止mysql自动加一秒,毫秒设为0 calendarEnd.set(Calendar.MILLISECOND, 0); return calendarEnd.getTime(); &#125; /** * 当天的最小时间00:00:00 * * @return */ public static Date getDayMinTime()&#123; Calendar calendarEnd = Calendar.getInstance(); calendarEnd.setTime(new Date()); calendarEnd.set(Calendar.HOUR_OF_DAY, 00); calendarEnd.set(Calendar.MINUTE, 00); calendarEnd.set(Calendar.SECOND, 00); // MySQL数据库对于毫秒大于500的数据进行进位，所有就造成的MySQL中的时间多一秒,防止mysql自动加一秒,毫秒设为0 calendarEnd.set(Calendar.MILLISECOND, 0); return calendarEnd.getTime(); &#125;&#125; 获取3年后的23:59:59，毫秒数设置成0 12022-09-04 23:59:59.000","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"IDEA下tomcat启动后 server乱码，Tomcat Catalina Log和Tomcat Localhost Log乱码问题的解决 ","slug":"IDEA下tomcat启动后-server乱码，Tomcat-Catalina-Log和Tomcat-Localhost-Log乱码问题的解决","date":"2019-06-03T23:48:03.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/35c3eddf.html","link":"","permalink":"https://blog.ydstudio.net/post/35c3eddf.html","excerpt":"前言不改的话，不影响使用，因为报错基本都是英文显示的。但是这几个中文字乱码的看着难受。 乱码的根本原因： Windows系统的cmd是GBK编码的，所以IDEA的下方log输出的部分的编码也是GBK的，然而Tomcat 9.0 版本默认log输出是UTF-8编码的，采用了两种不同的编码方式就会导致乱码。","text":"前言不改的话，不影响使用，因为报错基本都是英文显示的。但是这几个中文字乱码的看着难受。 乱码的根本原因： Windows系统的cmd是GBK编码的，所以IDEA的下方log输出的部分的编码也是GBK的，然而Tomcat 9.0 版本默认log输出是UTF-8编码的，采用了两种不同的编码方式就会导致乱码。 解决方案方法一 修改Tomcat 日志输出为GBK编码先打开tomcat的安装目录 编辑 conf 目录下的 logging.properties,把里面的UTF-8 通通改成 GBK,保存，重启Tomcat，即可生效。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the \"License\"); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.handlers = 1catalina.org.apache.juli.FileHandler, 2localhost.org.apache.juli.FileHandler, 3manager.org.apache.juli.FileHandler, 4host-manager.org.apache.juli.FileHandler, java.util.logging.ConsoleHandler.handlers = 1catalina.org.apache.juli.FileHandler, java.util.logging.ConsoleHandler############################################################# Handler specific properties.# Describes specific configuration info for Handlers.############################################################1catalina.org.apache.juli.FileHandler.level = FINE1catalina.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs1catalina.org.apache.juli.FileHandler.prefix = catalina.1catalina.org.apache.juli.FileHandler.encoding = UTF-82localhost.org.apache.juli.FileHandler.level = FINE2localhost.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs2localhost.org.apache.juli.FileHandler.prefix = localhost.2localhost.org.apache.juli.FileHandler.encoding = UTF-83manager.org.apache.juli.FileHandler.level = FINE3manager.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs3manager.org.apache.juli.FileHandler.prefix = manager.3manager.org.apache.juli.FileHandler.encoding = UTF-84host-manager.org.apache.juli.FileHandler.level = FINE4host-manager.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs4host-manager.org.apache.juli.FileHandler.prefix = host-manager.4host-manager.org.apache.juli.FileHandler.encoding = UTF-8java.util.logging.ConsoleHandler.level = FINEjava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatterjava.util.logging.ConsoleHandler.encoding = UTF-8############################################################# Facility specific properties.# Provides extra control for each logger.############################################################org.apache.catalina.core.ContainerBase.[Catalina].[localhost].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].handlers = 2localhost.org.apache.juli.FileHandlerorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].handlers = 3manager.org.apache.juli.FileHandlerorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].handlers = 4host-manager.org.apache.juli.FileHandler# For example, set the org.apache.catalina.util.LifecycleBase logger to log# each component that extends LifecycleBase changing state:#org.apache.catalina.util.LifecycleBase.level = FINE# To see debug messages in TldLocationsCache, uncomment the following line:#org.apache.jasper.compiler.TldLocationsCache.level = FINEjava.util.logging.ConsoleHandler.encoding = UTF-8 方法二 修改IDEA为UTF-8编码idea.exe.vmoptions、idea64.exe.vmoptions 修改idea.exe.vmoptions和idea64.exe.vmoptions这两个文件 分别在这两个文件的最后，添加一行 -Dfile.encoding=UTF-8 12345678910111213-Xms128m-Xmx750m-XX:ReservedCodeCacheSize=240m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Djdk.http.auth.tunneling.disabledSchemes=\"\"-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Dfile.encoding=UTF-8 这个参数的作用是强制系统文件使用UTF-8编码,改完之后保存，重启IDEA即可。","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://blog.ydstudio.net/tags/tomcat/"},{"name":"idea","slug":"idea","permalink":"https://blog.ydstudio.net/tags/idea/"}]},{"title":"JavaScript如何面向对象","slug":"JavaScript如何面向对象","date":"2019-05-23T23:47:08.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/d7445999.html","link":"","permalink":"https://blog.ydstudio.net/post/d7445999.html","excerpt":"关于JavaScript编写类的方式，总结一下JavaScript编写类的几种写法以及这几种写法的优缺点。","text":"关于JavaScript编写类的方式，总结一下JavaScript编写类的几种写法以及这几种写法的优缺点。 构造函数方式基本语法： 1234567891011121314 function 类名()&#123; this.属性名;//公共属性 var 属性名;//私有属性 /*凡是定义类的公共属性和公共方法都要使用this*/ //定义类的公共函数 this.函数名=function()&#123; ..... &#125; //定义类的私有函数 function 函数名()&#123; ...... &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/*定义一个Person类*/ function Person(_name,_age,_salary)&#123; //Person类的公开属性，类的公开属性的定义方式是：”this.属性名“ this.name=_name; //Person类的私有属性，类的私有属性的定义方式是：”var 属性名“ var age=_age;//私有属性 var salary=_salary;//私有属性 /*定义私有属性Age的对外公开访问方法*/ this.setAge = function(intAge) &#123; age = intAge; &#125; /*定义私有属性Age的对外公开访问方法*/ this.getAge = function() &#123; return age; &#125; //定义Person类的公开方法(特权方法)，类的公开方法的定义方式是：”this.functionName=function()&#123;.....&#125;“ this.Show=function()&#123; document.writeln(\"在公开方法里面访问类的私有属性是允许的，age=\"+age+\"\\t\"+\"salary=\"+salary);//在公开方法里面访问类的私有属性是允许的 &#125; //公共方法 this.publicMethod = function()&#123; document.writeln(\"在公开方法里面访问类的私有方法是允许的\"); privateFn();//在公开方法里面调用类的私有方法 privateFn2();//在公开方法里面调用类的私有方法 &#125; /* 定义Person类的私有方法(内部方法)， 类的私有方法的定义方式是：”function functionName()&#123;.....&#125;“， 或者 var functionName=function()&#123;....&#125; */ function privateFn()&#123; document.writeln(\"我是Person类的私有函数privateFn\"); &#125; var privateFn2=function()&#123; document.writeln(\"我是Person类的私有函数privateFn2\"); &#125; &#125; 测试Person类 1234567891011121314151617181920var p1 = new Person(\"孤傲苍狼\",24,2300); var p2 = new Person(\"白虎神皇\",24,2300); document.write(\"&lt;pre&gt;\"); document.writeln(\"p1 instanceof Person的结果是：\"+(p1 instanceof Person));//p1是Person类的实例，结果是true document.writeln(\"p2 instanceof Person的结果是：\"+(p2 instanceof Person));//p2是Person类的实例，结果是true //当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等 document.writeln(\"当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等\"); document.writeln(\"比较p1和p2这两个对象的show方法的内存地址是否一样：p1.show== p2.show的结果是：\"+(p1.show == p2.show));//false document.writeln(\"p1.show == p2.show的结果是：\"+(p1.show == p2.show)+\"，这证明p1对象和p2对象不是共享一个show方法，在内存中show方法的代码有2份，存放在两块内存区域\"); document.writeln(\"name是Person类定义的public属性，可以使用类的对象去直接访问类的public属性\"); document.writeln(\"p1.name=\"+p1.name);//访问公有属性，这是可以正常访问的 document.writeln(\"age和salary是Person类定义的private属性，不能使用类的对象去直接访问类私有属性，这是访问不了的，结果都是undefined\"); document.writeln(\"p1.age=\"+p1.age+\"，\"+\"p1.salary=\"+p1.salary)//不能使用类的对象去直接访问类私有属性，这是访问不了的，结果都是undefined p1.show();//调用类的公共函数，这次允许的 p1.publicMethod();//调用类的公共函数，这次允许的 p1.setAge(24);//使用public方法setAge方法为私有属性age赋值 document.writeln(\"使用public方法getAge方法获取私有属性age的值，p1.getAge()=\"+p1.getAge());//使用getAge方法获取私有属性age的值 //document.writeln(\"p1.privateFn()：\"+p1.privateFn()+\"&amp;nbsp;p1.privateFn2()：\"+p1.privateFn2());//不能使用类的对象去调用类的私有方法，这里会报错”对象不支持此属性或者方法 document.write(\"&lt;/pre&gt;\"); 这种方式的优点是：可以根据参数来构造不同的对象实例 ，每个对象的属性一般是不相同的，缺点是构造每个实例对象时，方法不能共享，Person类里面定义的那些方法，p1对象有一份，p2也有一份，那么在内存中就得开辟两块内存空间来分别存储p1的方法和p2的方法，这样就造成了内存的浪费。对于一个类的不同实例对象，这些对象的属性一般是不相同的，但是方法是相同的，所以节约内存的做法就是把方法放到内存的一块区域中存放，然后每个实例对象都从这块内存中取出方法。 原型方式需要说明的是，使用原型方式编写JavaScript类是无法给类添加私有属性和私有方法的，使用原型方式添加的属性和方法都是public的。 写法一 123456789101112131415161718192021222324252627/*定义一个Person类*/ function Person(_name,_age,_weight,_height)&#123; this.init(_name,_age,_weight,_height); &#125; /*使用原型的方式定义Person类的public属性：name,age,weight,height，使用原型的方式添加的属性都是public的*/ Person.prototype.name; Person.prototype.age; Person.prototype.weight; Person.prototype.height; /*使用原型的方式给Person类添加public方法，使用原型的方式添加的方法都是public的*/ /*使用原型的方式给Person类添加init方法*/ Person.prototype.init = function(_name,_age,_weight,_height) &#123; if(_name != undefined &amp;&amp; _age!=undefined &amp;&amp; _weight!=undefined &amp;&amp; _height!=undefined)&#123; this.name = _name; this.age = _age; this.weight=_weight; this.height=_height; document.writeln(\"this.name=\"+this.name+\",this.age=\"+this.age+\",this.weight=\"+this.weight+\",this.height=\"+this.height); &#125; &#125; /*使用原型的方式给Person类添加show方法*/ Person.prototype.show = function()&#123; document.writeln(\"show method\"); &#125; 测试 123456789101112131415161718document.write(\"&lt;pre&gt;\"); var p1 = new Person(\"孤傲苍狼\",24,115,160); var p2 = new Person(\"白虎神皇\",25,120,170); var p3 = new Person(); p3.init(\"玄天邪帝\",26,130,180);//调用public方法init初始化p3对象 document.writeln(\"p1 instanceof Person的结果是：\"+(p1 instanceof Person));//p1是Person类的实例，结果是true document.writeln(\"p2 instanceof Person的结果是：\"+(p2 instanceof Person));//p2是Person类的实例，结果是true document.writeln(\"p3 instanceof Person的结果是：\"+(p3 instanceof Person));//p3是Person类的实例，结果是true //当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等 document.writeln(\"当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等\"); document.writeln(\"比较p1和p2这两个对象的show方法的内存地址是否一样：p1.show == p2.show的结果是：\"+(p1.show == p2.show));//true document.writeln(\"p1.show == p2.show的结果是：\"+(p1.show == p2.show)+\"，这证明p1对象和p2对象共享一个show方法，在内存中show方法的代码只有一份，存放在内存的一块区域\");//true document.writeln(\"p1.name=\"+p1.name+\"，p1.age=\"+p1.age+\"，p1.weight=\"+p1.weight+\"，p1.height=\"+p1.height);//访问公有属性，这是可以正常访问的 document.writeln(\"p2.name=\"+p2.name+\"，p2.age=\"+p2.age+\"，p2.weight=\"+p2.weight+\"，p2.height=\"+p2.height);//访问公有属性，这是可以正常访问的 p3.name=\"灭世魔尊\";//为公共属性重新赋值 document.writeln(\"p3.name=\"+p3.name);//访问公有属性，这是可以正常访问的 p1.show();//调用类的公共函数，这次允许的 document.write(\"&lt;/pre&gt;\"); 写法二使用原型方式给类定义public属性和public方法更加优雅的写法，我个人推荐使用这种方式，这种方式看起来比较舒服 123456789101112131415161718192021222324/*定义类Person2*/ function Person2()&#123; &#125; /*使用原型方式给类定义public属性和public方法更加优雅的写法*/ Person2.prototype = &#123; name:\"\",//public属性 age:0,//public属性 weight:0,//public属性 height:0,//public属性 /*public方法*/ init:function(_name,_age,_weight,_height) &#123; this.name = _name; this.age = _age; this.weight=_weight; this.height=_height; document.writeln(\"this.name=\"+this.name+\",this.age=\"+this.age+\",this.weight=\"+this.weight+\",this.height=\"+this.height); &#125;, /*public方法*/ show:function()&#123; document.writeln(\"show method\"); &#125; &#125;; 测试代码： 1234567891011121314151617document.write(\"&lt;pre&gt;\"); var p2_1 = new Person2(); var p2_2 = new Person2(); p2_1.init(\"孤傲苍狼\",24,115,160); p2_2.init(\"白虎神皇\",25,120,170); document.writeln(\"p2_1.name=\"+p2_1.name+\"，p2_1.age=\"+p2_1.age+\"，p2_1.weight=\"+p2_1.weight+\"，p2_1.height=\"+p2_1.height);//访问公有属性，这是可以正常访问的 document.writeln(\"p2_2.name=\"+p2_2.name+\"，p2_2.age=\"+p2_2.age+\"，p2_2.weight=\"+p2_2.weight+\"，p2_2.height=\"+p2_2.height);//访问公有属性，这是可以正常访问的 document.writeln(\"p2_1 instanceof Person2的结果是：\"+(p2_1 instanceof Person2));//p2_1是Person2类的实例，结果是true document.writeln(\"p2_2 instanceof Person2的结果是：\"+(p2_2 instanceof Person2));//p2_2是Person2类的实例，结果是true //当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等 document.writeln(\"当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等\"); document.writeln(\"比较p2_1和p2_2这两个对象的init方法的内存地址是否一样：p2_1.init == p2_2.init的结果是：\"+(p2_1.init == p2_2.init));//true p2_1.name=\"灭世魔尊\";//为公共属性重新赋值 document.writeln(\"p2_1.name=\"+p2_1.name);//访问公有属性，这是可以正常访问的 p2_1.show();//调用类的公共函数，这次允许的 document.write(\"&lt;/pre&gt;\"); 构造函数+原型 构造函数方式和原型方式都有各自的优缺点，因此可以把这两种方式合并起来，用构造函数方式来定义类的属性(public属性，private属性)，用原型方式来定义类的方法(public方法)。互补不足，这就有了第三种写法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/*定义一个Person类*/ function Person(_name,_age,_salary)&#123; //在Person类内部定义类的public属性和private属性以及private方法 //Person类的公开属性，类的公开属性的定义方式是：”this.属性名“ this.name=_name; //Person类的私有属性，类的私有属性的定义方式是：”var 属性名“ var age=_age;//私有属性，只能在类内部使用 var salary=_salary;//私有属性，只能在类内部使用 /* 定义Person类的私有方法(内部方法)，只能在类内部使用 类的私有方法的定义方式是：”function functionName()&#123;.....&#125;“， 或者 var functionName=function()&#123;....&#125; */ function privateFn()&#123; document.write(\"&lt;pre&gt;\"); document.writeln(\"我是Person类的私有属性age，只能在Person类内部使用，初始化后age=\"+age); document.writeln(\"我是Person类的私有函数privateFn，只能在Person类内部使用\"); document.write(\"&lt;/pre&gt;\"); &#125; var privateFn2=function()&#123; document.write(\"&lt;pre&gt;\"); document.writeln(\"我是Person类的私有属性salary，只能在Person类内部使用，初始化后salary=\"+salary); document.writeln(\"我是Person类的私有函数privateFn2，只能在Person类内部使用\"); document.write(\"&lt;/pre&gt;\"); &#125; privateFn();//在Person类内部调用私有方法 privateFn2();//在Person类内部调用私有方法 &#125; //使用prototype原型方式定义的方法(public方法)是无法访问类的私有属性和私有方法的 //使用prototype原型方式定义Person类的方public方法 Person.prototype=&#123; setName:function(_name)&#123; this.name = _name; //privateFn();//不能调用Person类定义的私有方法privateFn()，会报错：缺少对象 &#125;, getName:function()&#123; return this.name; &#125;, show:function()&#123; document.writeln(\"公开方法show\"); &#125;, //公共方法 publicMethod:function()&#123; document.writeln(\"公开方法publicMethod\"); &#125; &#125;; 测试代码： 12345678910111213141516171819var p1 = new Person(\"孤傲苍狼\",24,2300); var p2 = new Person(\"白虎神皇\",25,3000); document.write(\"&lt;pre&gt;\"); document.writeln(\"p1 instanceof Person的结果是：\"+(p1 instanceof Person));//p1是Person类的实例，结果是true document.writeln(\"p2 instanceof Person的结果是：\"+(p2 instanceof Person));//p2是Person类的实例，结果是true //当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等 document.writeln(\"当==两边的内容是对象或者是对象的函数属性时，则比较内存地址是否相等\"); document.writeln(\"比较p1和p2这两个对象的show方法的内存地址是否一样：p1.show== p2.show的结果是：\"+(p1.show == p2.show));//true document.writeln(\"p1.show == p2.show的结果是：\"+(p1.show == p2.show)+\"，这证明p1对象和p2对象共享一个show方法，在内存中show方法的代码有1份，存放在1块内存区域\"); document.writeln(\"name是Person类定义的public属性，可以使用类的对象去直接访问类的public属性\"); document.writeln(\"p1.name=\"+p1.name);//访问公有属性，这是可以正常访问的 document.writeln(\"age和salary是Person类定义的private属性，不能使用类的对象去直接访问类私有属性，这是访问不了的，结果都是undefined\"); document.writeln(\"p1.age=\"+p1.age+\"，\"+\"p1.salary=\"+p1.salary)//不能使用类的对象去直接访问类私有属性，这是访问不了的，结果都是undefined p1.show();//调用类的公共函数，这次允许的 p1.publicMethod();//调用类的公共函数，这次允许的 p1.setName(\"玄天邪帝\");//调用类的公共函数设置为name属性重新赋值 document.writeln(\"p1.getName=\"+p1.getName()); //document.writeln(\"p1.privateFn()：\"+p1.privateFn()+\"&amp;nbsp;p1.privateFn2()：\"+p1.privateFn2());//不能使用类的对象去调用类的私有方法，这里会报错”对象不支持此属性或者方法 document.write(\"&lt;/pre&gt;\"); 第三种方式通过前两种方式的结合，算是达到了一个比较理想的写法了，可以通过传参构造对象实例，对象实例都共享同一份方法不造成内存浪费。第三种方式在开发中用得最多，我本人也是采用这种方式来编写JavaScript类。 查看原文","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://blog.ydstudio.net/tags/JavaScript/"},{"name":"oop","slug":"oop","permalink":"https://blog.ydstudio.net/tags/oop/"}]},{"title":"Dubbo消费者consumer捕捉服务提供者provider抛出的自定义异常","slug":"Dubbo消费者consumer捕捉服务提供者provider抛出的自定义异常","date":"2019-05-20T23:44:33.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/2e0453a7.html","link":"","permalink":"https://blog.ydstudio.net/post/2e0453a7.html","excerpt":"我们在自己的业务系统中，通常会用到自定义的业务异常类，这个异常会继承extends RuntimeException，当发生业务限制的时候，会throw出来。但是在使用dubbo进行soa治理的时候，会发现provider抛出的异常，在custom端并不能正确的捕获。即便我们在provider和custom都有导入相同framework.jar下面的BusinessException异常，并且抛出这个异常，在Consumer端只会打印一行异常信息，获取不到正常的异常。百度才知道Dubbo对抛出得异常用一个ExceptionFilter的类进行拦截。","text":"我们在自己的业务系统中，通常会用到自定义的业务异常类，这个异常会继承extends RuntimeException，当发生业务限制的时候，会throw出来。但是在使用dubbo进行soa治理的时候，会发现provider抛出的异常，在custom端并不能正确的捕获。即便我们在provider和custom都有导入相同framework.jar下面的BusinessException异常，并且抛出这个异常，在Consumer端只会打印一行异常信息，获取不到正常的异常。百度才知道Dubbo对抛出得异常用一个ExceptionFilter的类进行拦截。 在一个公共包里定义一个异常类，继承自RuntimeException。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class BusinessException extends RuntimeException &#123; /** * 异常code */ private String code; public BusinessException() &#123; super(); &#125; public BusinessException(String message) &#123; super(message); &#125; public BusinessException(String code, String message) &#123; super(message); this.code = code; &#125; public BusinessException(String message, Throwable cause) &#123; super(message, cause); &#125; public BusinessException(String code, String message, Throwable cause) &#123; super(message, cause); this.code = code; &#125; public BusinessException(Throwable cause) &#123; super(cause); &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125;&#125; 在服务提供者的Dubbo配置文件中添加下面的内容，主要就是自定义exceptionFilter，然后排出dubbo自带的exceptionFilter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- http://dubbo.apache.org/schema/dubbo/dubbo.xsd 上面配置为这个一直报错，改为 http://code.alibabatech.com/schema/dubbo/dubbo.xsd --&gt; &lt;!--用于配置当前应用信息，不管该应用是提供者还是消费者 --&gt; &lt;dubbo:application name=\"dubbo-web-provide\"/&gt; &lt;!-- 用于配置连接注册中心相关信息 --&gt; &lt;dubbo:registry address=\"zookeeper://localhost:2181\" timeout=\"30000\"&gt; &lt;!--配置redis连接参数 --&gt; &lt;!--具体参数配置见com.alibaba.dubbo.registry.redis.RedisRegistry.class --&gt; &lt;dubbo:parameter key=\"max.idle\" value=\"10\" /&gt; &lt;dubbo:parameter key=\"min.idle\" value=\"5\" /&gt; &lt;dubbo:parameter key=\"max.active\" value=\"20\" /&gt; &lt;dubbo:parameter key=\"max.total\" value=\"100\" /&gt; &lt;/dubbo:registry&gt; &lt;!-- 最重要的就是下面的配置：自定义exceptionFilter，然后排出dubbo自带的exceptionFilter payload 设置传输的最大值 --&gt; &lt;dubbo:provider filter=\"dubboExceptionFilter,-exception\" payload=\"123886080\" &gt;&lt;/dubbo:provider&gt; &lt;!-- 用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" accesslog=\"true\" serialization=\"hessian2\" /&gt; &lt;!-- 实现类 --&gt; &lt;bean id=\"helloService\" class=\"cn.ydstudio.dubbo.web.provide.serviceimpl.HelloServiceImpl\" /&gt; &lt;bean id=\"goodsService\" class=\"cn.ydstudio.dubbo.web.provide.serviceimpl.GoodsServiceImpl\" /&gt; &lt;bean id=\"goodsService2\" class=\"cn.ydstudio.dubbo.web.provide.serviceimpl.GoodsServiceImpl2\" /&gt; &lt;bean id=\"goodsOrderServiceRemoteImpl\" class=\"cn.ydstudio.dubbo.web.provide.serviceimpl.GoodsOrderServiceRemoteImpl\" /&gt; &lt;!--定义暴露服务的接口，用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心 --&gt; &lt;!--每个接口都应定义版本号，为后续不兼容升级提供可能 --&gt; &lt;!--ref：服务的真正实现类 --&gt; &lt;dubbo:service interface=\"cn.ydstudio.dubbo.rpc.service.HelloService\" ref=\"helloService\" version=\"1.0.0\" retries=\"1\"/&gt; &lt;dubbo:service interface=\"cn.ydstudio.dubbo.rpc.service.GoodsService\" ref=\"goodsService\" version=\"1.0.0\" retries=\"1\"/&gt; &lt;dubbo:service interface=\"cn.ydstudio.dubbo.rpc.service.GoodsService\" ref=\"goodsService2\" version=\"2.0.0\" retries=\"1\"/&gt; &lt;dubbo:service interface=\"cn.ydstudio.dubbo.rpc.service.GoodsOrderServiceRemote\" ref=\"goodsOrderServiceRemoteImpl\" version=\"1.0.0\" retries=\"0\" &gt; &lt;dubbo:method name=\"querGoodsOrderList\" timeout=\"1000000\"/&gt; &lt;/dubbo:service&gt; &lt;!--监控中心配置 监控中心协议，如果为protocol=\"registry\"，表示从注册中心发现监控中心地址，否则直连监控中心。 --&gt; &lt;!--&lt;dubbo:monitor protocol=\"registry\"&gt;&lt;/dubbo:monitor&gt;--&gt; &lt;!-- 直连监控中心服务器地址 --&gt; &lt;!-- &lt;dubbo:monitor address=\"localhost:6379\"&gt;&lt;/dubbo:monitor&gt; --&gt; &lt;/beans&gt; 最重要的继承ExceptionFilter，然后重写invoke方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package cn.ydstudio.dubbo.web.provide.filter;import cn.ydstudio.common.tools.exception.BizException;import cn.ydstudio.common.tools.exception.BusinessException;import com.alibaba.dubbo.common.logger.Logger;import com.alibaba.dubbo.common.logger.LoggerFactory;import com.alibaba.dubbo.common.utils.ReflectUtils;import com.alibaba.dubbo.common.utils.StringUtils;import com.alibaba.dubbo.rpc.*;import com.alibaba.dubbo.rpc.filter.ExceptionFilter;import com.alibaba.dubbo.rpc.service.GenericService;import java.lang.reflect.Method;/** * 功能描述:&lt;br/&gt; * * @Author 刘洋【19037900】 * @Date 2019/4/30 18:02 */public class DubboExceptionFilter extends ExceptionFilter &#123; private final Logger logger; public DubboExceptionFilter() &#123; this(LoggerFactory.getLogger(com.alibaba.dubbo.rpc.filter.ExceptionFilter.class)); &#125; public DubboExceptionFilter(Logger logger) &#123; this.logger = logger; &#125; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; Result result = invoker.invoke(invocation); if (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; try &#123; Throwable exception = result.getException(); // 自定义的异常 if (exception instanceof BizException || exception instanceof BusinessException)&#123; return result; &#125; if (!(exception instanceof RuntimeException) &amp;&amp; exception instanceof Exception) &#123; return result; &#125; else &#123; try &#123; Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes()); Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes(); Class[] arr$ = exceptionClassses; int len$ = exceptionClassses.length; for (int i$ = 0; i$ &lt; len$; ++i$) &#123; Class&lt;?&gt; exceptionClass = arr$[i$]; if (exception.getClass().equals(exceptionClass)) &#123; return result; &#125; &#125; &#125; catch (NoSuchMethodException var11) &#123; return result; &#125; this.logger.error(\"Got unchecked and undeclared exception which called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + exception.getClass().getName() + \": \" + exception.getMessage(), exception); String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface()); String exceptionFile = ReflectUtils.getCodeBase(exception.getClass()); if (serviceFile != null &amp;&amp; exceptionFile != null &amp;&amp; !serviceFile.equals(exceptionFile)) &#123; String className = exception.getClass().getName(); if (!className.startsWith(\"java.\") &amp;&amp; !className.startsWith(\"javax.\")) &#123; return (Result) (exception instanceof RpcException ? result : new RpcResult(new RuntimeException(StringUtils.toString(exception)))); &#125; else &#123; return result; &#125; &#125; else &#123; return result; &#125; &#125; &#125; catch (Throwable var12) &#123; this.logger.warn(\"Fail to ExceptionFilter when called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + var12.getClass().getName() + \": \" + var12.getMessage(), var12); return result; &#125; &#125; else &#123; return result; &#125; &#125; catch (RuntimeException var13) &#123; this.logger.error(\"Got unchecked and undeclared exception which called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + var13.getClass().getName() + \": \" + var13.getMessage(), var13); throw var13; &#125; &#125;&#125; 然后在provider可以直接抛出异常，在consumer可以直接捕捉到。consumer服务消费端可以新建一个全局异常处理的控制器，可以格式化后输出给前端。","categories":[],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://blog.ydstudio.net/tags/dubbo/"}]},{"title":"小试阿里巴巴EasyExcel导出Excel","slug":"小试阿里巴巴EasyExcel导出Excel","date":"2019-05-17T23:43:39.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/76eb7bfd.html","link":"","permalink":"https://blog.ydstudio.net/post/76eb7bfd.html","excerpt":"添加easyexcel的maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;","text":"添加easyexcel的maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; 导出的模型需要继承BaseRowModel，然后可以在每个属性上设置所在的列和一些format12345678910111213141516171819202122232425262728293031323334public class GoodsOrderExportDto extends BaseRowModel &#123; @ExcelProperty(value = \"订单序号\",index = 0) private Long orderId; @ExcelProperty(value = \"订单编号\",index = 1) private String orderCode; @ExcelProperty(value = \"商品序号\",index = 2) private Long goodsId; @ExcelProperty(value = \"商品名称\",index = 3) private String goodsTitle; @ExcelProperty(value = \"商品链接\",index = 4) private String goodsDetailsUrl; @ExcelProperty(value = \"商品图片\",index = 5) private String goodsPhoto; @ExcelProperty(value = \"商品数量\",index = 6) private Long goodsNum; @ExcelProperty(value = \"商品价格\",index = 7) private BigDecimal goodsAmt; @ExcelProperty(value = \"区域公司\",index = 8) private Long areaComp; @ExcelProperty(value = \"付款时间\",index = 12,format = \"yy-MM-dd hh:mm:ss\") private Date payTime;&#125; 最后在控制器输出12345678910111213141516171819202122232425262728293031323334@RequestMapping(value = \"export\",method = RequestMethod.GET) public void exportExcel(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; List&lt;GoodsOrderDto&gt; orderDtoList = goodsOrderServiceRemote.querGoodsOrderList(); List&lt;GoodsOrderExportDto&gt; orderExportDtoList = Collections.emptyList(); if (CollectionUtils.isNotEmpty(orderDtoList))&#123; orderExportDtoList = new ArrayList&lt;&gt;(orderDtoList.size()); for (GoodsOrderDto goodsOrderDto : orderDtoList) &#123; GoodsOrderExportDto goodsOrderExportDto = new GoodsOrderExportDto(); BeanUtils.copyProperties(goodsOrderDto,goodsOrderExportDto); orderExportDtoList.add(goodsOrderExportDto); &#125; orderDtoList.clear(); &#125; // 设定输出文件头 response.setHeader(\"Content-disposition\", \"attachment; filename=\" + URLEncoder.encode(\"订单导出.xls\", \"UTF-8\")); // 定义输出类型 response.setContentType(\"application/msexcel\"); OutputStream outputStream = response.getOutputStream(); ExcelWriter excelWriter = new ExcelWriter(outputStream, ExcelTypeEnum.XLS); Sheet sheet = new Sheet(1, 0, GoodsOrderExportDto.class); excelWriter.write(orderExportDtoList,sheet); outputStream.flush(); excelWriter.finish(); outputStream.close(); &#125;","categories":[],"tags":[{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://blog.ydstudio.net/tags/EasyExcel/"}]},{"title":"查看依赖第三方jar最低要求运行的jdk版本","slug":"查看依赖第三方jar最低要求运行的jdk版本","date":"2019-05-17T23:42:49.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/58af8f82.html","link":"","permalink":"https://blog.ydstudio.net/post/58af8f82.html","excerpt":"最近在比较阿里巴巴的easyexcel和easypoi的excel导出功能哪个强大。两者的demo我都是写在同一个工程里面的，easyexcel的demo是先写的，使用起来方便简洁。然后开始写easypoi的demo时，首先出现了依赖下载不了，依赖能下载之后，还出现了下面的乱七八糟的问题：","text":"最近在比较阿里巴巴的easyexcel和easypoi的excel导出功能哪个强大。两者的demo我都是写在同一个工程里面的，easyexcel的demo是先写的，使用起来方便简洁。然后开始写easypoi的demo时，首先出现了依赖下载不了，依赖能下载之后，还出现了下面的乱七八糟的问题： 123Handler dispatch failed; nested exception is java.lang.NoClassDefFoundError: cn/afterturn/easypoi/excel/entity/ExportParamsUnsupported major.minor version 52.0 刚开始我是以为easypoi的依赖包没有完整下下来，后来检查发现应该全部下载了。后来我想是不是依赖没有添加全，去easypoi的官方网站看，我的依赖使用应该是没有问题的，但是我还是把easypoi的版本从4.0.0降到了3.30，但是demo运行起来还是报错。后来我想到easyexcel也是依赖poi的，是不是他俩又版本依赖的冲突。于是我把easyexcel给注释了，于是我就成功了！~我嘞个去！！！！！出现第一个错误就是因为easyexcel和easypoi的依赖有冲突。出现第二个错误是英文，使用的easypoi的版本过高，我使用的是easypoi4.0.0,他需要的jdk的版本是jdk8以上的。 那如何查看第三方依赖最低要求运行的jdk版本呢？ 在第三方jar包下会存在一个META-INF目录，该目录下有一个MANIFEST.MF文件，这个文件以键值对的形式存储一些关于jar包的关键信息。下面我以easypoi-base的MANIFEST.MF文件做为示例： 12345Manifest-Version: 1.0Archiver-Version: Plexus ArchiverBuilt-By: jueyueCreated-By: Apache Maven 3.1.1Build-Jdk: 1.8.0_144 可是一个.jar文件中，如果没有这个字段，就必须通过下面一种方法来查看 通过反编译.class文件来查看解压.jar包，能得到.class文件。用JDK自带的javap反编译.class文件，用如下命令： 1234javap -verbose Configuration.class#查看得到的信息中，major version属性的内容，如下major version: 52 说明这个.class文件是由JDK1.8编译得到的。 Java 9 uses major version 53 J2SE 8.0 = 52(0x33 hex) J2SE 7.0 = 51(0x32 hex) J2SE 6.0 = 50 (0x32 hex) J2SE 5.0 = 49 (0x31 hex) JDK 1.4 = 48 (0x30 hex) JDK 1.3 = 47 (0x2F hex) JDK 1.2 = 46 (0x2E hex) JDK 1.1 = 45 (0x2D hex) 注意：一个.jar包中可能有多个.class文件，每个.class的JDK版本可能会不一样（编译器多个项目设置不同） 我电脑上安装的是jdk7。所以解决办法是删掉easyexcel的依赖，使用easypoi运行和自己jdk相同版本的就行了","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"Dubbo出现ExceedPayloadLimitException: Data length too large的错误","slug":"Dubbo出现ExceedPayloadLimitException-Data-length-too-large的错误","date":"2019-05-14T23:41:47.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/45135675.html","link":"","permalink":"https://blog.ydstudio.net/post/45135675.html","excerpt":"在使用dubbo的时候，一次请求的数据量过大的时候，会出现下面的问题。","text":"在使用dubbo的时候，一次请求的数据量过大的时候，会出现下面的问题。 123456789101112131415161718192021222324252627com.alibaba.dubbo.remoting.transport.ExceedPayloadLimitException: Data length too large: 12470880, max payload: 8388608, channel: NettyChannel [channel=[id: 0x78767b1e, /10.23.144.194:54414 =&gt; /10.23.144.194:20880]] at com.alibaba.dubbo.remoting.transport.AbstractCodec.checkPayload(AbstractCodec.java:44) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.encodeResponse(ExchangeCodec.java:288) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.encode(ExchangeCodec.java:73) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec.encode(DubboCountCodec.java:38) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalEncoder.encode(NettyCodecAdapter.java:80) [dubbo-2.6.2.jar:2.6.2] at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:66) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:776) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:304) [netty-3.2.5.Final.jar:na] at com.alibaba.dubbo.remoting.transport.netty.NettyHandler.writeRequested(NettyHandler.java:98) [dubbo-2.6.2.jar:2.6.2] at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:266) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.Channels.write(Channels.java:611) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.Channels.write(Channels.java:578) [netty-3.2.5.Final.jar:na] at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:251) [netty-3.2.5.Final.jar:na] at com.alibaba.dubbo.remoting.transport.netty.NettyChannel.send(NettyChannel.java:100) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.transport.AbstractPeer.send(AbstractPeer.java:53) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:173) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:51) [dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:80) [dubbo-2.6.2.jar:2.6.2] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]2019-05-14 10:27:30.194 WARN 10424 --- [:20880-thread-4] c.a.d.r.exchange.codec.ExchangeCodec : [DUBBO] Data length too large: 12470880, max payload: 8388608, channel: NettyChannel [channel=[id: 0x78767b1e, /10.23.144.194:54414 =&gt; /10.23.144.194:20880]], dubbo version: 2.6.2, current host: 10.23.144.194 当Dubbo服务提供者向消费者传输大数据容量的对象时，会受到Dubbo的限制，抛出上面的Data length too large异常编辑dubbo.xml,添加payload配置，默认是8M，我给改成80M。这样做简单粗暴，其实不太符合Dubbo的设计理念。 1&lt;dubbo:provider filter=\"dubboExceptionFilter,-exception\" payload=\"83886080\" &gt;&lt;/dubbo:provider&gt;","categories":[],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://blog.ydstudio.net/tags/dubbo/"}]},{"title":"MyBatis Generator配置文件--指定生成实体类使用实际的表列名作为实体类的属性名","slug":"MyBatis-Generator配置文件-指定生成实体类使用实际的表列名作为实体类的属性名","date":"2019-05-13T23:40:33.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/f1ed0391.html","link":"","permalink":"https://blog.ydstudio.net/post/f1ed0391.html","excerpt":"今天在用MyBatis Generator生成表实体的时候，发现数据库中的表字段使用的是小驼峰命名规则，生成出来的实体属性都是小写了，没有转成小驼峰，一番搜索得知可以在MyBatis Generator的配置文件中修改。","text":"今天在用MyBatis Generator生成表实体的时候，发现数据库中的表字段使用的是小驼峰命名规则，生成出来的实体属性都是小写了，没有转成小驼峰，一番搜索得知可以在MyBatis Generator的配置文件中修改。 table标签下的设置属性useActualColumnNames用于指定生成实体类时是否使用实际的列名作为实体类的属性名，取值true或false。 true：MyBatis Generator会使用数据库中实际的字段名字作为生成的实体类的属性名。 false：这是默认值。如果设置为false,则MyBatis Generator会将数据库中实际的字段名字转换为Camel Case风格作为生成的实体类的属性名。 如果明确的使用columnOverride元素指定了字段对应的实体的属性名,那么useActualColumnNames会被忽略。 假设表有一个字段名为start_date,如果这个属性设置为true,则生成的实体类的属性名为start_date,生成的setter/getter为 setStart_date/getStart_date。如果useActualColumnNames设置为false,则生成的实体类的属性名为startDate,生成的setter/getter为setStartDate/getStartDate。 123456&lt;table tableName=\"dobbo_goods_order\" domainObjectName=\"GoodsOrder\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\" &gt; &lt;!-- table标签下的设置属性useActualColumnNames用于指定生成实体类时是否使用实际的列名作为实体类的属性名，取值true或false--&gt; &lt;property name=\"useActualColumnNames\" value=\"true\" /&gt; &lt;/table&gt;","categories":[],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://blog.ydstudio.net/tags/mybatis/"}]},{"title":"Dubbo由于连接不上monitor监控中心报错","slug":"Dubbo由于连接不上monitor监控中心报错","date":"2019-05-08T23:38:49.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/9008dc8b.html","link":"","permalink":"https://blog.ydstudio.net/post/9008dc8b.html","excerpt":"dubbbo使用时候没有启动监控中心，不能配了监控地址。","text":"dubbbo使用时候没有启动监控中心，不能配了监控地址。 12345678910111213141516com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method collect in the service com.alibaba.dubbo.monitor.MonitorService. No provider available for the service com.alibaba.dubbo.monitor.MonitorService from registry localhost:2181 on the consumer 10.23.144.194 using the dubbo version 2.6.2. Please check if the providers have been started and registered. at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.checkInvokers(AbstractClusterInvoker.java:257) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:56) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:238) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:75) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:52) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.common.bytecode.proxy0.collect(proxy0.java) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.monitor.dubbo.DubboMonitor.send(DubboMonitor.java:112) ~[dubbo-2.6.2.jar:2.6.2] at com.alibaba.dubbo.monitor.dubbo.DubboMonitor$1.run(DubboMonitor.java:69) ~[dubbo-2.6.2.jar:2.6.2] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304) [na:1.7.0_80] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_80] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_80] 解决方案：这是因为没有启动监控中心，却配了监控地址，把监控中心启动，或者把xml配置中的&lt;dubbo:monitor protocol=”registry”&gt;或properties配置中的dubbo.monitor.protocol=registry去掉，即可。","categories":[],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://blog.ydstudio.net/tags/dubbo/"}]},{"title":"Java中ListIterator和Iterator的异同","slug":"Java中ListIterator和Iterator的异同","date":"2019-05-08T23:37:09.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/5da32797.html","link":"","permalink":"https://blog.ydstudio.net/post/5da32797.html","excerpt":"在使用Java集合的时候，都需要使用Iterator。但是java集合中还有一个迭代器ListIterator,在使用List、ArrayList、LinkedList和Vector的时候可以使用。这两种迭代器有什么区别呢？下面我们详细分析。这里有一点需要明确的时候，迭代器指向的位置是元素之前的位置。","text":"在使用Java集合的时候，都需要使用Iterator。但是java集合中还有一个迭代器ListIterator,在使用List、ArrayList、LinkedList和Vector的时候可以使用。这两种迭代器有什么区别呢？下面我们详细分析。这里有一点需要明确的时候，迭代器指向的位置是元素之前的位置。 首先看一下Iterator和ListIterator迭代器的方法有哪些。 Iterator迭代器包含的方法有： hasNext()：如果迭代器指向位置后面还有元素，则返回 true，否则返回false next()：返回集合中Iterator指向位置后面的元素 remove()：删除集合中Iterator指向位置后面的元素 ListIterator迭代器包含的方法有： add(E e): 将指定的元素插入列表，插入位置为迭代器当前位置之前 hasNext()：以正向遍历列表时，如果列表迭代器后面还有元素，则返回 true，否则返回false hasPrevious():如果以逆向遍历列表，列表迭代器前面还有元素，则返回 true，否则返回false next()：返回列表中ListIterator指向位置后面的元素 nextIndex():返回列表中ListIterator所需位置后面元素的索引 previous():返回列表中ListIterator指向位置前面的元素 previousIndex()：返回列表中ListIterator所需位置前面元素的索引 remove():从列表中删除next()或previous()返回的最后一个元素（有点拗口，意思就是对迭代器使用hasNext()方法时，删除ListIterator指向位置后面的元素；当对迭代器使用hasPrevious()方法时，删除ListIterator指向位置前面的元素） set(E e)：从列表中将next()或previous()返回的最后一个元素返回的最后一个元素更改为指定元素e 相同点都是迭代器，当需要对集合中元素进行遍历不需要干涉其遍历过程时，这两种迭代器都可以使用。 不同点 使用范围不同，Iterator可以应用于所有的集合，Set、List和Map和这些集合的子类型。而ListIterator只能用于List及其子类型。 ListIterator有add方法，可以向List中添加对象，而Iterator不能。 ListIterator和Iterator都有hasNext()和next()方法，可以实现顺序向后遍历，但是ListIterator有hasPrevious()和previous()方法，可以实现逆向（顺序向前）遍历。Iterator不可以。 ListIterator可以定位当前索引的位置，nextIndex()和previousIndex()可以实现。Iterator没有此功能。 都可实现删除操作，但是ListIterator可以实现对象的修改，set()方法可以实现。Iterator仅能遍历，不能修改。 1234567891011121314151617181920212223ArrayList&lt;String&gt; stringArrayList1 = new ArrayList&lt;String&gt;(); ArrayList&lt;String&gt; stringArrayList2 = new ArrayList&lt;String&gt;(); stringArrayList1.add(\"ok\"); stringArrayList1.add(\"hello\"); stringArrayList1.add(\"world\"); stringArrayList2.add(\"好的\"); stringArrayList2.add(\"你好\"); stringArrayList2.add(\"世界\"); stringArrayList1.addAll(stringArrayList2); ListIterator&lt;String&gt; iterator = stringArrayList1.listIterator(); System.out.println(\"从前往后输出:\"); while (iterator.hasNext())&#123; System.out.println(\"next=\"+iterator.next()); &#125; System.out.println(\"\\r\\n从后往前输出:\"); while (iterator.hasPrevious())&#123; System.out.println(\"previous=\"+iterator.previous()); &#125; 注意：一定要先进行由前向后输出，之后才能进行由后向前的输出。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"ListIterator","slug":"ListIterator","permalink":"https://blog.ydstudio.net/tags/ListIterator/"},{"name":"Iterator","slug":"Iterator","permalink":"https://blog.ydstudio.net/tags/Iterator/"}]},{"title":"深入理解spring注解之@Bean注解","slug":"深入理解spring注解之-Bean注解","date":"2019-04-23T23:36:01.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/2d1810c4.html","link":"","permalink":"https://blog.ydstudio.net/post/2d1810c4.html","excerpt":"@Bean是一个方法级别上的注解，主要用在@Configuration注解的类里，也可以用在@Component注解的类里。添加的bean的id为方法名。","text":"@Bean是一个方法级别上的注解，主要用在@Configuration注解的类里，也可以用在@Component注解的类里。添加的bean的id为方法名。 12345678910111213141516171819202122@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Bean &#123; @AliasFor(\"name\") String[] value() default &#123;&#125;; @AliasFor(\"value\") String[] name() default &#123;&#125;; Autowire autowire() default Autowire.NO; String initMethod() default \"\"; String destroyMethod() default \"(inferred)\";&#125;value -- bean别名和name是相互依赖关联的，value,name如果都使用的话值必须要一致name -- bean名称，如果不写会默认为注解的方法名称autowire -- 自定装配默认是不开启的，建议尽量不要开启，因为自动装配不能装配基本数据类型、字符串、数组等，这是自动装配设计的局限性，以及自动装配不如显示依赖注入精确initMethod -- bean的初始化之前的执行方法，该参数一般不怎么用，因为可以完全可以在代码中实现destroyMethod -- bean销毁执行的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190package net.ydstudio.practise.bean;import org.springframework.context.annotation.*;/** * 功能描述:&lt;br/&gt; * @Bean意思是定义一个bean，该注解是一个方法级别上的注解，可以使用在@Configuration的类里，也可以 * 在@Component注解的类里，添加的bean的id为方法的名称 * * @Date 2019/4/23 19:36 */@Configurationpublic class AppConfig &#123; /** * * 下面的代码就相当于在xml之中添加下面的配置 * &lt;beans&gt; * &lt;bean id=\"transferService\" class=\"net.ydstudio.practise.bean.TransferServiceImpl“ &gt;&lt;/bean&gt; * &lt;/beans&gt; * * 还能够使用@Scope注解来指定使用@Bean定义的bean * singleton : 单例，整个应用中只存在一个实例bean * prototype ： 与单例相对，每次getBean都会重新生成一个Bean。 * request ： web环境下，每个请求都会创建一个bean，在一次请求中只存在一个Bean，不同request的bean不同 * session ： web环境下，session生命周期下，获取的是同一个bean * * 默认情况下，所有单实例bean都会在创建spring容器的时候创建， * 如果在bean第一次使用的时候创建，我们称为懒加载 * 配置很简单，在创建bean的方法上添加@Lazy注解即可 * * @return net.ydstudio.practise.bean.TransferService * @date 2019/4/23 19:41 */ @Bean @Lazy @Scope(\"singleton\") public TransferService transferService()&#123; return new TransferServiceImpl(); &#125; /** * @Bean可以依赖其他任意数量的bean，如果TransferService依赖Foo，我们可以通过方法参数实现这个依赖 * * @param: foo * @return net.ydstudio.practise.bean.TransferService * @date 2019/4/24 11:23 */ @Bean public TransferService transferService(Foo foo)&#123; return new TransferServiceImpl(foo); &#125; /** * * 任何使用@Bean定义的bean，也可以执行生命周期的回调函数 * 类似@PostConstruct and @PreDestroy的方法 * * @return net.ydstudio.practise.bean.Foo * @date 2019/4/23 19:49 */ @Bean(initMethod = \"init\") public Foo foo()&#123; return new Foo(); &#125; /** * 任何使用@Bean定义的bean，也可以执行生命周期的回调函数 * 类似@PostConstruct and @PreDestroy的方法 * @param: * @return net.ydstudio.practise.bean.Bar * @date 2019/4/23 19:50 */ @Bean(destroyMethod = \"cleanUp\") public Bar bar()&#123; return new Bar(); &#125; /** * * 默认情况下bean的名称和方法名称相同，你也可以使用 * 注解中的name属性进行指定 * * @param: * @return net.ydstudio.practise.bean.Foo * @date 2019/4/23 19:52 */ @Bean(name = \"myFoo\") public Foo getFoo()&#123; return new Foo(); &#125; /** * 可以通过某些条件，来选择是否注册Bean，通过@Condition注解来实现 * 实现Condition接口，并重写matches方法，根据该方法返回的布尔值来决定是否注册Bean * @return net.ydstudio.practise.bean.Book * @date 2019/4/24 11:54 */ @Bean @Conditional(MyCondition.class) public Book book()&#123; return new Book(); &#125;&#125;public class Bar &#123; public void cleanUp()&#123; System.out.println(\"---111111cleanUp---\"); &#125; @Override public String toString() &#123; final StringBuffer sb = new StringBuffer(\"Bar&#123;\"); sb.append('&#125;'); return sb.toString(); &#125;&#125;public class Book &#123; private String name; private BigDecimal price; private Date publishDate; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public BigDecimal getPrice() &#123; return price; &#125; public void setPrice(BigDecimal price) &#123; this.price = price; &#125; public Date getPublishDate() &#123; return publishDate; &#125; public void setPublishDate(Date publishDate) &#123; this.publishDate = publishDate; &#125;&#125;public class Foo &#123; public void init()&#123; System.out.println(\"初始化之前---init---初始化之前\"); &#125; @Override public String toString() &#123; final StringBuffer sb = new StringBuffer(\"Foo&#123;\"); sb.append('&#125;'); return sb.toString(); &#125;&#125;public class MyCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; /** * 根据环境变量是否存在my.env=hello的属性来决定是否创建， * 可以通过启动参数指定-Dmy.env=hello来测试。 **/ Environment environment = conditionContext.getEnvironment(); String property = environment.getProperty(\"my.env\"); if (\"hello\".equals(property)) &#123; return true; &#125; return false; &#125;&#125;public interface TransferService &#123;&#125;public class TransferServiceImpl implements TransferService&#123; private Foo foo; public TransferServiceImpl(Foo foo) &#123; this.foo = foo; &#125; public TransferServiceImpl() &#123; &#125;&#125;","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"https://blog.ydstudio.net/tags/spring/"},{"name":"bean","slug":"bean","permalink":"https://blog.ydstudio.net/tags/bean/"}]},{"title":"idea自动生成方法注释（含参数及返回值）","slug":"idea自动生成方法注释（含参数及返回值）","date":"2019-04-22T23:35:02.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/526abd46.html","link":"","permalink":"https://blog.ydstudio.net/post/526abd46.html","excerpt":"程序员到新的公司上班，拿到新电脑当然要第一时间配置好各种开发环境和开发工具。","text":"程序员到新的公司上班，拿到新电脑当然要第一时间配置好各种开发环境和开发工具。 在idea中打开设置，选择File-&gt;settings-&gt;Editor-&gt;Live Templates点击”+”-&gt;选择template group ，然后输入group的name，如annotation。然后，选中刚才创建的myGroup，然后再次点击右侧的绿色+，这次选择的是Live Template。取名（Abbreviation）为*。Description中填写”方法注释” 配置模板选择刚刚添加的Live Template，在下面的Text Template中添加下面的内容，注意不要整理下面的格式。 12345678* * * $VAR1$ $params$ * @return $returns$ * @author 19037900@xx.cn * @date $date$ $time$ */ 注意：此处一定要为刚刚的模板指定使用范围,选择全部就行了。 配置variables，点击 Edit variablesVAR1参数不用管params (网上好多都不行，这个是我正在用的) 1groovyScript(\"def result=''; def params=\\\"$&#123;_1&#125;\\\".replaceAll('[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]', '').split(',').toList(); for(i = 0; i &lt; params.size(); i++) &#123;result+='* @'+'param: ' + params[i] + ((i &lt; params.size() - 1) ? '\\\\n'+'\\\\b' : '')&#125;; return result\", methodParameters()) returns参数可以下拉，选择methodReturnType();date参数可以下拉，选择date();time参数可以下拉，选择time(); 配置快捷键，点击Edit variables下面的Options中的Expand with下拉选择Enter。开始使用输入 /**，然后Enter，大功告成","categories":[],"tags":[{"name":"idea","slug":"idea","permalink":"https://blog.ydstudio.net/tags/idea/"}]},{"title":"Window下搭建Redis高可用集群-哨兵模式（Redis-Sentinel）","slug":"Window下搭建Redis高可用集群-哨兵模式（Redis-Sentinel","date":"2019-02-28T23:32:15.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/bdbc3b8a.html","link":"","permalink":"https://blog.ydstudio.net/post/bdbc3b8a.html","excerpt":"Sentinel的分布式特性Redis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移， 以及选择哪个从服务器作为新的主服务器。","text":"Sentinel的分布式特性Redis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移， 以及选择哪个从服务器作为新的主服务器。 单个sentinel进程来监控redis集群是不可靠的，当sentinel进程宕掉后(sentinel本身也有单点问题，single-point-of-failure)整个集群系统将无法按照预期的方式运行。所以有必要将sentinel集群，这样有几个好处： 有一些sentinel进程宕掉了，依然可以进行redis集群的主备切换； 如果只有一个sentinel进程，如果这个进程运行出错，或者是网络堵塞，那么将无法实现redis集群的主备切换（单点问题）； 如果有多个sentinel，redis的客户端可以随意地连接任意一个sentinel来获得关于redis集群中的信息； 一个健壮的部署至少需要三个哨兵实例。三个哨兵实例应该放置在客户使用独立方式确认故障的计算机或虚拟机中。例如不同的物理机或不同可用区域的虚拟机。 开始准备环境搭建：本次在window上搭建哨兵模式的Redis集群。按照上一篇文章Redis主从复制的指导，先搭建好Redis的集群，具体情况如下：在git上下载好window下的Redis免安装的包，解压配置好之后，再复制两份，端口号分别为6380和6381，Redis安装目录则分别为redis6379、redis6380、redis6381. 127.0.0.1 6379 master 127.0.0.1 6380 slave 127.0.0.1 6381 slave 127.0.0.1:26379 127.0.0.1:26380 127.0.0.1:26381 sentinel Redis的密码都设置成requirepass 123456 配置Sentinel在上述三个Redis安装目录下新建sentinel.conf文件，在其中写入以下内容： 1234567891011121314# 这个是Redis6379配置内容，其他文件同理新增然后改一下端口即可，26380，和 26381。#当前Sentinel服务运行的端口port 26379 # 哨兵监听的主服务器 sentinel monitor mymaster 127.0.0.1 6379 2# 3s内mymaster无响应，则认为mymaster宕机了sentinel down-after-milliseconds mymaster 3000#如果10秒后,mysater仍没启动过来，则启动failover sentinel failover-timeout mymaster 10000 # 执行故障转移时， 最多有1个从服务器同时对新的主服务器进行同步sentinel parallel-syncs mymaster 1# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster 123456 在另外的两个Redis目录里面分别创建sentinel.conf，注意修改其中port端口分26380和26381。配置文件只需要配置master的信息就好啦，不用配置slave的信息，因为slave能够被自动检测到(master节点中有关于slave的消息)。 为了更清楚每一行配置的含义，对每个选项的含义进行简单介绍： 1sentinel monitor [master-group-name] [ip] [port] [quorum] master-group-name：master名称（可以自定义） ip port : IP地址和端口号 quorum：票数，Sentinel需要协商同意master是否可到达的数量。 第一行配置指示 Sentinel 去监视一个名为 mymaster 的主服务器， 这个主服务器的 IP 地址为 127.0.0.1 ， 端口号为 6379 ， 而将这个主服务器判断为失效至少需要 2 个 Sentinel 同意 （只要同意 Sentinel 的数量不达标，自动故障迁移就不会执行）。票数在本文中：redis集群中有3个sentinel实例，其中master挂掉啦，这里设置票数为2，表示有2个sentinel认为master挂掉啦，才能被认为是正真的挂掉啦。 1sentinel &lt;选项的名字&gt; &lt;主服务器的名字&gt; &lt;选项的值&gt; down-after-milliseconds 选项指定了 Sentinel 认为服务器已经断线所需的毫秒数。 如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 将这个服务器标记为主观下线（subjectively down，简称 SDOWN ）。不过只有一个 Sentinel 将服务器标记为主观下线并不一定会引起服务器的自动故障迁移： 只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（objectively down， 简称 ODOWN ）， 这时自动故障迁移才会执行。将服务器标记为客观下线所需的 Sentinel 数量由对主服务器的配置决定。 parallel-syncs 选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。 新增Redis启动脚本：startRedisServer.bat123@echo offredis-server.exe redis.conf@pause 新增Redis-Sentinel启动脚本：startRedisSentinel.bat123@echo offredis-server.exe sentinel.conf --sentinel @pause 另外两个进行同样的操作，创建新增Redis启动脚本和Redis-Sentinel启动脚本。 开始启动环境 点击startRedis.bat，启动Redis集群 点击startRedisSentinel.bat，启动哨兵实例 搭建中出现的问题 sentinel配置文件的顺序问题 12345678[3968] 01 Mar 11:06:38.314 #*** FATAL CONFIG FILE ERROR ***[3968] 01 Mar 11:06:38.314 # Reading the configuration file, at line 10[3968] 01 Mar 11:06:38.314 # &gt;&gt;&gt; 'sentinel down-after-milliseconds mymaster 3000'[3968] 01 Mar 11:06:38.314 # No such master with specified name. 解决方法：哨兵监听的主服务器的配置 1sentinel monitor mymaster 127.0.0.1 6379 2 要尽量放到sentinel配置的前面 配置文件的空格问题 1Invalid argument during startup: unknown conf file parameter : 解决方法：删除或者更改配置注意不要留有空格 未完","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://blog.ydstudio.net/tags/redis/"},{"name":"Redis-Sentinel","slug":"Redis-Sentinel","permalink":"https://blog.ydstudio.net/tags/Redis-Sentinel/"}]},{"title":"Linux下搭建Redis主从复制","slug":"Linux下搭建Redis主从复制","date":"2019-02-27T23:30:02.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/c1608171.html","link":"","permalink":"https://blog.ydstudio.net/post/c1608171.html","excerpt":"最近忙着准备面试，就把之前用到的Redis的主从配置和哨兵模式配置都重新复习一遍。这篇文章先复习配置Redis的主从，下一篇复习Redis的哨兵模式。Redis的主从复制配置起来比较简单，主从配置有以下特点：","text":"最近忙着准备面试，就把之前用到的Redis的主从配置和哨兵模式配置都重新复习一遍。这篇文章先复习配置Redis的主从，下一篇复习Redis的哨兵模式。Redis的主从复制配置起来比较简单，主从配置有以下特点： 一个Master可以有多个slave主机，支持链式复制 Master以非阻塞方式同步数据至slave主机 在一台节点上配置文件中定义自己是谁的从节点，并且启用主节点密码认证即可。下面使用3台主机配置一主两从的结构，redis使用一主多从的结构时还可以实现像mysql MHA那样的复制集群，当master节点宕机后，可以在两个slave节点中根据优先级选举新的master。 安装Redis本次采用源码编译的方式安装Redis，执行相关的命令如下：123456789101112131415161718192021#下载redis安装包cd /usr/local/srcwget http://download.redis.io/releases/redis-5.0.3.tar.gz#解压安装包tar -zxvf redis-5.0.3.tar.gz#拷贝到/usr/local/redis目录mkdir -p /usr/local/redis#编译安装make &amp; make install#redis安装完成后，redis-server、redis-cli等程序默认安装在/usr/local/redis/src目录中，我们需要将它安装到系统搜索路径，并安装为系统服务，方便在任何终端访问，并且开机自动启动。cd /usr/local/src/redis/utils./install_server.sh#重复上述安装操作，安装redis到6380和6381端口./install_server.sh 环境准备好之后，具体情况如下： 三个Redis实例分别安装以下IP地址和端口，角色分别如下 192.168.1.103 6379 master192.168.1.103 6380 slave192.168.1.103 6381 slave 配置Master节点1234bind 0.0.0.0 #绑定地址 (绑定在127.0.0.1，只有本机客户端可以访问，其他服务器无法访问，绑定在0.0.0.0上，如果没有端口限制，那么其他服务器则可以连接该服务器的该端口)requirepass 123456 #启用密码认证#默认master节点修改这两项就可以了，也可以进行其他设置 配置Slave节点 1234567bind 0.0.0.0 #定义master信息slaveof 192.168.1.103 6379 #认证masterauth 123456 #从节点上配置这三项页就可以，其他参数可以根据情况选择调整即可。 修改后记得重启服务，可以登录到master节点查看信息。 首先使用client list命令查看 12345678910[root@192 bin]# redis-cli -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.127.0.0.1:6379&gt; client listid=3 addr=127.0.0.1:44273 fd=7 name= age=2456 idle=1 flags=S db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=replconfid=4 addr=127.0.0.1:45342 fd=8 name= age=2453 idle=1 flags=S db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=replconfid=6 addr=127.0.0.1:49306 fd=9 name= age=6 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client127.0.0.1:6379&gt; cmd=client 表示是mastercmd=replconf 表示是slave 首先使用info replication 命令查看123456789101112131415127.0.0.1:6379&gt; info replication# Replicationrole:master #自己的角色connected_slaves:2 #从节点数量slave0:ip=127.0.0.1,port=6380,state=online,offset=3738,lag=0 #从节点信息slave1:ip=127.0.0.1,port=6381,state=online,offset=3738,lag=1 #从节点信息master_replid:061bcdd36e3b8d9a0c38d29dc762e908445baad6master_replid2:0000000000000000000000000000000000000000master_repl_offset:3738second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:3738127.0.0.1:6379&gt; 可以看到主从差不多已经配置好了，接下来可以进行简单的验证复制，在master节点设置一个key，看两个slave节点复制情况。 Master节点创建一个key: 12345[root@192 bin]# redis-cli -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.127.0.0.1:6379&gt; set jobNo 123456OK127.0.0.1:6379&gt; 从slave 6380 : 12345[root@192 bin]# redis-cli -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.127.0.0.1:6380&gt; get jobNo\"123456\"127.0.0.1:6380&gt; 从slave 6381： 12345[root@192 bin]# redis-cli -p 6381 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.127.0.0.1:6381&gt; get jobNo\"123456\"127.0.0.1:6381&gt; 可以看出在master上设置的key已经同步到了两个slave上。 slave节点定义也可以通过指令设置，设置后立即生效，并且会被保存至配置文件中，指令配置方式如下： #配置slave节点 12redis-cli&gt; SLAVEOF &lt;MASTER_IP&gt; &lt;MASTER_PORT&gt;redis-cli&gt; CONFIG SET masterauth &lt;PASSWORD&gt; redis主从复制相关配置下面是redis主从复制场景的一些可调参数，需要根据实际环境调整 slave-serve-stale-data yes ： 是否可以把不新鲜的数据服务与客户端 slave-read-only yes ： 从节点只读，启用slaveof定义后才生效 repl-diskless-sync no ：是否同时向多个从节点同时发数据 repl-diskless-sync-delay 5 ：发送的延迟时间 repl-ping-slave-period 10 探测从节点状态 repl-timeout 60 探测节点超时时间 repl-disable-tcp-nodelay no ： 启用nodelay repl-backlog-size 1mb slave-priority 100 ： 从节点优先级,复制集群中，主节点故障时，sentinel应用场景中的主节点选举时使用的优先级；数字越小优先级越高，但0表示不参与选举； min-slaves-to-write 3：主节点仅允许其能够通信的从节点数量大于等于此处的值时接受写操作； min-slaves-max-lag 10：从节点延迟时长超出此处指定的时长时，主节点会拒绝写入操作； 查看原文","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"redis","slug":"redis","permalink":"https://blog.ydstudio.net/tags/redis/"},{"name":"主从复制","slug":"主从复制","permalink":"https://blog.ydstudio.net/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"}]},{"title":"Nginx代理时header头中带_的信息丢失的问题","slug":"Nginx代理时header头中带-的信息丢失的问题","date":"2019-02-01T23:28:37.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/a6b6fb0a.html","link":"","permalink":"https://blog.ydstudio.net/post/a6b6fb0a.html","excerpt":"开发网关项目时，在请求时往请求头header中放入了签名sign_key信息，在接收请求时再从header中拿出，在本地调试时是可以的，但上线之后通过Nginx代理之后发现拿不到。","text":"开发网关项目时，在请求时往请求头header中放入了签名sign_key信息，在接收请求时再从header中拿出，在本地调试时是可以的，但上线之后通过Nginx代理之后发现拿不到。 123456789101112location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; add_header Proxy-Node $upstream_addr; add_header Proxy-Status $upstream_status; proxy_http_version 1.1; proxy_pass http://tianusa; &#125; 后来找到原因是因为Nginx对header有所限制，下划线（_）不支持 1.不用下划线把下划线_改成其他的，如sign_key改成sign-key 2.从根本解除Nginx的限制Nginx默认request的header的那么中包含’_’时，会自动忽略掉。解决方法是：在nginx里的nginx.conf配置文件中的http部分中添加如下配置： 1underscores_in_headers on; （默认 underscores_in_headers 为off）","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"}]},{"title":"Mybatis Generator最完整配置详解","slug":"Mybatis-Generator最完整配置详解","date":"2019-01-29T23:27:40.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/a9e1e2fd.html","link":"","permalink":"https://blog.ydstudio.net/post/a9e1e2fd.html","excerpt":"这是一份Mybatis Generator最完整配置详解，大家可以好好看看。","text":"这是一份Mybatis Generator最完整配置详解，大家可以好好看看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\"\"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;!-- 配置生成器 --&gt;&lt;generatorConfiguration&gt;&lt;!-- 可以用于加载配置项或者配置文件，在整个配置文件中就可以使用$&#123;propertyKey&#125;的方式来引用配置项 resource：配置资源加载地址，使用resource，MBG从classpath开始找，比如com/myproject/generatorConfig.properties url：配置资源加载地质，使用URL的方式，比如file:///C:/myfolder/generatorConfig.properties. 注意，两个属性只能选址一个; 另外，如果使用了mybatis-generator-maven-plugin，那么在pom.xml中定义的properties都可以直接在generatorConfig.xml中使用&lt;properties resource=\"\" url=\"\" /&gt; --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包 location属性指明加载jar/zip包的全路径&lt;classPathEntry location=\"/Program Files/IBM/SQLLIB/java/db2java.zip\" /&gt; --&gt; &lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG--&gt;&lt;context id=\"mysql\" defaultModelType=\"hierarchical\" targetRuntime=\"MyBatis3Simple\" &gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name=\"autoDelimitKeywords\" value=\"false\"/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name=\"javaFileEncoding\" value=\"UTF-8\"/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name=\"javaFormatter\" value=\"org.mybatis.generator.api.dom.DefaultJavaFormatter\"/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name=\"xmlFormatter\" value=\"org.mybatis.generator.api.dom.DefaultXmlFormatter\"/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;property name=\"beginningDelimiter\" value=\"`\"/&gt; &lt;property name=\"endingDelimiter\" value=\"`\"/&gt; &lt;!-- 必须要有的，使用这个配置链接数据库 @TODO:是否可以扩展 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql:///pss\" userId=\"root\" password=\"admin\"&gt; &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 --&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type=\"org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl\"&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage=\"com._520it.mybatis.domain\" targetProject=\"src/main/java\"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name=\"constructorBased\" value=\"false\"/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;property name=\"immutable\" value=\"false\"/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;property name=\"rootClass\" value=\"com._520it.mybatis.domain.BaseDomain\"/&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成SQL map的XML文件生成器， 注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口）， 或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置 targetPackage/targetProject:同javaModelGenerator --&gt; &lt;sqlMapGenerator targetPackage=\"com._520it.mybatis.mapper\" targetProject=\"src/main/resources\"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;javaClientGenerator targetPackage=\"com._520it.mybatis.mapper\" type=\"ANNOTATEDMAPPER\" targetProject=\"src/main/java\"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name=\"rootInterface\" value=\"\"/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的\"\"把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers=\"true\"即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName=\"userinfo\" &gt; &lt;!-- 参考 javaModelGenerator 的 constructorBased属性--&gt; &lt;property name=\"constructorBased\" value=\"false\"/&gt; &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； --&gt; &lt;property name=\"ignoreQualifiersAtRuntime\" value=\"false\"/&gt; &lt;!-- 参考 javaModelGenerator 的 immutable 属性 --&gt; &lt;property name=\"immutable\" value=\"false\"/&gt; &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 --&gt; &lt;property name=\"modelOnly\" value=\"false\"/&gt; &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 &lt;property name=\"rootClass\" value=\"\"/&gt; --&gt; &lt;!-- 参考javaClientGenerator 的 rootInterface 属性 &lt;property name=\"rootInterface\" value=\"\"/&gt; --&gt; &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog &lt;property name=\"runtimeCatalog\" value=\"\"/&gt; --&gt; &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema &lt;property name=\"runtimeSchema\" value=\"\"/&gt; --&gt; &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename &lt;property name=\"runtimeTableName\" value=\"\"/&gt; --&gt; &lt;!-- 注意，该属性只针对MyBatis3Simple有用； 如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； --&gt; &lt;property name=\"selectAllOrderByClause\" value=\"age desc,username asc\"/&gt; &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN_DATE，生成的属性名字就是BORN_DATE,而不会是bornDate --&gt; &lt;property name=\"useActualColumnNames\" value=\"false\"/&gt; &lt;!-- generatedKey用于生成生成主键的方法， 如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选 column:主键的列名； sqlStatement：要生成的selectKey语句，有以下可选项： Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2 :相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2_MF :相当于selectKey的SQL为：SELECT IDENTITY_VAL_LOCAL() FROM SYSIBM.SYSDUMMY1 Derby :相当于selectKey的SQL为：VALUES IDENTITY_VAL_LOCAL() HSQLDB :相当于selectKey的SQL为：CALL IDENTITY() Informix :相当于selectKey的SQL为：select dbinfo('sqlca.sqlerrd1') from systables where tabid=1 MySql :相当于selectKey的SQL为：SELECT LAST_INSERT_ID() SqlServer :相当于selectKey的SQL为：SELECT SCOPE_IDENTITY() SYBASE :相当于selectKey的SQL为：SELECT @@IDENTITY JDBC :相当于在生成的insert元素上添加useGeneratedKeys=\"true\"和keyProperty属性 &lt;generatedKey column=\"\" sqlStatement=\"\"/&gt; --&gt; &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候， 比如列名为：CUST_ID,CUST_NAME,CUST_EMAIL,CUST_ADDRESS等； 那么就可以设置searchString为\"^CUST_\"，并使用空白替换，那么生成的Customer对象中的属性名称就不是 custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email； 注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的， 如果使用了columnOverride元素，该属性无效； &lt;columnRenamingRule searchString=\"\" replaceString=\"\"/&gt; --&gt; &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性； column:要重新设置的列名； 注意，一个table元素中可以有多个columnOverride元素哈~ --&gt; &lt;columnOverride column=\"username\"&gt; &lt;!-- 使用property属性来指定列要生成的属性名称 --&gt; &lt;property name=\"property\" value=\"userName\"/&gt; &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名 &lt;property name=\"javaType\" value=\"\"/&gt; --&gt; &lt;!-- jdbcType用于指定该列的JDBC类型 &lt;property name=\"jdbcType\" value=\"\"/&gt; --&gt; &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名 注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler 只会生成类似：where id = #&#123;id,jdbcType=BIGINT,typeHandler=com._520it.mybatis.MyTypeHandler&#125;的参数描述 &lt;property name=\"jdbcType\" value=\"\"/&gt; --&gt; &lt;!-- 参考table元素的delimitAllColumns配置，默认为false &lt;property name=\"delimitedColumnName\" value=\"\"/&gt; --&gt; &lt;/columnOverride&gt; &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 column:指定要忽略的列的名字； delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false 注意，一个table元素中可以有多个ignoreColumn元素 &lt;ignoreColumn column=\"deptId\" delimitedColumnName=\"\"/&gt; --&gt; &lt;/table&gt; &lt;/context&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://blog.ydstudio.net/tags/mybatis/"}]},{"title":"Java实现二分查找算法","slug":"Java实现二分查找算法","date":"2019-01-25T23:26:42.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/e486e255.html","link":"","permalink":"https://blog.ydstudio.net/post/e486e255.html","excerpt":"二分法查找，也称为折半法，是一种在有序数组中查找特定元素的搜索算法。所以在采用二分法查找时，数据需是有序不重复的，如果是无序的也可通过选择排序、冒泡排序等数组排序方法进行排序之后，就可以使用二分法查找。 基本思想：假设数据是按升序排序的，对于给定值 x，从序列的中间位置开始比较，如果当前位置值等于 x，则查找成功；若 x 小于当前位置值，则在数列的前半段中查找；若 x 大于当前位置值则在数列的后半段中继续查找，直到找到为止，但是如果当前段的索引最大值小于当前段索引最小值，说明查找的值不存在，返回-1，不继续查找。","text":"二分法查找，也称为折半法，是一种在有序数组中查找特定元素的搜索算法。所以在采用二分法查找时，数据需是有序不重复的，如果是无序的也可通过选择排序、冒泡排序等数组排序方法进行排序之后，就可以使用二分法查找。 基本思想：假设数据是按升序排序的，对于给定值 x，从序列的中间位置开始比较，如果当前位置值等于 x，则查找成功；若 x 小于当前位置值，则在数列的前半段中查找；若 x 大于当前位置值则在数列的后半段中继续查找，直到找到为止，但是如果当前段的索引最大值小于当前段索引最小值，说明查找的值不存在，返回-1，不继续查找。 下面贴出代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.ArrayList;import java.util.LinkedList;import java.util.List;/** * Created by Sam on 18/12/9. */public class Test &#123; public static void main(String[] args) &#123; int[] array = &#123;1,4,7,9,12,56,78,89,120,179,180,200,290&#125;; System.out.println(\"index=\"+binarySearch(array,290)); &#125; public static int binarySearch(int[] array,int searchNumber)&#123; int minIndex = 0; int maxIndex = array.length - 1; int searchIndex = (minIndex + maxIndex) &gt;&gt; 1 ; int count = 0; while (array[searchIndex] != searchNumber)&#123; System.out.printf(\"第次%d次运算\\n\", ++count); if (array[searchIndex] &gt; searchNumber)&#123; maxIndex = searchIndex - 1 ; &#125;else &#123; minIndex = searchIndex + 1 ; &#125; if (minIndex&gt;maxIndex)&#123; return -1; &#125; searchIndex = (minIndex + maxIndex) &gt;&gt; 1 ; &#125; return searchIndex; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"二分法","slug":"二分法","permalink":"https://blog.ydstudio.net/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"}]},{"title":"PowerDesigner生成SQL时注释为name和comment合并后的内容","slug":"PowerDesigner生成SQL时注释为name和comment合并后的内容","date":"2019-01-18T23:25:42.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/26129f65.html","link":"","permalink":"https://blog.ydstudio.net/post/26129f65.html","excerpt":"PowerDesigner生成SQL时的注释默认是没有name字段的，网上讲的设置方法大部分都是只能用name或者comment，无法将两者合并使用。但是有时候我们需要name和comment字段合并起来加到注释中，则可以通过下面的方法来实现。","text":"PowerDesigner生成SQL时的注释默认是没有name字段的，网上讲的设置方法大部分都是只能用name或者comment，无法将两者合并使用。但是有时候我们需要name和comment字段合并起来加到注释中，则可以通过下面的方法来实现。 第一步：修改SQL的生成脚本 选择菜单：database -&gt; edit current DBMS… 选择general选项卡：script -&gt; objects -&gt; column -&gt; columncommnet 修改value值为： 重点就是下面这个脚本了，本人对脚本语法不熟悉，经过各种尝试，最终脚本如下123456alter table %TABLE% modify column [%QUALIFIER%] %TABLE%.%COLUMN% %DATATYPE%[%Unsigned%? unsigned][%ZeroFill%? zerofill][.Z:[ %NOTNULL%][%R%?[%PRIMARY%]][%IDENTITY%? auto_increment:[ default %DEFAULT%]]] comment.if (%COMMENT%==%COLNNAME%) '%COLNNAME%'.else '%COLNNAME% %COMMENT%'.endif(\\n) 第二步：修改生成规则当第一步的脚本修改后就可以显示name为注释了，但是comment为空的则不能生成注释，需要修改生成规则。 选择菜单：database -&gt; generate database… 选择format选项卡，选中”generate name is empty comment”选项 点“应用”按钮保存设置 第一次实现这种效果，不是通过这种方式，换了新的机器之后，之前那种方法找不到了，就通过查找资料用这种方式实现了","categories":[],"tags":[{"name":"PowerDesigner","slug":"PowerDesigner","permalink":"https://blog.ydstudio.net/tags/PowerDesigner/"}]},{"title":"Snowflake算法生成分布式系统唯一ID","slug":"Snowflake算法生成分布式系统唯一ID","date":"2019-01-06T23:23:41.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4f74853e.html","link":"","permalink":"https://blog.ydstudio.net/post/4f74853e.html","excerpt":"在复杂的系统中唯一ID是我们在设计的时候常常会遇见的问题，生成ID的方法有很多，适应不同的场景、需求以及性能要求。所以有些比较复杂的系统会有多个ID生成的策略，下面就介绍一些常见的ID生成策略。","text":"在复杂的系统中唯一ID是我们在设计的时候常常会遇见的问题，生成ID的方法有很多，适应不同的场景、需求以及性能要求。所以有些比较复杂的系统会有多个ID生成的策略，下面就介绍一些常见的ID生成策略。 1. 数据库自增长序列或字段最常见的方式。利用数据库，全数据库唯一。 优点： 简单，代码方便，性能可以接受。 数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点： 不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。 在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。 在性能达不到要求的情况下，比较难于扩展。 如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。 优化方案： 针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。 2. UUID UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：550e8400-e29b-41d4-a716-446655440000，到目前为止业界一共有5种方式生成UUID。 优点： 简单，代码方便。 生成ID性能非常好，基本不会有性能问题，本地生成，没有网络消耗。 全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对。 缺点： 不易于存储，UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。MySQL官方有明确的建议主键要尽量越短越好 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 生成ID无序对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。 3. snowflake方案大致来说是一种以划分命名空间（UUID也算，由于比较常见，所以单独分析）来生成ID的一种算法，这种方案把64-bit分别划分成多段，分开来标示机器、时间等，比如在snowflake中的64-bit分别表示如下图所示： 10 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 1bit 表示符号位，表示是正数还是负数，设为正数固定为0 41bit 的时间戳 可以表示( 1L&lt;&lt;41 ) / ( 1000L * 3600 * 24 *365 )=69年的时间。 10bit机器可以分别表示1024台机器。如果我们对IDC划分有需求，还可以将10bit分5bit给IDC，分5bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，可以根据自身需求定义。 12bit可以表示的最大正整数是2^12-1=4095，即可以用0、1、2、3、….4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。 优点： 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 可以根据自身业务特性分配bit位，非常灵活。 缺点： 强依赖机器时钟，在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，还有闰秒的存在，会导致重复或者服务会处于不可用状态。 附上相关的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150package com.dm.tool.util;/** * 通过 snowFlake 雪花算法生成唯一且在时间段内趋势递增的 * 分布式ID * @author Nick * @projectName dm-mt * @package com.dm.tool.util * @createDate 2019/01/17 09:17 * @updateDate 2019/01/17 09:17 */public class SnowFlake&#123; private static volatile SnowFlake instance ; /** * 起始的时间戳 * 从 2019/01/01 00:00:00 开始 */ private final static long START_STMP = 1546272000000L; /** * 序列号占用的位数 */ private final static long SEQUENCE_BIT = 12; /** * 机器标识占用的位数 */ private final static long MACHINE_BIT = 5; /** * 数据中心占用的位数 */ private final static long DATACENTER_BIT = 5; /** * 每一部分的最大值 */ private final static long MAX_DATACENTER_NUM = -1L ^ (-1L &lt;&lt; DATACENTER_BIT); private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT); private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT; /** * 数据中心 */ private long datacenterId; /** * 机器标识 */ private long machineId; /** * 序列号 */ private long sequence = 0L; /** * 上一次时间戳 */ private long lastStmp = -1L; /** * * @param datacenterId 数据中心ID (0~31) * @param machineId workerId 工作ID (0~31) */ private SnowFlake(long datacenterId, long machineId) &#123; if (datacenterId &gt; MAX_DATACENTER_NUM || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"datacenterId can't be greater than %d or less than 0\",MAX_DATACENTER_NUM)); &#125; if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"machineId can't be greater than %d or less than 0\",MAX_MACHINE_NUM)); &#125; this.datacenterId = datacenterId; this.machineId = machineId; &#125; public static SnowFlake getInstance(long datacenterId, long machineId)&#123; if (instance == null)&#123; synchronized (SnowFlake.class)&#123; if (instance == null)&#123; instance = new SnowFlake(datacenterId,machineId); &#125; &#125; &#125; return instance; &#125; /** * 产生下一个ID * * @return */ protected synchronized long nextId() &#123; long currStmp = getNewTimestamp(); if (currStmp &lt; lastStmp) &#123; String msg = String.format(\"Clock moved backwards. Refusing to generate id! currStmp=%d,lastStmp=%d\",currStmp,lastStmp); throw new RuntimeException(msg); &#125; if (currStmp == lastStmp) &#123; // 相同毫秒内，序列号自增 sequence = (sequence + 1) &amp; MAX_SEQUENCE; // 同一毫秒的序列数已经达到最大 if (sequence == 0L) &#123; currStmp = getNextMill(); &#125; &#125; else &#123; // 不同毫秒内，序列号置为0 sequence = 0L; &#125; lastStmp = currStmp; // 时间戳 41 数据中心 5 机器标识 5 序列号 12 return (currStmp - START_STMP) &lt;&lt; TIMESTMP_LEFT | datacenterId &lt;&lt; DATACENTER_LEFT | machineId &lt;&lt; MACHINE_LEFT | sequence; &#125; private long getNextMill() &#123; long mill = getNewTimestamp(); while (mill &lt;= lastStmp) &#123; mill = getNewTimestamp(); &#125; return mill; &#125; private long getNewTimestamp() &#123; return System.currentTimeMillis(); &#125; public static long getSequenceBit() &#123; return SEQUENCE_BIT; &#125; public static long getMachineBit() &#123; return MACHINE_BIT; &#125; public static long getDatacenterBit() &#123; return DATACENTER_BIT; &#125; public static long getStartStmp() &#123; return START_STMP; &#125;&#125; 工具类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.dm.tool.util;import org.apache.commons.lang.StringUtils;import java.math.BigInteger;import java.util.HashSet;import java.util.Set;/** * * snowFlake工具类 * * @author Nick * @projectName dm-mt * @package com.dm.tool.util * @createDate 2019/01/16 09:30 * @updateDate 2019/01/16 09:30 */public class SnowFlakeIDUtil &#123; private static final int radix = 2; /** * 数据中心ID 0，机器ID 0 * @param datacenterId * @param machineId * @return */ public static long getNextId(long datacenterId, long machineId)&#123; return SnowFlake.getInstance(datacenterId,machineId).nextId(); &#125; /** * 获得订单ID生成时的时间戳 * @param id * @return */ public static long getIDTimestamp(long id)&#123; return (id &gt;&gt; SnowFlake.getTimestmpLeft() &amp; ~(-1L &lt;&lt; 41))+SnowFlake.getStartStmp(); &#125; /** * 获取数据中心 ID * @param id * @return */ public static long getDatacenterId(long id)&#123; return id &gt;&gt; SnowFlake.getDatacenterLeft() &amp; ~(-1L &lt;&lt; SnowFlake.getDatacenterBit()); &#125; /** * 获得机器ID * @param id * @return */ public static long getMachineId(long id)&#123; return id &gt;&gt; SnowFlake.getMachineLeft() &amp; ~(-1L &lt;&lt; SnowFlake.getMachineBit()); &#125; /** * 获取序列ID * @param id * @return */ public static long getSequence(long id)&#123; return id &amp; ~(-1L &lt;&lt; SnowFlake.getSequenceBit()); &#125; public static void main(String[] args)&#123; MyThread thread1 = new MyThread(); MyThread thread2 = new MyThread(); MyThread thread3 = new MyThread(); MyThread thread4 = new MyThread(); thread1.start(); thread2.start(); thread3.start(); thread4.start(); &#125; static class MyThread extends Thread&#123; @Override public void run() &#123; while (true)&#123; long id = SnowFlakeIDUtil.getNextId(0,0); System.out.println(\"ID=\"+id+\"时间戳= \"+getIDTimestamp(id)+\" DatacenterId= \"+getDatacenterId(id)+\" MachineId=\"+getMachineId(id)+\" Sequence=\"+getSequence(id)); &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"Snowflake","slug":"Snowflake","permalink":"https://blog.ydstudio.net/tags/Snowflake/"}]},{"title":"使用FastJson进行对象和JSON转换属性命名规则为下划线和驼峰的问题","slug":"使用FastJson进行对象和JSON转换属性命名规则为下划线和驼峰的问题","date":"2018-12-24T23:20:33.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/ff52aa1f.html","link":"","permalink":"https://blog.ydstudio.net/post/ff52aa1f.html","excerpt":"最近在对接支付宝，在编写支付需要的bean的时候，发现支付宝需要传递的参数命名方式都是下划线，自己idea又装了阿里巴巴的编程规约，代码老是有黄色提示，显得特别难看。于是乎我把属性改成了驼峰的命名方式，然后下意识的在上面加了一个@JsonProperty注解实现相互转换过程中属性命名方式也能自动转换。可是我运行代码时发现代码报错运行不起来了。主要代码如下：","text":"最近在对接支付宝，在编写支付需要的bean的时候，发现支付宝需要传递的参数命名方式都是下划线，自己idea又装了阿里巴巴的编程规约，代码老是有黄色提示，显得特别难看。于是乎我把属性改成了驼峰的命名方式，然后下意识的在上面加了一个@JsonProperty注解实现相互转换过程中属性命名方式也能自动转换。可是我运行代码时发现代码报错运行不起来了。主要代码如下： 12345678910111213141516171819202122232425262728public class AliPayParam &#123; @JsonProperty(name=\"out_trade_no\") private String outTradeNo; @JsonProperty(name=\"total_amount\") private String totalAmount; /** * 公共回传参数 */ @JsonProperty(name=\"passback_params\") private String passbackParams; private String subject; private String body; @JsonProperty(name=\"product_code\") private String productCode; /** * 该参数在请求到支付宝时开始计时,该笔订单允许的最晚付款时间，逾期将关闭交易。 * 取值范围：1m～15d。m-分钟，h-小时，d-天，1c-当天 * （1c-当天的情况下，无论交易何时创建，都在0点关闭）。 * 该参数数值不接受小数点， 如 1.5h，可转换为 90m。 */ @JsonProperty(name=\"timeout_express\") private String timeoutExpress; ｝ 突然发现这个@JsonProperty注解是Spring框架自带jackson的注解，不是阿里FastJson的注解，于是乎我看了看找到了下面的这个注解： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public @interface JSONField &#123; /** * config encode/decode ordinal * @since 1.1.42 * @return */ // 配置序列化和反序列化的顺序，1.1.42版本之后才支持 int ordinal() default 0; // 指定字段的名称 String name() default \"\"; // 指定字段的格式，对日期格式有用 String format() default \"\"; // 是否序列化 boolean serialize() default true; // 是否反序列化 boolean deserialize() default true; SerializerFeature[] serialzeFeatures() default &#123;&#125;; Feature[] parseFeatures() default &#123;&#125;; String label() default \"\"; /** * @since 1.2.12 */ boolean jsonDirect() default false; /** * Serializer class to use for serializing associated value. * * @since 1.2.16 */ Class&lt;?&gt; serializeUsing() default Void.class; /** * Deserializer class to use for deserializing associated value. * * @since 1.2.16 */ Class&lt;?&gt; deserializeUsing() default Void.class; /** * @since 1.2.21 * @return the alternative names of the field when it is deserialized */ String[] alternateNames() default &#123;&#125;; /** * @since 1.2.31 */ boolean unwrapped() default false;&#125; 知道这个注解之后，把@JsonProperty替换成@JSONField注解就行了，转换成Json属性名就会从outTradeNo变成out_trade_no","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"fastJson","slug":"fastJson","permalink":"https://blog.ydstudio.net/tags/fastJson/"}]},{"title":"谈谈Java集合ArrayList扩容","slug":"谈谈Java集合ArrayList扩容","date":"2018-12-13T23:19:26.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/3d08b907.html","link":"","permalink":"https://blog.ydstudio.net/post/3d08b907.html","excerpt":"一 先从 ArrayList 的构造函数说起ArrayList有三种方式来初始化，构造方法源码如下：","text":"一 先从 ArrayList 的构造函数说起ArrayList有三种方式来初始化，构造方法源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** *默认构造函数，使用初始容量10构造一个空列表(无参数构造) */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123;//初始容量大于0 //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123;//初始容量等于0 //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123;//初始容量小于0，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125;/** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会降到这一点内容！ 二 一步一步分析 ArrayList 扩容机制这里以无参构造函数创建的 ArrayList 为例分析 1. 先来看 add 方法12345678910 /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123;//添加元素之前，先调用ensureCapacityInternal方法 ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; 2. 再来看看 ensureCapacityInternal() 方法可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1) 123456789//得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; 当 要 add 进第1个元素时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。 3. ensureExplicitCapacity() 方法如果调用 ensureCapacityInternal() 方法就一定会进过（执行）这个方法，下面我们来研究一下这个方法的源码！ 123456789//判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; 我们来仔细分析一下： 当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length &gt; 0成立，所以会进入 grow(minCapacity) 方法。 当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。 添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。 直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。 4. grow() 方法123456789101112131415161718192021222324/** * 要分配的最大数组大小 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍！ 记清楚了！不是网上很多人说的 1.5 倍+1！ “&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 我们再来通过例子探究一下grow() 方法 ： 当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。 当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true,size增为11。 以此类推······ 这里补充一点比较重要，但是容易被忽视掉的知识点： java 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法. java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! 5. hugeCapacity() 方法。从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。 1234567891011private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较 //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小 //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小 //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 三 System.arraycopy() 和 Arrays.copyOf()方法阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！ 3.1 System.arraycopy() 方法123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 我们写一个简单的方法测试以下： 1234567891011121314151617public class ArraycopyTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] a = new int[10]; a[0] = 0; a[1] = 1; a[2] = 2; a[3] = 3; System.arraycopy(a, 2, a, 3, 3); a[2]=99; for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i]); &#125; &#125;&#125; 结果： 10 1 99 2 3 0 0 0 0 0 3.2 Arrays.copyOf()方法1234567/** 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 */ public Object[] toArray() &#123; //elementData：要复制的数组；size：要复制的长度 return Arrays.copyOf(elementData, size); &#125; 个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下： 1234567891011public class ArrayscopyOfTest &#123; public static void main(String[] args) &#123; int[] a = new int[3]; a[0] = 0; a[1] = 1; a[2] = 2; int[] b = Arrays.copyOf(a, 10); System.out.println(\"b.length\"+b.length); &#125;&#125; 结果： 110 3.3 两者联系和区别联系： 看两者源代码可以发现 copyOf() 内部实际调用了 System.arraycopy() 方法 区别： arraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。 四 ensureCapacity方法ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？ 1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125; 最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量从新分配的次数 我们通过下面的代码实际测试以下这个方法的效果： 123456789101112131415161718192021public class EnsureCapacityTest &#123; public static void main(String[] args) &#123; ArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); final int N = 10000000; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法前：\"+(endTime - startTime)); list = new ArrayList&lt;Object&gt;(); long startTime1 = System.currentTimeMillis(); list.ensureCapacity(N); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime1 = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法后：\"+(endTime1 - startTime1)); &#125;&#125; 运行结果： 12使用ensureCapacity方法前：4637使用ensureCapacity方法后：241 通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量从新分配的次数 查看原文","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"arrayList","slug":"arrayList","permalink":"https://blog.ydstudio.net/tags/arrayList/"}]},{"title":"谈谈Java集合ArrayList","slug":"谈谈Java集合ArrayList","date":"2018-11-30T23:17:57.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/e6d29090.html","link":"","permalink":"https://blog.ydstudio.net/post/e6d29090.html","excerpt":"ArrayList简介 ArrayList核心源码 ArrayList源码分析 System.arraycopy()和Arrays.copyOf()方法 两者联系与区别 ArrayList核心扩容技术 内部类 ArrayList经典Demo ArrayList简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。","text":"ArrayList简介 ArrayList核心源码 ArrayList源码分析 System.arraycopy()和Arrays.copyOf()方法 两者联系与区别 ArrayList核心扩容技术 内部类 ArrayList经典Demo ArrayList简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 在我们学数据结构的时候就知道了线性表的顺序存储，插入删除元素的时间复杂度为O（n）,求表长以及增加元素，取第 i 元素的时间复杂度为O（1） ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 ArrayList 实现了RandomAccess 接口，即提供了随机访问功能。RandomAccess 是 Java 中用来被 List 实现，为 List 提供快速访问功能的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 ArrayList 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 ArrayList 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。 和 Vector 不同，ArrayList 中的操作不是线程安全的！所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 ArrayList核心源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498package java.util;import java.util.function.Consumer;import java.util.function.Predicate;import java.util.function.UnaryOperator;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; /** *默认构造函数，其默认初始容量为10 */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; // elementData = c.toArray(); //如果指定集合元素个数不为0 if ((size = elementData.length) != 0) &#123; // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断， //这里用到了反射里面的getClass()方法 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 用空数组代替 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125;//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为ArrayList定义的最大容量，否则，新容量大小则为 minCapacity。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //比较minCapacity和 MAX_ARRAY_SIZE private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; /** *返回此列表中的元素数。 */ public int size() &#123; return size; &#125; /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() &#123; //注意=和==的区别 return size == 0; &#125; /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) &#123; //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 return indexOf(o) &gt;= 0; &#125; /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) //equals()方法比较 if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度 v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // 这不应该发生，因为我们是可以克隆的 throw new InternalError(e); &#125; &#125; /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // 新建一个运行时类型的数组，但是ArrayList数组的内容 return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; // Positional Access Operations @SuppressWarnings(\"unchecked\") E elementData(int index) &#123; return (E) elementData[index]; &#125; /** * 返回此列表中指定位置的元素。 */ public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125; /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) &#123; //对index进行界限检查 rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素 return oldValue; &#125; /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置(本人修改，移动成员包括index所在元素)；将element插入index位置；最后size加1。 */ public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; /** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 */ public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work //从列表中删除的元素 return oldValue; &#125; /** * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。 *返回true，如果此列表包含指定的元素 */ public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; /** * 从列表中删除所有元素。 */ public void clear() &#123; modCount++; // 把数组中所有的元素的值设为null for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; /** * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 *将任何后续元素移动到左侧（减少其索引）。 */ protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; /** * 检查给定的索引是否在范围内。 */ private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * add和addAll使用的rangeCheck的一个版本 */ private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 返回IndexOutOfBoundsException细节信息 */ private String outOfBoundsMsg(int index) &#123; return \"Index: \"+index+\", Size: \"+size; &#125; /** * 从此列表中删除指定集合中包含的所有元素。 */ public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); //如果此列表被修改则返回true return batchRemove(c, false); &#125; /** * 仅保留此列表中包含在指定集合中的元素。 *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 */ public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(\"Index: \"+index); return new ListItr(index); &#125; /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; ArrayList源码分析System.arraycopy()和Arrays.copyOf()方法 通过上面源码我们发现这两个实现数组复制的方法被广泛使用而且很多地方都特别巧妙。比如下面add(int index, E element)方法就很巧妙的用到了arraycopy()方法让数组自己复制自己实现让index开始之后的所有成员后移一个位置: 123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 又如toArray()方法中用到了copyOf()方法 12345678910/** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */public Object[] toArray() &#123;//elementData：要复制的数组；size：要复制的长度 return Arrays.copyOf(elementData, size);&#125; 两者联系与区别联系：看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法区别： arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，并返回该数组。ArrayList 核心扩容技术1234567891011121314151617181920212223242526272829303132333435363738//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容,上面两个方法都要调用 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 如果说minCapacity也就是所需的最小容量大于保存ArrayList数据的数组的长度的话，就需要调用grow(minCapacity)方法扩容。 //这个minCapacity到底为多少呢？举个例子在添加元素(add)方法中这个minCapacity的大小就为现在数组的长度加1 if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; 12345678910111213141516171819202122/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; //elementData为保存ArrayList数据的数组 ///elementData.length求数组长度elementData.size是求数组中的元素个数 // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为ArrayList定义的最大容量，否则，新容量大小则为 minCapacity。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 扩容机制代码已经做了详细的解释。另外值得注意的是大家很容易忽略的一个运算符：移位运算符 简介：移位运算符就是在二进制的基础上对数字进行平移。按照平移的方向和填充数字的规则分为三种:&lt;&lt;(左移)、&gt;&gt;(带符号右移)和&gt;&gt;&gt;(无符号右移)。 作用：对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 比如这里：int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。 另外需要注意的是： java 中的length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的length()方法是针对字 符串String说的,如果想看这个字符串的长度则用到 length()这个方法. .java 中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! 内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 (1)private class Itr implements Iterator&lt;E&gt; (2)private class ListItr extends Itr implements ListIterator&lt;E&gt; (3)private class SubList extends AbstractList&lt;E&gt; implements RandomAccess (4)static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; ``` ArrayList有四个内部类，其中的**Itr是实现了Iterator接口**，同时重写了里面的**hasNext()**，**next()**，**remove()**等方法；其中的**ListItr**继承**Itr**，实现了**ListIterator接口**，同时重写了**hasPrevious()**，**nextIndex()**，**previousIndex()**，**previous()**，**set(E e)**，**add(E e)**等方法，所以这也可以看出了**Iterator和ListIterator的区别:**ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。### ArrayList经典Demo```javapackage list;import java.util.ArrayList;import java.util.Iterator;public class ArrayListDemo &#123; public static void main(String[] srgs)&#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size()); System.out.println(\"Printing elements of arrayList\"); // 三种遍历方式打印元素 // 第一种：通过迭代器遍历 System.out.print(\"通过迭代器遍历:\"); Iterator&lt;Integer&gt; it = arrayList.iterator(); while(it.hasNext())&#123; System.out.print(it.next() + \" \"); &#125; System.out.println(); // 第二种：通过索引值遍历 System.out.print(\"通过索引值遍历:\"); for(int i = 0; i &lt; arrayList.size(); i++)&#123; System.out.print(arrayList.get(i) + \" \"); &#125; System.out.println(); // 第三种：for循环遍历 System.out.print(\"for循环遍历:\"); for(Integer number : arrayList)&#123; System.out.print(number + \" \"); &#125; // toArray用法 // 第一种方式(最常用) Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解) Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型 //Integer[] integer2 = new Integer[arrayList.size()]; //integer2 = arrayList.toArray(); System.out.println(); // 在指定位置添加元素 arrayList.add(2,2); // 删除指定位置上的元素 arrayList.remove(2); // 删除指定元素 arrayList.remove((Object)3); // 判断arrayList是否包含5 System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5)); // 清空ArrayList arrayList.clear(); // 判断ArrayList是否为空 System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty()); &#125;&#125; 查看原文","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"arrayList","slug":"arrayList","permalink":"https://blog.ydstudio.net/tags/arrayList/"}]},{"title":"使用Nginx做反向代理,设置请求返回时带上被代理机器的信息","slug":"使用Nginx做反向代理-设置请求返回时带上被代理机器的信息","date":"2018-11-08T23:16:02.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/8f4c3efa.html","link":"","permalink":"https://blog.ydstudio.net/post/8f4c3efa.html","excerpt":"现在的大家经常使用Nginx做代理，例如用Nginx去代理Node。如果代理的Node过多，Node一旦出现问题我们怎么知道到底是哪个出了问题呢？于是就有了今天的文章，我们可以设置请求返回时带上被代理机器的一些信息。","text":"现在的大家经常使用Nginx做代理，例如用Nginx去代理Node。如果代理的Node过多，Node一旦出现问题我们怎么知道到底是哪个出了问题呢？于是就有了今天的文章，我们可以设置请求返回时带上被代理机器的一些信息。 Nginx的配置123456789101112131415161718192021222324upstream usa &#123; server 127.0.0.1:3001; &#125;server &#123; listen 80 ; server_name xxx.com ; error_log /var/log/nginx/tianxingusa_error.log error; access_log /var/log/nginx/tianxingusa_accss.log main; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; add_header Proxy-Node $upstream_addr; add_header Proxy-Status $upstream_status; proxy_http_version 1.1; proxy_pass http://usa; &#125; #省略部分信息&#125; 上面配置中12add_header Proxy-Node $upstream_addr;add_header Proxy-Status $upstream_status; 设置了Proxy-Node和Proxy-Status两个header，Proxy-Node显示的是被代理的节点，Proxy-Status显示的是被代理节点的状态，配置好之后重载Nginx的配置文件。我们就可以在 Response Headers 中看到相关的信息：12345678910111213HTTP/1.1 200 OKServer: nginxDate: Fri, 09 Nov 2018 03:07:55 GMTContent-Type: text/html; charset=UTF-8Content-Length: 1227Connection: keep-aliveX-Powered-By: ExpressAccept-Ranges: bytesCache-Control: public, max-age=0Last-Modified: Fri, 26 Oct 2018 10:11:49 GMTETag: W/\"4cb-166afdbcd67\"Proxy-Node: 127.0.0.1:3001Proxy-Status: 200","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"},{"name":"proxy","slug":"proxy","permalink":"https://blog.ydstudio.net/tags/proxy/"}]},{"title":"Spring Boot 1.x 中整合Sharding-JDBC实现读写分离","slug":"Spring-Boot-1-x-中整合Sharding-JDBC实现读写分离","date":"2018-10-06T23:14:30.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/6d3d362b.html","link":"","permalink":"https://blog.ydstudio.net/post/6d3d362b.html","excerpt":"国庆期间研究了数据库中间件例如Mycat和Sharding JDBC，Sharding-jdbc和Mycat使用不同的理念，Sharding-jdbc目前是基于Jdbc驱动，无需额外的proxy，因此也无需关注proxy本身的高可用。Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以jar包的形式提供轻量级服务的。","text":"国庆期间研究了数据库中间件例如Mycat和Sharding JDBC，Sharding-jdbc和Mycat使用不同的理念，Sharding-jdbc目前是基于Jdbc驱动，无需额外的proxy，因此也无需关注proxy本身的高可用。Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以jar包的形式提供轻量级服务的。 先介绍一下整合过程中用到的主要软件的版本： 12Spring Boot: 1.5.8.RELEASESharding-JDBC: 2.0.3 注意： 实现读写分离我们自己要先配置好MySQL的主从复制，我自己已经配置好了一主两从。配置的步骤可以参考【实现MySQL主从复制】 pom.xml 依赖123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.shardingjdbc&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-core-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application配置文件1234567891011121314151617181920212223242526272829303132333435363738server.port=8080sharding.jdbc.datasource.names=ds_master,ds_slave_1,ds_slave_2# 主数据源sharding.jdbc.datasource.ds_master.type=com.alibaba.druid.pool.DruidDataSourcesharding.jdbc.datasource.ds_master.driver-class-name=com.mysql.jdbc.Driversharding.jdbc.datasource.ds_master.url=jdbc:mysql://localhost:3306/db1?characterEncoding=utf-8sharding.jdbc.datasource.ds_master.username=rootsharding.jdbc.datasource.ds_master.password=123456sharding.jdbc.datasource.ds_master.maxPoolSize=20# 从数据源 ds_slave_1sharding.jdbc.datasource.ds_slave_1.type=com.alibaba.druid.pool.DruidDataSourcesharding.jdbc.datasource.ds_slave_1.driver-class-name=com.mysql.jdbc.Driversharding.jdbc.datasource.ds_slave_1.url=jdbc:mysql://localhost:3307/db1?characterEncoding=utf-8sharding.jdbc.datasource.ds_slave_1.username=rootsharding.jdbc.datasource.ds_slave_1.password=123456sharding.jdbc.datasource.ds_slave_1.maxPoolSize=20# 从数据源 ds_slave_2sharding.jdbc.datasource.ds_slave_2.type=com.alibaba.druid.pool.DruidDataSourcesharding.jdbc.datasource.ds_slave_2.driver-class-name=com.mysql.jdbc.Driversharding.jdbc.datasource.ds_slave_2.url=jdbc:mysql://localhost:3308/db1?characterEncoding=utf-8sharding.jdbc.datasource.ds_slave_2.username=rootsharding.jdbc.datasource.ds_slave_2.password=123456sharding.jdbc.datasource.ds_slave_2.maxPoolSize=20# 读写分离配置sharding.jdbc.config.masterslave.load-balance-algorithm-type=round_robinsharding.jdbc.config.masterslave.name=dataSourcesharding.jdbc.config.masterslave.master-data-source-name=ds_mastersharding.jdbc.config.masterslave.slave-data-source-names=ds_slave_1,ds_slave_2mybatis.config-location=classpath:mybatis-config.xmlmybatis.mapper-locations=classpath:mapper/*.xmlmybatis.typeAliasesPackage=net.ydstuio.shardingjdbc.repository sharding.jdbc.config.masterslave.load-balance-algorithm-type查询时的负载均衡算法，目前有2种算法，round_robin（轮询）和random（随机）。 算法接口是：io.shardingjdbc.core.api.algorithm.masterslave.MasterSlaveLoadBalanceAlgorithm。 实现类有RandomMasterSlaveLoadBalanceAlgorithm和RoundRobinMasterSlaveLoadBalanceAlgorithm。 sharding.jdbc.config.masterslave.master-data-source-name 主数据源名称。 sharding.jdbc.config.masterslave.slave-data-source-names 从数据源名称，多个用逗号隔开。 到此，Sharing-Jdbc的读写分离就已经就配置好了，看看是不是很简单。如果对数据的及时性要求很高，可以使用下面的代码，使得读取也落到主库上。 12// 强制路由主库HintManager.getInstance().setMasterRouteOnly();","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://blog.ydstudio.net/tags/sharding-jdbc/"}]},{"title":"Spring Boot 1.5.8整合Dubbo","slug":"Spring-Boot-1-5-8整合Dubbo","date":"2018-10-06T23:06:57.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/53410e91.html","link":"","permalink":"https://blog.ydstudio.net/post/53410e91.html","excerpt":"废话不多说，今天说说Spring Boot和Dubbo的整合,注册服务中心用的是Zookeeper，至于Dubbo、Zookeeper为何物我在此不再多言，不知道是什么自己去百度，本文适用于对微服务或者RPC了解的人准备的！","text":"废话不多说，今天说说Spring Boot和Dubbo的整合,注册服务中心用的是Zookeeper，至于Dubbo、Zookeeper为何物我在此不再多言，不知道是什么自己去百度，本文适用于对微服务或者RPC了解的人准备的！ 先介绍一下整合过程中用到的主要软件的版本： 1234Spring Boot: 1.5.8.RELEASEDubbo: dubbo-spring-boot-starter 0.1.1Zookeeper: 3.4.10dubbo-admin：2.5.4 其中dubbo-admin使用的是老版本的，新版本的大家可以到github上去搜索，这里给出这个版本的下载地址，我不保证任何时候都可以使用dubbo-admin-2.5.4Dubbo使用的是alibaba官方提供的starter ： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.1.1&lt;/version&gt;&lt;/dependency&gt; 如果您的工程遇到了依赖问题, 请尝试添加如下 Maven 参考到工程的 pom.xml 文件中： 123456789101112&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 从现在开始, dubbo-spring-boot-project 将在每个发布中发行两个版本 : 0.2.x 是支持 Spring Boot 2.x 的主要版本（推荐，长期维护） 0.1.x 是支持 Spring Boot 1.x 的维护版本（兼容，短期维护）123版本 Java Spring Boot Dubbo0.2.0 1.8+ 2.0.x 2.6.2+0.1.1 1.7+ 1.5.x 2.6.2+ 以上牵涉到需要安装的软件，需要大家自行准备，本文的重点不在于此！友情提示,使用上面版本的dubbo-admin是个war包可以之前部署在Tomcat中，注意其中配置文件中的Zookeeper的地址，请修改成自己可用的Zookeeper地址！ 我之前写过一个基于Spring Boot和Spring Cloud的BT搜索项目，我主要是想用这个项目练手Spring Cloud，其中用了Zuul、Fegin、Ribbon、Spring Config、Hystrix、Eureka等组件。下面开始正式的编码，Spring Boot和Dubbo的整合。其中问题有很多，浪费了我国庆假期中的一天，其实最后发现问题解决很简单。 ####由服务提供方为服务消费方暴露接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package net.ydstudio.dubbo.search.api.service;import net.ydstudio.dubbo.search.api.document.BtSearchDocument;import net.ydstudio.dubbo.search.api.model.EsSearchHotResult;import java.io.IOException;/** * Created by Sam on 18/7/7. */public interface BtSearchService &#123; /** * 创建索引 * @return * @throws IOException */ Boolean createIndex() throws IOException; /** * 通过word查询 文档 * @param word * @return * @throws IOException */ BtSearchDocument findOne(String word) throws IOException; /** * 根据id删除文档 * @param word * @throws IOException * @return */ Boolean delete(String word) throws IOException; /** * 保存 document * @param word * @throws IOException * @return true or false */ Boolean save(String word) throws IOException; /** * 删除索引 * @return * @throws IOException */ Boolean deleteIndex() throws IOException; /** * 热搜词 * @return */ EsSearchHotResult hotWordList();&#125; ####服务提供方 pom.xml中的依赖123456789101112131415161718192021222324 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;net.ydstudio.dubbo&lt;/groupId&gt; &lt;artifactId&gt;search-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 实现暴露的接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139package net.ydstudio.dubbo.search.service;import com.alibaba.dubbo.config.annotation.Service;import io.searchbox.client.JestClient;import io.searchbox.client.JestResult;import io.searchbox.core.Search;import net.ydstudio.dubbo.search.api.document.BtSearchDocument;import net.ydstudio.dubbo.search.api.model.EsSearchHotResult;import net.ydstudio.dubbo.search.api.service.BtSearchService;import net.ydstudio.dubbo.search.util.Md5Util;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.builder.SearchSourceBuilder;import org.elasticsearch.search.sort.FieldSortBuilder;import org.elasticsearch.search.sort.SortBuilders;import org.elasticsearch.search.sort.SortOrder;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.core.io.Resource;import org.springframework.util.StringUtils;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.List;/** * Created by Sam on 18/7/7. */@Servicepublic class BtSearchServiceImpl implements BtSearchService,EsSearchService&lt;BtSearchDocument&gt; &#123; /** * 索引 */ public static final String INDEX_NAME = \"search\"; /** * 索引类型 */ public static final String TYPE = \"searchWord\"; @Value(\"classpath:mapping/searchMapping.json\") private Resource mappingFile; @Autowired private JestClient jestClient; @Override public Boolean createIndex() throws IOException &#123; return createESIndex(jestClient, mappingFile, INDEX_NAME, TYPE); &#125; @Override public BtSearchDocument findOne(String word) throws IOException &#123; String id = Md5Util.md5(word); return findDocument(jestClient, INDEX_NAME, TYPE, id, BtSearchDocument.class); &#125; @Override public Boolean delete(String word) throws IOException &#123; String id = Md5Util.md5(word); return deleteDocument(jestClient, INDEX_NAME, TYPE, id); &#125; @Override public Boolean save(String word) throws IOException &#123; String id = Md5Util.md5(word); BtSearchDocument document = this.findOne(id); SimpleDateFormat format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); Date date = new Date(); if (StringUtils.isEmpty(document))&#123; document = new BtSearchDocument(); document.setId(id); document.setCreated(format.format(date)); document.setNum(1); document.setWord(word); &#125;else &#123; document.setNum(document.getNum()+1); &#125; document.setUpdated(format.format(date)); return saveDocument(jestClient, INDEX_NAME, TYPE, id, document); &#125; @Override public Boolean deleteIndex() throws IOException &#123; return deleteESIndex(jestClient, INDEX_NAME); &#125; @Override public EsSearchHotResult hotWordList() &#123; // match_all BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); QueryBuilder queryBuilder = QueryBuilders.matchAllQuery(); boolQuery.must(queryBuilder); FieldSortBuilder sortBuilder = SortBuilders.fieldSort(\"num\"); sortBuilder.order(SortOrder.DESC); searchSourceBuilder.query(boolQuery); searchSourceBuilder.sort(sortBuilder); // 构建Search对象 Search search = new Search.Builder(searchSourceBuilder.toString()) .addIndex(INDEX_NAME) .addType(TYPE) .build(); EsSearchHotResult esSearchHotResult = new EsSearchHotResult(); try &#123; JestResult result = jestClient.execute(search); List&lt;BtSearchDocument&gt; list = result.getSourceAsObjectList(BtSearchDocument.class); esSearchHotResult.setTook(result.getValue(\"took\").toString()); esSearchHotResult.setDocumentList(list); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return esSearchHotResult; &#125;&#125; search服务提供方的application的配置信息： 123456789101112131415161718dubbo: application: id: search-provider name: search-provider protocosl: id: dubbo name: dubbo port: 20880 scan: basePackages: net.ydstudio.dubbo.search.service registry: id: my-registry address: zookeeper://xx.xx.xxx.xxx:xxx parameters: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 注意 basePackages项配置的包路径，他对应的是设置扫描路径即被注解@service和@Reference描述的接口（或者说是暴露接口的实现类的包路径，这个很重要，我在此处耽搁了很久）,这个配置可以使用 @EnableDubbo 注解替代（加在启动类上） ####服务消费方#####pom.xml中的依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;net.ydstudio.dubbo&lt;/groupId&gt; &lt;artifactId&gt;bt-model&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.ydstudio.dubbo&lt;/groupId&gt; &lt;artifactId&gt;search-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--thymeleaf--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator&lt;/artifactId&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置文件123456789101112131415161718dubbo: application: id: bt-search name: bt-search protocosl: id: dubbo name: dubbo port: 20880 scan: basePackages: net.ydstudio.dubbo.bt registry: id: my-registry address: zookeeper://xx.xx.xxx.xxx:xxx parameters: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 注意 basePackages 设置扫描路径,扫描被注解@service和@Reference的接口 RPC调用12@Referenceprivate BtSearchService btSearchService; 使用com.alibaba.dubbo.config.annotation.Reference中的 @Reference注解修饰接口BtSearchService ，然后像普通的bean使用即可。 整合总结由于软件更新的快，或者软件项目的生存周期太短，软件对应的说明文档会跟不上。Dubbo现在已经捐献给了Apache，这一方面可能会好一点。大家在开发的时候注意细心一点，多去看看GitHub，不然问题会很多！ 附注参考资料【官方Dubbo和Spring Boot整合的GitHub地址】","categories":[],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://blog.ydstudio.net/tags/dubbo/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"}]},{"title":"Mycat 数据库分库分表中间件的分库配置","slug":"Mycat-数据库分库分表中间件的分库配置","date":"2018-10-03T23:04:44.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/dcd836f7.html","link":"","permalink":"https://blog.ydstudio.net/post/dcd836f7.html","excerpt":"本文是Mycat 数据库分库分表中间件系列文章的第三篇，平时工作太忙，加上又忙着从PHP转Java，平日的空闲时间都去研究Java了。什么Spring MVC、Spring Boot、Spring Cloud、Dubbo，东西真尼玛的多！正好国庆一人没事干，再次拾起来Mycat的研究。","text":"本文是Mycat 数据库分库分表中间件系列文章的第三篇，平时工作太忙，加上又忙着从PHP转Java，平日的空闲时间都去研究Java了。什么Spring MVC、Spring Boot、Spring Cloud、Dubbo，东西真尼玛的多！正好国庆一人没事干，再次拾起来Mycat的研究。 首先，先按照 实现MySQL主从复制 上的步骤配置一个简单的MySQL主从环境，先贴一下相关的配置信息：MySQL中Master的配置： 123456789101112131415161718192021[client]port=3306[mysql]default-character-set=utf8[mysqld]port=3306basedir=\"C:/phpStudy/MySQL/\"datadir=\"C:/phpStudy/MySQL/data/\"character-set-server=utf8collation-server=utf8_general_ci default-storage-engine=MyISAM### addserver-id=1log-bin =mysql-binbinlog-format = mixedbinlog-do-db=db1 #此参数表示只记录指定数据库的二进制日志。binlog-do-db=db2binlog-do-db=db3#binlog-ignore-db=api,mysql,performance_schema #此参数表示忽略指定的数据库的二进制日志。#其他配置省略 MySQL中slave的配置： 12345678910111213141516171819[client]port=3307[mysql]default-character-set=utf8[mysqld]port=3307basedir=\"C:/phpStudy/MySQL3307/\"datadir=\"C:/phpStudy/MySQL3307/data/\"character-set-server=utf8collation-server=utf8_general_ci default-storage-engine=MyISAMserver-id=3307log-bin = mysql-binbinlog-format =mixedrelay-log=mysql-relayslave-skip-errors=all #跳过所有错误#其他配置省略 在master上创建用于同步数据的账户： 123grant replication client,replication slave on *.* to slave3307@'%' identified by 'slave3307';#刷新权限，立即生效flush privileges; 在Master执行命令查看log_pos和log_file 1234567show master status; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000062 | 8233| | | +------------------+----------+--------------+------------------+ 注意 执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化 在slave上执行下面的命令，讲master和slave关联起来： 12345hange master to master_host='127.0.0.1',master_port=3306,master_user='slave3307',master_password='slave3307',master_log_file='mysql-bin.000062',master_log_pos=8233;start slave #启动从服务器复制功能show slave status\\G 其中 Slave_IO_Running 和 Slave_SQL_Running 两列的值都为 “Yes”，表明 Slave 的 I/O 和 SQL 线程都在正常运行。正常的表现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 127.0.0.1 Master_User: slave3307 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000007 Read_Master_Log_Pos: 24536 Relay_Log_File: mysql-relay.000005 Relay_Log_Pos: 24699 Relay_Master_Log_File: mysql-bin.000007 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 24536 Relay_Log_Space: 25318 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: fe1b230d-6ee9-11e8-b0c6-9c5c8e103115 Master_Info_File: C:\\phpStudy\\MySQL3307\\data\\master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.00 sec) 友情提示：如果是直接复制MySQL的安装目录配置的主从，注意MySQL5.6开始的UUID的问题。下面开始Mycat的配置，Mycat中有三个重要的配置文件：server.xml、schema.xml、rule.xml，下面就分别贴一下对应的配置信息：server.xml中的配置信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mycat:server SYSTEM \"server.dtd\"&gt;&lt;mycat:server xmlns:mycat=\"http://io.mycat/\"&gt; &lt;system&gt; &lt;property name=\"useSqlStat\"&gt;0&lt;/property&gt; &lt;!-- 1为开启实时统计、0为关闭 --&gt; &lt;property name=\"useGlobleTableCheck\"&gt;0&lt;/property&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name=\"sequnceHandlerType\"&gt;2&lt;/property&gt; &lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena--&gt; &lt;property name=\"processorBufferPoolType\"&gt;0&lt;/property&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name=\"handleDistributedTransactions\"&gt;0&lt;/property&gt; &lt;!--off heap for merge/order/group/limit 1开启 0关闭--&gt; &lt;property name=\"useOffHeapForMerge\"&gt;1&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name=\"memoryPageSize\"&gt;1m&lt;/property&gt; &lt;!--单位为k--&gt; &lt;property name=\"spillsFileBufferSize\"&gt;1k&lt;/property&gt; &lt;property name=\"useStreamOutput\"&gt;0&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name=\"systemReserveMemorySize\"&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name=\"useZKSwitch\"&gt;true&lt;/property&gt; &lt;/system&gt; &lt;user name=\"root\"&gt; &lt;property name=\"password\"&gt;mycat&lt;/property&gt; &lt;!--多个数据库逗号隔开 --&gt; &lt;property name=\"schemas\"&gt;testdb&lt;/property&gt; &lt;/user&gt; &lt;user name=\"mycatread\"&gt; &lt;property name=\"password\"&gt;mycatread&lt;/property&gt; &lt;property name=\"schemas\"&gt;testdb&lt;/property&gt; &lt;property name=\"readOnly\"&gt;true&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; schema.xml中的配置信息： 12345678910111213141516171819202122&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM \"schema.dtd\"&gt;&lt;mycat:schema xmlns:mycat=\"http://io.mycat/\"&gt; &lt;schema name=\"testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"&gt; &lt;table name=\"t_user\" dataNode=\"dn1,dn2,dn3\" rule=\"crc32slot\"&gt; &lt;!-- 父表为t_user，子表为t_admin。t_admin表中的字段user_id引用t_user表中的id主键字段。 --&gt; &lt;childTable name=\"t_admin\" joinKey=\"user_id\" parentKey=\"id\" /&gt; &lt;/table&gt; &lt;/schema&gt; &lt;dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" /&gt; &lt;dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" /&gt; &lt;dataNode name=\"dn3\" dataHost=\"localhost1\" database=\"db3\" /&gt; &lt;dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"2\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;show slave status&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"127.0.0.1:3306\" user=\"root\" password=\"123456\"&gt; &lt;!--&lt;readHost host=\"hostS1\" url=\"127.0.0.1:3307\" user=\"root\" password=\"123456\"/&gt;--&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; rule.xml中的配置信息： 1234&lt;function name=\"crc32slot\" class=\"io.mycat.route.function.PartitionByCRC32PreSlot\"&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --&gt;&lt;/function&gt; 注意下面的地方： 12345678&lt;!--schema.xml中--&gt;&lt;table name=\"t_user\" dataNode=\"dn1,dn2,dn3\" rule=\"crc32slot\"&gt;&lt;!--rule.xml中--&gt;&lt;function name=\"crc32slot\" class=\"io.mycat.route.function.PartitionByCRC32PreSlot\"&gt; &lt;property name=\"count\"&gt;3&lt;/property&gt;&lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --&gt; &lt;/function&gt; 使用crc32lot进行分片，分片的数据库节点的数量默认给了2，如果你修改了这里，请一定要删除conf/ruledata/crc32slot_T_USER.properties这个文件，并重新启动Mycat，不然你的数据是不会分到db3这个数据库节点的。到这里Mycat分库配置就完成了，你只需要在Mycat的管理上操作，就能在master、slave上看到效果： 123456789101112131415161718192021222324252627mysql&gt;mysql -uroot -pmycat -P8066Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.6.29-mycat-1.6-RELEASE-20161028204710 MyCat Server (OpenClounCopyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; insert into t_user(id, name) values(1, 'aaa');Query OK, 1 row affected (0.02 sec)mysql&gt; insert into t_user(id, name) values(2, 'bbb');Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t_user(id, name) values(3, 'ccc');Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t_user(id, name) values(4, 'ddd');Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t_user(id, name) values(5, 'eee');Query OK, 1 row affected (0.00 sec) 在master上看效果： 1234567891011121314151617181920212223242526272829303132333435363738394041C:\\Users\\nick&gt;mysql -uroot -p123456Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10628Server version: 5.6.40-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; select * from db1.t_user;+----+------+-------+| id | name | _slot |+----+------+-------+| 3 | ccc | 32411 || 5 | eee | 27566 |+----+------+-------+2 rows in set (0.00 sec)mysql&gt; select * from db2.t_user;+----+------+-------+| id | name | _slot |+----+------+-------+| 1 | aaa | 44983 || 2 | bbb | 65037 |+----+------+-------+2 rows in set (0.00 sec)mysql&gt; select * from db3.t_user;+----+------+-------+| id | name | _slot |+----+------+-------+| 4 | ddd | 68408 |+----+------+-------+1 row in set (0.00 sec) 在slave上查看数据也是如此，此处就贴出部分数据： 1234567891011121314151617181920212223C:\\Users\\nick&gt;mysql -uroot -p -P3307Enter password: ******Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10412Server version: 5.6.40-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; select * from db1.t_user;+----+------+-------+| id | name | _slot |+----+------+-------+| 3 | ccc | 32411 || 5 | eee | 27566 |+----+------+-------+2 rows in set (0.00 sec)","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"mycat","slug":"mycat","permalink":"https://blog.ydstudio.net/tags/mycat/"}]},{"title":"Feign调用返回复杂对象时报错java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx","slug":"Feign调用返回复杂对象时报错java-lang-ClassCastException-java-util-LinkedHashMap-cannot-be-cast-to-xxx","date":"2018-09-30T23:39:50.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4f6a533b.html","link":"","permalink":"https://blog.ydstudio.net/post/4f6a533b.html","excerpt":"在公司的数据中心项目里使用了Feign，进行接口的调用，在返回一个复杂的对象时候，出现下面的一个错误： 1java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx","text":"在公司的数据中心项目里使用了Feign，进行接口的调用，在返回一个复杂的对象时候，出现下面的一个错误： 1java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to xxx 大致意思就是 LinkedHashMap 不能够转换成 xxx 对象，我很奇怪！因为这个接口相关的地方都没有使用到 LinkedHashMap，他是从哪里冒出来的？我开始调试下面的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Overridepublic List&lt;EsFilterKV&gt; getFilterKV(Integer companyId, Integer appId, Long usrId, String filterName) &#123; if (StringUtils.isEmpty(filterName))&#123; return null; &#125; List&lt;CompanyDistributionFilterGroup&gt; distributionFilterGroupList = companyDistributionService.findDistributionFilterGroupList(companyId,true); List&lt;ProductDocument&gt; productDocumentList = new ArrayList&lt;ProductDocument&gt;(100); try &#123; for (CompanyDistributionFilterGroup group: distributionFilterGroupList) &#123; List&lt;FilterItem&gt; filterItemList = filterGroupFilterService.findFilterItemList(group.getFilterGroupId()); MtSearchFilterRequest request = new MtSearchFilterRequest(); request.setFilterItemList(filterItemList); MtSearchResult mtSearchResult = productSearchService.search(request); productDocumentList.addAll(mtSearchResult.getData()); &#125; &#125; catch (MtException e) &#123; e.printStackTrace(); &#125; List&lt;Long&gt; longList = productDocumentList.stream().map(p-&gt;p.getId()).distinct().collect(Collectors.toList()); if (CollectionUtils.isEmpty(longList))&#123; return null; &#125; List&lt;Map&gt; idValueList = productPackageService.findPackageIdValueList(longList,filterName,true); if (CollectionUtils.isEmpty(idValueList))&#123; return null; &#125; List&lt;EsFilterKV&gt; esFilterKVs = new ArrayList&lt;EsFilterKV&gt;(idValueList.size()); for (Map map: idValueList)&#123; EsFilterKV esFilterKV = new EsFilterKV(); esFilterKV.setName(map.get(\"name\").toString()); esFilterKV.setId(new Long(map.get(\"id\").toString())); esFilterKV.setJsonName(\"&#123;'id':\"+esFilterKV.getId()+\",'name':'\"+esFilterKV.getName()+\"'&#125;\"); esFilterKVs.add(esFilterKV); &#125; return esFilterKVs;&#125; 我发现在 productDocumentList.addAll(mtSearchResult.getData()); 这一行，productDocumentList里面放的全是LinkedHashMap，不是想象中的对象列表。通过面向百度编程，我把productSearchService.search()这个方法返回的泛型给去掉了，指定了真实的类型，从而解决了上面的问题！ 通过百度得知有不少人遇到这种问题，有个感觉比较靠谱的解释如下： 因为rpc远程调用在底层还是使用的HTTPClient，所以在传递参数的时候，必定要有个顺序，当你传递map的时候map里面的值也要有顺序，不然服务层在接的时候就出问题了，所以它才会从map转为linkedhashMap！spring 有一个类叫ModelMap，继承了linkedhashMap public class ModelMap extends LinkedHashMap ,所以一个接口返回的结果就可以直接用ModelMap来接，注意ModelMap是没有泛型的，不管你返回的结果是什么类型的map，泛型是多复杂的map，都可以直接new一个Modelmap，用它来接返回的结果！！！","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"feign","slug":"feign","permalink":"https://blog.ydstudio.net/tags/feign/"}]},{"title":"php-fpm的进程池相关参数说明","slug":"php-fpm的进程池相关参数说明","date":"2018-09-17T22:59:19.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/c1dfde53.html","link":"","permalink":"https://blog.ydstudio.net/post/c1dfde53.html","excerpt":"最近公司的官网据业务说时不时的卡，而负责维护官网的人请假去德国跑马拉松了（ps:有钱真好），我又苦逼的帮他处理官网的事情。 php-fpm进程池开启进程有两种方式，一种是static，直接开启指定数量的php-fpm进程，不再增加或者减少；另一种则是dynamic，开始时开启一定数量的php-fpm进程，当请求量变大时，动态的增加php-fpm进程数到上限，当空闲时自动释放空闲的进程数到一个下限。这两种不同的执行方式，可以根据服务器的实际需求来进行调整。","text":"最近公司的官网据业务说时不时的卡，而负责维护官网的人请假去德国跑马拉松了（ps:有钱真好），我又苦逼的帮他处理官网的事情。 php-fpm进程池开启进程有两种方式，一种是static，直接开启指定数量的php-fpm进程，不再增加或者减少；另一种则是dynamic，开始时开启一定数量的php-fpm进程，当请求量变大时，动态的增加php-fpm进程数到上限，当空闲时自动释放空闲的进程数到一个下限。这两种不同的执行方式，可以根据服务器的实际需求来进行调整。 其中涉及到的一些参数，分别是pm、pm.max_children、pm.start_servers、pm.min_spare_servers和pm.max_spare_servers。pm表示使用那种方式，有两个值可以选择，就是static（静态）或者dynamic（动态）。 下面4个参数的意思分别为： 1234pm.max_children：静态方式下开启的php-fpm进程数量，在动态方式下他限定php-fpm的最大进程数（这里要注意pm.max_spare_servers的值只能小于等于pm.max_children）pm.start_servers：动态方式下的起始php-fpm进程数量。pm.min_spare_servers：动态方式空闲状态下的最小php-fpm进程数量。pm.max_spare_servers：动态方式空闲状态下的最大php-fpm进程数量。 php的配置文件里面给出了pm.start_servers的计算公式：min_spare_servers + (max_spare_servers - min_spare_servers) / 2 如果dm设置为static，那么其实只有pm.max_children这个参数生效。系统会开启参数设置数量的php-fpm进程。 如果dm设置为dynamic，4个参数都生效。系统会在php-fpm运行开始时启动pm.start_servers个php-fpm进程，然后根据系统的需求动态在pm.min_spare_servers和pm.max_spare_servers之间调整php-fpm进程数。","categories":[],"tags":[{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"},{"name":"php-fpm","slug":"php-fpm","permalink":"https://blog.ydstudio.net/tags/php-fpm/"}]},{"title":"Spring Cloud Config客户端报错Could not locate PropertySource: I/O error on GET request xxx","slug":"Spring-Cloud-Config客户端报错Could-not-locate-PropertySource-I-O-error-on-GET-request-xxx","date":"2018-09-15T23:46:48.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/29fad61b.html","link":"","permalink":"https://blog.ydstudio.net/post/29fad61b.html","excerpt":"今天在研究Spring Cloud Config配置中心，出了一个很让人恼火的问题，我先贴一下我的相关配置信息：","text":"今天在研究Spring Cloud Config配置中心，出了一个很让人恼火的问题，我先贴一下我的相关配置信息： 客户端的bootstrap.yml配置： 123456789101112131415161718192021server: port: 9009spring: application: name: admin-server profiles: active: dev cloud: config: name: admin-server-config label: master profile: dev discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://Eurexxxr:xxxx-12xxx56@accp.xxx.net:8786/eureka/ 出现的问题如下： 1Could not locate PropertySource: I/O error on GET request for \"http://config-server:9008/admin-server-config/dev/master\": Connection refused; nested exception is java.net.ConnectException: Connection refused 大致的意思是说”http://config-server:9008/admin-server-config/dev/master&quot;这个链接不能够访问，可我试着访问一下，却是可以访问的，这就让我百思不得其解！于是乎百度google走起，在stackoverflow上倒是找到几条相关的问题，但是问题的解答方案都不是很靠谱！于是乎放弃答案的寻找，我就去菜市场买菜，毕竟晚饭还是要吃的!酒足饭饱之后我又来研究这个问题。按理说提示这种链接不能访问，就是hosts文件映射的问题（ps：配置中心config-server我部署在我阿里云博客上），可是那个链接确实可以直接访问的…………………………………………我就试着看看我的hosts文件，第一次我还没有看出问题，我不死心的又看第二次，总算让我发现了问题的所在，下面是当时hosts文件的内容： 123456789101112131415161718192021# Host Database## localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.##127.0.0.1 localhostxx.78.xx.12 config-server127.0.0.1 dev127.0.0.1 search-provider127.0.0.1 config-server127.0.0.1 work.ydstudios.com127.0.0.1 work.damei.com127.0.0.1 work.gx.com127.0.0.1 work.phpcms.com127.0.0.1 work.typecho.com127.0.0.1 work.seacms.com127.0.0.1 work.dy360.net127.0.0.1 work.btsearch.com127.0.0.1 work.search.com127.0.0.1 work.mm.com127.0.0.1 work.duowan.com 不知道大家看出来没有？有两个ip指向了config-server，而且我发现这种配置，不同时候起作用的配置还不一样！直接访问url地址的时候，第一个配置生效，程序里确实第二个配置生效，尴尬…………","categories":[],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://blog.ydstudio.net/tags/spring-cloud/"},{"name":"spring cloud config","slug":"spring-cloud-config","permalink":"https://blog.ydstudio.net/tags/spring-cloud-config/"}]},{"title":"Spring Cloud整合配置中心Eureka中的服务状态显示UNKOWN","slug":"Spring-Cloud整合配置中心Eureka中的服务状态显示UNKOWN","date":"2018-09-09T23:42:27.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/5e4a0e78.html","link":"","permalink":"https://blog.ydstudio.net/post/5e4a0e78.html","excerpt":"今天在研究Spring Cloud的配置中心的时候，发现将应用的配置移到git上，启动应用后发现，在Euraka注册中心上这个应用的状态始终为UNKOWN，可是这个应用是可以提供服务的。下面是应用的bootstrap的配置：","text":"今天在研究Spring Cloud的配置中心的时候，发现将应用的配置移到git上，启动应用后发现，在Euraka注册中心上这个应用的状态始终为UNKOWN，可是这个应用是可以提供服务的。下面是应用的bootstrap的配置： 12345678910111213141516171819202122232425262728293031spring: application: name: search-provider cloud: config: name: search-config profile: dev label: master discovery: enabled: true service-id: config-servereureka: client: fetch-registry: true register-with-eureka: true healthcheck: enabled: true service-url: defaultZone: http://xxxx:xxxx@xxx.ydstudio.net:xxx/eureka/ instance: #instance-id默认值是主机名：应用名：应用端口 instance-id: $&#123;spring.application.name&#125;:$&#123;random.value&#125; #instance-id: $&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125; instance-id: $&#123;spring.cloud.client.ipAddress&#125;:$&#123;spring.application.name&#125;:$&#123;server.port&#125; hostname: $&#123;spring.cloud.client.ipAddress&#125; #hostname: $&#123;spring.application.name&#125; # 默认30s，表示eureka client发送心跳给server端的频率 lease-renewal-interval-in-seconds: 15 # 默认90s，表示eureka server至上一次收到client的心跳之后，等待下一次心跳的超时时间，在这个时间内若没收到下一次心跳，则将移除该instance lease-expiration-duration-in-seconds: 25 # 将自己的ip显示到EuekaServer上 prefer-ip-address: true 日志打印应用的状态： 1StatusChangeEvent [timestamp=1536481926709, current=UNKNOWN, previous=UP] 这些配置肯定没有什么问题，因为这些配置在没有挪到bootstrap.yml中之前都是可以正常使用的。现在Eureka注册中心却不能检测到应用的状态，这样让我百思不得其解。后来我在stackoverflow上找到了答案stackoverflow地址,问题只有一个答案，其中重要内容如下： 1eureka.client.healthcheck.enabled=true should only be set in application.yml. Setting the value in bootstrap.yml will cause undesirable side effects like registering in eureka with an UNKNOWN status. 知道这一点后我将bootstrap.yml中的内容修改如下面一样： 123456789101112131415161718spring: application: name: search-provider cloud: config: name: search-config profile: dev label: master #uri: http://localhost:9008 discovery: enabled: true service-id: config-servereureka: client: service-url: defaultZone: http://xxxx:xxxx@xxx.ydstudio.net:xxx/eureka/ 在Eureka注册中心中应用的状态就显示正常了！","categories":[],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://blog.ydstudio.net/tags/spring-cloud/"},{"name":"eureka","slug":"eureka","permalink":"https://blog.ydstudio.net/tags/eureka/"}]},{"title":"Elastic Search搜索数据Terms聚合返回的不正确的问题","slug":"Elastic-Search搜索数据Terms聚合返回的不正确的问题","date":"2018-08-30T23:37:03.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/39992895.html","link":"","permalink":"https://blog.ydstudio.net/post/39992895.html","excerpt":"项目中使用Elastic Search做搜索，在聚合产品的标签的时候，我发现标签的种类有很多超过了10个（这一点很重要），但是聚合标签出来的数据只有10个，缺少了很多标签，查询的语句如下：","text":"项目中使用Elastic Search做搜索，在聚合产品的标签的时候，我发现标签的种类有很多超过了10个（这一点很重要），但是聚合标签出来的数据只有10个，缺少了很多标签，查询的语句如下： 1234567891011121314151617181920212223242526272829&#123; \"from\" : 0, \"size\" : 15, \"query\" : &#123; \"bool\" : &#123; \"must\" : [ &#123; \"terms\" : &#123; \"categoryId\" : [ 1046, 1045, 1044 ] &#125; &#125;, &#123; \"terms\" : &#123; \"tagList.id\" : [ 1063, 1138, 1115, 1142 ] &#125; &#125; ] &#125; &#125;, \"aggregations\" : &#123; \"categoryId\" : &#123; \"terms\" : &#123; \"field\" : \"categoryId\" &#125; &#125;, \"tagList.tagContent\" : &#123; \"terms\" : &#123; \"field\" : \"tagList.tagContent\" &#125; &#125; &#125;&#125; 百思不得其解，看文档发现自己的查询和Terms的聚合使用都是没有任何问题的，但是出来的数据为什么会少呢？于是昨天上午花了将近一个小时的时间才找到问题的所在，下面是文档上对返回数据的一个解释：By default, the terms aggregation will return the buckets for the top ten terms ordered by the doc_count. One can change this default behaviour by setting the size parameter. SizeThe size parameter can be set to define how many term buckets should be returned out of the overall terms list. By default, the node coordinating the search process will request each shard to provide its own top size term buckets and once all shards respond, it will reduce the results to the final list that will then be returned to the client. This means that if the number of unique terms is greater than size, the returned list is slightly off and not accurate (it could be that the term counts are slightly off and it could even be that a term that should have been in the top size buckets was not returned). 原来Elastic Search对数据聚合默认返回10个，我聚合的数据术语桶超过了10个，可以自行设置size来返回不同数量的术语桶。于是乎，查询的语句修改成下面的样子就成功返回了所有的数据： 12345678910111213141516171819202122232425262728293031&#123; \"from\" : 0, \"size\" : 15, \"query\" : &#123; \"bool\" : &#123; \"must\" : [ &#123; \"terms\" : &#123; \"categoryId\" : [ 1046, 1045, 1044 ] &#125; &#125;, &#123; \"terms\" : &#123; \"tagList.id\" : [ 1063, 1138, 1115, 1142 ] &#125; &#125; ] &#125; &#125;, \"aggregations\" : &#123; \"categoryId\" : &#123; \"terms\" : &#123; \"field\" : \"categoryId\", \"size\" : 100 &#125; &#125;, \"tagList.tagContent\" : &#123; \"terms\" : &#123; \"field\" : \"tagList.tagContent\", \"size\" : 100 &#125; &#125; &#125;&#125; 其实我还有一个问题，在使用Range范围聚合的时候，发现聚合的数据不准确，就是说10-20本来就30条记录，但是聚合显示这个范围的数据只有10个，这个问题我暂时还没有找到原因，有人知道的话，我很高兴有人能告诉我！ 2018/10/12更新：对于上面的Range范围聚合不正确的原因已经找到，发现还是自己太过粗心，人家提供的开发文档没有仔细的看，终于我在2018/10/11的时候重新看了一下Elasticsearch Reference 5.5 » Aggregations » Bucket Aggregations » Range Aggregation,最开始的一段话就是问题的答案！ 1234567891011121314151617181920/*A multi-bucket value source based aggregation that enables the user to define a set of ranges - each representing a bucket. During the aggregation process, the values extracted from each document will be checked against each bucket range and \"bucket\" the relevant/matching document. Note that this aggregation includes the from value and excludes the to value for each range.Example:*/&#123; \"aggs\" : &#123; \"price_ranges\" : &#123; \"range\" : &#123; \"field\" : \"price\", \"ranges\" : [ &#123; \"to\" : 50 &#125;, &#123; \"from\" : 50, \"to\" : 100 &#125;, &#123; \"from\" : 100 &#125; ] &#125; &#125; &#125;&#125; 上面的统计的含义是： 统计价格小于50的总数 统计价格大于等于50，小于100的总数 统计价格大于等于100的总数 总之，就是统计包含下限，不包含上限。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"elasticSearch","slug":"elasticSearch","permalink":"https://blog.ydstudio.net/tags/elasticSearch/"}]},{"title":"IntelliJ Idea 常用快捷键列表","slug":"IntelliJ-Idea-常用快捷键列表","date":"2018-08-28T23:34:44.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/fea71f82.html","link":"","permalink":"https://blog.ydstudio.net/post/fea71f82.html","excerpt":"加粗的是我常用的快捷键","text":"加粗的是我常用的快捷键 Ctrl+Shift + Enter，语句完成“！”，否定完成，输入表达式时按 “！”键Ctrl+E，最近的文件Ctrl+Shift+E，最近更改的文件Shift+Click，可以关闭文件Ctrl+[ OR ]，可以跑到大括号的开头与结尾Ctrl+F12，可以显示当前文件的结构Ctrl+F7，可以查询当前元素在当前文件中的引用，然后按 F3 可以选择Ctrl+N，可以快速打开类Ctrl+Shift+N，可以快速打开文件Alt+Q，可以看到当前方法的声明Ctrl+P，可以显示参数信息Ctrl+Shift+Insert，可以选择剪贴板内容并插入Alt+Insert，可以生成构造器/Getter/Setter等Ctrl+Alt+V，可以引入变量。例如：new String(); 自动导入变量定义Ctrl+Alt+T，可以把代码包在一个块内，例如：try/catchCtrl+Enter，导入包，自动修正Ctrl+Alt+L，格式化代码Ctrl+Alt+I，将选中的代码进行自动缩进编排，这个功能在编辑 JSP 文件时也可以工作Ctrl+Alt+O，优化导入的类和包Ctrl+R，替换文本Ctrl+F，查找文本Ctrl+Shift+Space，自动补全代码Ctrl+空格，代码提示（与系统输入法快捷键冲突）Ctrl+Shift+Alt+N，查找类中的方法或变量Alt+Shift+C，最近的更改Alt+Shift+Up/Down，上/下移一行Shift+F6，重构 - 重命名Ctrl+X，删除行Ctrl+D，复制行Ctrl+/或Ctrl+Shift+/，注释（//或者//）Ctrl+J，自动代码（例如：serr）Ctrl+Alt+J，用动态模板环绕Ctrl+H，显示类结构图（类的继承层次）**Ctrl+Q，显示注释文档Alt+F1，查找代码所在位置Alt+1，快速打开或隐藏工程面板Ctrl+Alt+left/right，返回至上次浏览的位置Alt+left/right，切换代码视图Alt+Up/Down，在方法间快速移动定位Ctrl+Shift+Up/Down，向上/下移动语句F2 或 Shift+F2，高亮错误或警告快速定位Tab，代码标签输入完成后，按 Tab，生成代码Ctrl+Shift+F7，高亮显示所有该文本，按 Esc 高亮消失Alt+F3，逐个往下查找相同文本，并高亮显示Ctrl+Up/Down，光标中转到第一行或最后一行下Ctrl+B/Ctrl+Click，快速打开光标处的类或方法（跳转到定义处）Ctrl+Alt+B，跳转到方法实现处Ctrl+Shift+Backspace，跳转到上次编辑的地方Ctrl+O，重写方法Ctrl+Alt+Space，类名自动完成Ctrl+Alt+Up/Down，快速跳转搜索结果Ctrl+Shift+J，整合两行Alt+F8，计算变量值Ctrl+Shift+V，可以将最近使用的剪贴板内容选择插入到文本Ctrl+Alt+Shift+V，简单粘贴Shift+Esc，不仅可以把焦点移到编辑器上，而且还可以隐藏当前（或最后活动的）工具窗口F12，把焦点从编辑器移到最近使用的工具窗口Shift+F1，要打开编辑器光标字符处使用的类或者方法 Java 文档的浏览器Ctrl+W，可以选择单词继而语句继而行继而函数Ctrl+Shift+W，取消选择光标所在词Alt+F7，查找整个工程中使用地某一个类、方法或者变量的位置Ctrl+I，实现方法Ctrl+Shift+U，大小写转化Ctrl+Y，删除当前行Shift+Enter，向下插入新行psvm/sout，main/System.out.println(); Ctrl+J，查看更多Ctrl+Shift+F，全局查找Ctrl+F，查找/Shift+F3，向上查找/F3，向下查找Ctrl+Shift+S，高级搜索Ctrl+U，转到父类Ctrl+Alt+S，打开设置对话框Alt+Shift+Inert，开启/关闭列选择模式Ctrl+Alt+Shift+S，打开当前项目/模块属性Ctrl+G，定位行Alt+Home，跳转到导航栏Ctrl+Enter，上插一行Ctrl+Backspace，按单词删除Ctrl+”+/-“，当前方法展开、折叠Ctrl+Shift+”+/-“，全部展开、折叠【调试部分、编译】Ctrl+F2，停止Alt+Shift+F9，选择 DebugAlt+Shift+F10，选择 RunCtrl+Shift+F9，编译Ctrl+Shift+F10，运行Ctrl+Shift+F8，查看断点F8，步过F7，步入Shift+F7，智能步入Shift+F8，步出Alt+Shift+F8，强制步过Alt+Shift+F7，强制步入Alt+F9，运行至光标处Ctrl+Alt+F9，强制运行至光标处F9，恢复程序Alt+F10，定位到断点Ctrl+F8，切换行断点Ctrl+F9，生成项目Alt+1，项目Alt+2，收藏Alt+6，TODOAlt+7，结构Ctrl+Shift+C，复制路径Ctrl+Alt+Shift+C，复制引用，必须选择类名Ctrl+Alt+Y，同步Ctrl+，快速切换方案（界面外观、代码风格、快捷键映射等菜单）Shift+F12，还原默认布局Ctrl+Shift+F12，隐藏/恢复所有窗口Ctrl+F4，关闭Ctrl+Shift+F4，关闭活动选项卡Ctrl+Tab，转到下一个拆分器Ctrl+Shift+Tab，转到上一个拆分器【重构】Ctrl+Alt+Shift+T，弹出重构菜单Shift+F6，重命名F6，移动F5，复制Alt+Delete，安全删除Ctrl+Alt+N，内联【查找】Ctrl+F，查找Ctrl+R，替换F3，查找下一个Shift+F3，查找上一个Ctrl+Shift+F，在路径中查找Ctrl+Shift+R，在路径中替换Ctrl+Shift+S，搜索结构Ctrl+Shift+M，替换结构Alt+F7，查找用法Ctrl+Alt+F7，显示用法Ctrl+F7，在文件中查找用法Ctrl+Shift+F7，在文件中高亮显示用法【VCS】Alt+，VCS 操作菜单Ctrl+K，提交更改Ctrl+T，更新项目Ctrl+Alt+Shift+D，显示变化","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"ide","slug":"ide","permalink":"https://blog.ydstudio.net/tags/ide/"}]},{"title":"BigDecimal运算出现Non-terminating decimal expansion; no exact representable decimal result","slug":"BigDecimal运算出现Non-terminating-decimal-expansion-no-exact-representable-decimal-result","date":"2018-08-24T23:28:55.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/77a90911.html","link":"","permalink":"https://blog.ydstudio.net/post/77a90911.html","excerpt":"我们都知道Java提供了两个高精度计算的类:BigInteger和BigDeciaml。虽然它们大体上属于“包装器类”的范畴，但两者都没有对应的基本类型。BigDeciaml支持任意精度的定点数。例如，可以用它进行精确的货币计算。（以上摘自Java编程思想第4版）","text":"我们都知道Java提供了两个高精度计算的类:BigInteger和BigDeciaml。虽然它们大体上属于“包装器类”的范畴，但两者都没有对应的基本类型。BigDeciaml支持任意精度的定点数。例如，可以用它进行精确的货币计算。（以上摘自Java编程思想第4版） 最近的项目使用BigDeciaml，代码如下: 123456789101112131415161718/*** @param originPrice 原始货币金额* @param betweenCurrencyRate 原始货币兑换中间货币的汇率* @param toCurrencyRate 中间货币兑换目标货币的汇率* @return java.math.BigDecimal*/public static BigDecimal rate(BigDecimal originPrice,BigDecimal betweenCurrencyRate,BigDecimal toCurrencyRate)&#123; return originPrice.multiply(betweenCurrencyRate).divide(toCurrencyRate);&#125;BigDecimal chaoIn = exchangeRate.getChaoIn();BigDecimal cNYChaoIn = exchangeRateCNY.getChaoIn();adultPrice = RateExchangeUtil.rate(adultPrice,chaoIn,cNYChaoIn);childPrice = RateExchangeUtil.rate(childRetail.multiply(new BigDecimal(childNum)),chaoIn,cNYChaoIn);// 计算酒店里面总价hotelTotalPrice = hotelTotalPrice.add(childPrice).add(adultPrice); 在使用BigDecimal做运算的时候，出现了下面的异常： 1Non-terminating decimal expansion; no exact representable decimal result. 后来通过搜索得知，通过BigDecimal的divide方法进行除法时当不整除，出现无限循环小数时，就会抛出上面的异常。我们应该使用divide的重载方法： 123456789101112131415161718192021BigDecimal.divide(BigDecimal divisor, int scale, RoundingMode roundingMode) ;scale为小数位数；roundingMode为小数模式；ROUND_CEILING如果 BigDecimal 是正的，则做 ROUND_UP 操作；如果为负，则做 ROUND_DOWN 操作。ROUND_DOWN从不在舍弃(即截断)的小数之前增加数字。ROUND_FLOOR如果 BigDecimal 为正，则作 ROUND_UP ；如果为负，则作 ROUND_DOWN 。ROUND_HALF_DOWN若舍弃部分&gt; .5，则作 ROUND_UP；否则，作 ROUND_DOWN 。ROUND_HALF_EVEN如果舍弃部分左边的数字为奇数，则作 ROUND_HALF_UP ；如果它为偶数，则作 ROUND_HALF_DOWN 。ROUND_HALF_UP若舍弃部分&gt;=.5，则作 ROUND_UP ；否则，作 ROUND_DOWN 。ROUND_UNNECESSARY该“伪舍入模式”实际是指明所要求的操作必须是精确的，，因此不需要舍入操作。ROUND_UP总是在非 0 舍弃小数(即截断)之前增加数字。 最后修正rate方法中的问题，代码如下： 1234567891011121314151617/*** 货币转换 美元转加元，人民币作为中间货币* 美元 * 美元兑换人民币的汇率 / 人民币兑换加元的汇率* 出现问题 Non-terminating decimal expansion; no exact representable decimal result.* 要指定 divide的后两个参数* JAVA中如果用BigDecimal做除法的时候一定要在divide方法中传递scale参数，* 定义精确到小数点后几位，否则在不整除的情况下，结果是无限循环小数时，就会抛出以上异常。** @param originPrice 原始货币金额* @param betweenCurrencyRate 原始货币兑换中间货币的汇率* @param toCurrencyRate 中间货币兑换目标货币的汇率* @return java.math.BigDecimal*/public static BigDecimal rate(BigDecimal originPrice,BigDecimal betweenCurrencyRate,BigDecimal toCurrencyRate)&#123; return originPrice.multiply(betweenCurrencyRate).divide(toCurrencyRate,4,BigDecimal.ROUND_HALF_UP);&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"BigDecimal","slug":"BigDecimal","permalink":"https://blog.ydstudio.net/tags/BigDecimal/"}]},{"title":"Nginx实现反向代理 Node.js","slug":"Nginx实现反向代理-Node-js","date":"2018-08-07T23:25:53.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/45183e9d.html","link":"","permalink":"https://blog.ydstudio.net/post/45183e9d.html","excerpt":"公司有项目前端是用node.js进行服务器渲染，然后再返回给浏览器，进而解决单页面的SEO问题。项目部署的时候，使用Nginx反向代理Node.js。具体的步骤如下：","text":"公司有项目前端是用node.js进行服务器渲染，然后再返回给浏览器，进而解决单页面的SEO问题。项目部署的时候，使用Nginx反向代理Node.js。具体的步骤如下： （Nginx、Node.js的安装和基本配置直接跳过） 首先我们要在nginx.cnf文件中的http节点打开下面的配置： 12345678910111213141516171819http &#123; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # 打开这一行的配置 include /etc/nginx/conf.d/*.conf;&#125; 然后每个域名的配置文件就放到这个目录/etc/nginx/conf.d/下，文件后缀以conf结束。 第一种方式，这种简单： 12345678910111213141516171819202122232425262728293031323334server &#123; listen 80 ; server_name localhost; root /xxx/xxx/hxxydexx/; #set $my_server_name $scheme://$server_name; #if ( $my_server_name != https://$server_name ) &#123; # rewrite ^ https://$server_name$request_uri? permanent; #&#125; error_log /var/log/nginx/hyde_error.log error; access_log /var/log/nginx/hyde_accss.log main; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; # 不需要考虑到负载的，就无需配置upstream节点。 proxy_pass http://127.0.0.1:3000; &#125; error_page 404 /404.html; location = /xxx/xxx/40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /xxx/xxx/50x.html &#123; &#125;&#125; 2.第二种方式，考虑到负载 12345678910111213141516171819202122232425262728293031323334353637upstream node &#123; server 127.0.0.1:3000; &#125;server &#123; listen 80 ; server_name localhost; root /xxx/xxx/hxxydexx/; #set $my_server_name $scheme://$server_name; #if ( $my_server_name != https://$server_name ) &#123; # rewrite ^ https://$server_name$request_uri? permanent; #&#125; error_log /var/log/nginx/hyde_error.log error; access_log /var/log/nginx/hyde_accss.log main; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; proxy_http_version 1.1; proxy_set_header Connection \"\"; # 配置upstream节点 proxy_pass http://node; &#125; error_page 404 /404.html; location = /xxx/xxx/40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /xxx/xxx/50x.html &#123; &#125;&#125; 然后重启或者重新载入nginx的配置文件即可。命令如下： 12345678#检查nginx配置文件中语法是否正确nginx -t#重启nginxservice nginx restart#重载配置文件nginx -s reload 注意问题：上面可能会出现下面的问题： 1234567891011121314events.js:72 throw er; // Unhandled 'error' event ^Error: listen EADDRINUSE at errnoException (net.js:884:11) at Server._listen2 (net.js:1022:14) at listen (net.js:1044:10) at Server.listen (net.js:1110:5) at Object.&lt;anonymous&gt; (folderName/app.js:33:24) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Function.Module.runMain (module.js:497:10) 这个其实是Node.js服务多开端口被占用导致的报错，出现这种问题，可以使用Node.js项目管理工具pm2，或者使用netstat -anop进行查看端口被那个进程占用，然后杀掉重启服务！ 附上Nginx的负载均衡策略： 轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 1234upstream backserver &#123; server 192.168.0.14; server 192.168.0.15; &#125; 指定权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream backserver &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10; &#125; IP绑定 ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345678910111213141516171819202122232425262728upstream backserver &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; ``` - fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。```bashupstream backserver &#123; server 192.168.0.14:88; server 192.168.0.15:80; fair; &#125; ``` - url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 ```bashupstream backserver &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"},{"name":"proxy","slug":"proxy","permalink":"https://blog.ydstudio.net/tags/proxy/"}]},{"title":"Java学习系列文章第九篇：Java中泛型的学习","slug":"Java学习系列文章第九篇：Java中泛型的学习","date":"2018-08-04T23:03:24.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/d9ad2c86.html","link":"","permalink":"https://blog.ydstudio.net/post/d9ad2c86.html","excerpt":"什么是泛型Java 泛型（generics）是 JDK5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。(PHP就不需要泛型，哈哈)","text":"什么是泛型Java 泛型（generics）是 JDK5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。(PHP就不需要泛型，哈哈) 下面我们看一道关于Java泛型的经典测试题： 1234List&lt;String&gt; list1 = new ArrayList&lt;String&gt;();List&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();System.out.println(list1.getClass() == list2.getClass()); 上面代码最终结果输出的是什么？不了解泛型的和很熟悉泛型的同学应该能够答出来，而对泛型有所了解，但是了解不深入的同学可能会答错。 正确答案是 true。 上面提到了泛型的本质是类型参数化，如何解释类型参数化呢？ 123456789101112public class Cache &#123; Object value; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125;&#125; 这样的 Cache 是能够存取任何类型的值，但是我们在使用的时候会有点麻烦。我们要获取真正的类型，就要进行类型的强制转换了。 12345Cache cache = new Cache();cache.setValue(134);int value = (int) cache.getValue();cache.setValue(\"hello\");String value1 = (String) cache.getValue(); 这样的编程真的是太麻烦了，万一忘记了存放变量的类型，程序在运行的时候就会报类型转换错误。于是在JDK5 中引用的泛型给我们带来了另一番编程体验。 123456789101112public class Cache&lt;T&gt; &#123; T value; public Object getValue() &#123; return value; &#125; public void setValue(T value) &#123; this.value = value; &#125;&#125; 这就是泛型，它将 value 这个属性的类型也参数化了，这就是所谓的参数化类型。再看它的使用方法。 1234567Cache&lt;String&gt; cache1 = new Cache&lt;String&gt;();cache1.setValue(\"123\");String value2 = cache1.getValue();Cache&lt;Integer&gt; cache2 = new Cache&lt;Integer&gt;();cache2.setValue(123);int value3 = cache2.getValue(); 最显而易见的好处就是它不再需要对取出来的结果进行强制转换了。但，还有另外一点不同。泛型除了可以将类型参数化外，而参数一旦确定好，如果类似不匹配，编译器就不通过。综合上面信息，我们可以得到下面的结论: 与普通的 Object 代替一切类型这样简单粗暴而言，泛型使得数据的类别可以像参数一样由外部传递进来。它提供了一种扩展能力。它更符合面向抽象开发的软件编程宗旨。 当具体的类型确定后，泛型又提供了一种类型检测的机制，只有相匹配的数据才能正常的赋值，否则编译器就不通过。所以说，它是一种类型安全检测机制，一定程度上提高了软件的安全性防止出现低级的失误。 泛型提高了程序代码的可读性，不必要等到运行的时候才去强制转换，在定义或者实例化阶段，因为 Cache 这个类型显化的效果，程序员能够一目了然猜测出代码要操作的数据类型。 泛型的定义和使用泛型按照使用情况可以分为 3 种。 泛型类 泛型方法 泛型接口 泛型类那如何定义泛型类呢？ 123public class Test&lt;T&gt; &#123; T field;&#125; 尖括号 &lt;&gt; 中的 T 被称作是类型参数，用于指代任何类型。事实上，T 只是一种习惯性写法，如果你愿意。你可以这样写。 123public class Test&lt;TMD&gt; &#123; TMD field;&#125; 但出于规范的目的，Java 还是建议我们用单个大写字母来代表类型参数。常见的如： T 代表一般的任何类。 E 代表Element 的意思，或者是Exception 异常的意思 K 代表 Key 的意思 V 代表 Value 的意思，通常与 K 一起配合使用 S 代表 Subtype 的意思 如果一个类被 的形式定义，那么它就被称为泛型类。那么对于泛型类怎么样使用呢？ 12Test&lt;String&gt; test1 = new Test&lt;&gt;();Test&lt;Integer&gt; test2 = new Test&lt;&gt;(); 只要在对泛型类创建实例的时候，在尖括号中赋值相应的类型便是。T 就会被替换成对应的类型，如 String 或者是 Integer。你可以相像一下，当一个泛型类被创建时，内部自动扩展成下面的代码。 123public class Test&lt;String&gt; &#123; String field;&#125; 当然，泛型类不是只能接受一个类型参数，它还可以这样接受多个类型参数。 123456789101112public class MultiType &lt;E,T&gt;&#123; E value1; T value2; public E getValue1()&#123; return value1; &#125; public T getValue2()&#123; return value2; &#125;&#125; 泛型方法123456public class Test1 &#123; public &lt;T&gt; void testMethod(T t)&#123; &#125;&#125; 泛型方法与泛型类稍有不同的地方是，类型参数也就是尖括号那一部分是写在返回值前面的。 中的 T 被称为类型参数，而方法中的 T 被称为参数化类型，它不是运行时真正的参数。 当然，声明的类型参数，其实也是可以当作返回值的类型的。 123public &lt;T&gt; T testMethod1(T t)&#123; return null;&#125; 泛型类与泛型方法的共存现象: 123456789public class Test&lt;T&gt;&#123; public void testMethod(T t)&#123; System.out.println(t.getClass().getName()); &#125; public &lt;T&gt; T testMethod1(T t)&#123; return t; &#125;&#125; 上面代码中，Test1 是泛型类，testMethod 是泛型类中的普通方法，而 testMethod1 是一个泛型方法。而泛型类中的类型参数与泛型方法中的类型参数是没有相应的联系的，泛型方法始终以自己定义的类型参数为准。 所以，针对上面的代码，我们可以这样编写测试代码。 123Test1&lt;String&gt; t = new Test1();t.testMethod(\"generic\");Integer i = t.testMethod1(new Integer(1)); 泛型类的实际类型参数是 String，而传递给泛型方法的类型参数是 Integer，两者不想干。 但是，为了避免混淆，如果在一个泛型类中存在泛型方法，那么两者的类型参数最好不要同名。比如，Test 代码可以更改为这样 123456789public class Test1&lt;T&gt;&#123; public void testMethod(T t)&#123; System.out.println(t.getClass().getName()); &#125; public &lt;E&gt; E testMethod1(E e)&#123; return e; &#125;&#125; 泛型接口泛型接口定义： 12public interface Iterable&lt;T&gt; &#123;&#125; 通配符 ？除了用 表示泛型外，还有 这种形式。？ 被称为通配符。 可能有同学会想，已经有了 的形式了，为什么还要引进 这样的概念呢？ 12345678class Base&#123;&#125;class Sub extends Base&#123;&#125;Sub sub = new Sub();Base base = sub; 上面代码显示，Base 是 Sub 的父类，它们之间是继承关系，所以 Sub 的实例可以给一个 Base 引用赋值，那么 12List&lt;Sub&gt; lsub = new ArrayList&lt;Sub&gt;();List&lt;Base&gt; lbase = lsub; 最后一行代码成立吗？编译会通过吗？ 答案是通过不了编译的。 编译器不会让它通过的。Sub 是 Base 的子类，不代表 List 和 List 有继承关系。 但是，在现实编码中，确实有这样的需求，希望泛型能够处理某一范围内的数据类型，比如某个类和它的子类，对此 Java 引入了通配符这个概念。 所以，通配符的出现是为了指定泛型中的类型范围。 通配符有 3 种形式: &lt;?&gt; 被称作无限定的通配符 &lt;? extends T&gt; 被称作有上限的通配符 &lt;? super T&gt; 被称作有下限的通配符 无限定通配符12public void testWildCards(Collection&lt;?&gt; collection)&#123;&#125; 上面的代码中，方法内的参数是被无限定通配符修饰的 Collection 对象，它隐略地表达了一个意图或者可以说是限定，那就是 testWidlCards() 这个方法内部无需关注 Collection 中的真实类型，因为它是未知的。所以，你只能调用 Collection 中与类型无关的方法。 1234567891011121314public class TestWildCards&#123; public void testWildCards(Collection&lt;?&gt; collection)&#123; #报错 collection.add(123); #报错 collection.add(\"hello\"); #报错 collection.add(new Object()); collection.iterator().next(); collection.size(); &#125;&#125; 我们可以看到，当 &lt;?&gt; 存在时，Collection 对象丧失了 add() 方法的功能，编译器不通过。我们再看下面的代码： 12List&lt;?&gt; wildlist = new ArrayList&lt;String&gt;();wildlist.add(123);// 编译不通过 有人说，&lt;?&gt; 提供了只读的功能，也就是它删减了增加具体类型元素的能力，只保留与具体类型无关的功能。它不管装载在这个容器内的元素是什么类型，它只关心元素的数量、容器是否为空？我想这种需求还是很常见的吧。 有同学可能会想，&lt;?&gt; 既然作用这么渺小，那么为什么还要引用它呢？ 个人认为，提高了代码的可读性，程序员看到这段代码时，就能够迅速对此建立极简洁的印象，能够快速推断源码作者的意图。 &lt;? extends T&gt;&lt;?&gt; 代表着类型未知，但是我们的确需要对于类型的描述再精确一点，我们希望在一个范围内确定类别，比如类型 A 及 类型 A 的子类都可以。 123public void testSub(Collection&lt;? extends Base&gt; para)&#123;&#125; 上面代码中，para 这个 Collection 接受 Base 及 Base 的子类的类型。但是，它仍然丧失了写操作的能力。也就是说: 12para.add(new Sub());para.add(new Base()); 仍然编译不通过。没有关系，我们不知道具体类型，但是我们至少清楚了类型的范围。 &lt;? super T&gt;这个和 &lt;? extends T&gt; 相对应，代表 T 及 T 的超类。 123public void testSuper(Collection&lt;? super Sub&gt; para)&#123;&#125;` &lt;? super T&gt; 神奇的地方在于，它拥有一定程度的写操作的能力。 1234public void testSuper(Collection&lt;? super Sub&gt; para)&#123; para.add(new Sub());//编译通过 para.add(new Base());//编译不通过&#125; 通配符与类型参数的区别一般而言，通配符能干的事情都可以用类型参数替换。比如: 12public void testWildCards(Collection&lt;?&gt; collection)&#123;&#125; 可以被 12public &lt;T&gt; void test(Collection&lt;T&gt; collection)&#123;&#125; 取代。值得注意的是，如果用泛型方法来取代通配符，那么上面代码中 collection 是能够进行写操作的。只不过要进行强制转换。 1234public &lt;T&gt; void test(Collection&lt;T&gt; collection)&#123; collection.add((T)new Integer(12)); collection.add((T)\"123\");&#125; 需要特别注意的是，类型参数适用于参数之间的类别依赖关系，举例说明: 123456789public class Test2 &lt;T,E extends T&gt;&#123; T value1; E value2;&#125;public &lt;D,S extends D&gt; void test(D d,S s)&#123;&#125; E 类型是 T 类型的子类，显然这种情况类型参数更适合。有一种情况是，通配符和类型参数一起使用。 123public &lt;T&gt; void test(T t,Collection&lt;? extends T&gt; collection)&#123;&#125; 如果一个方法的返回类型依赖于参数的类型，那么通配符也无能为力。 123public T test1(T t)&#123; return value1;&#125; 类型擦除泛型是 Java 1.5 版本才引进的概念，在这之前是没有泛型的概念的，但显然，泛型代码能够很好地和之前版本的代码很好地兼容。 这是因为，泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除。 通俗地讲，泛型类和普通类在 java 虚拟机内是没有什么特别的地方。回顾文章开始时的那段代码: 1234List&lt;String&gt; list1 = new ArrayList&lt;String&gt;();List&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();System.out.println(list1.getClass() == list2.getClass()); 打印的结果为 true 是因为 List 和 List 在 jvm 中的 Class 都是 List.class。 泛型信息被擦除了。 可能同学会问，那么类型 String 和 Integer 怎么办？ 答案是泛型转译。 12345678public class Erasure &lt;T&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125;&#125; Erasure 是一个泛型类，我们查看它在运行时的状态信息可以通过反射。 123456Erasure&lt;String&gt; erasure = new Erasure&lt;String&gt;(\"hello\");Class eclz = erasure.getClass();System.out.println(\"erasure class is:\"+eclz.getName());#打印的结果是erasure class is:com.frank.test.Erasure Class 的类型仍然是 Erasure 并不是 Erasure 这种形式，那我们再看看泛型类中 T 的类型在 jvm 中是什么具体类型。 1234567Field[] fs = eclz.getDeclaredFields();for ( Field f:fs) &#123; System.out.println(\"Field name \"+f.getName()+\" type:\"+f.getType().getName());&#125;#打印结果是Field name object type:java.lang.Object 那我们可不可以说，泛型类被类型擦除后，相应的类型就被替换成 Object 类型呢？ 这种说法，不完全正确。 我们更改一下代码。 123456789101112public class Erasure &lt;T extends String&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125;&#125;#现在再看测试结果：Field name object type:java.lang.String 我们现在可以下结论了，在泛型类被类型擦除的时候，之前泛型类中的类型参数部分如果没有指定上限，如 则会被转译成普通的 Object 类型，如果指定了上限如 则类型参数就被替换成类型上限。 所以，在反射中: 123456789101112public class Erasure &lt;T&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125; public void add(T object)&#123; &#125;&#125; add() 这个方法对应的 Method 的签名应该是 Object.class。 123456789101112Erasure&lt;String&gt; erasure = new Erasure&lt;String&gt;(\"hello\");Class eclz = erasure.getClass();System.out.println(\"erasure class is:\"+eclz.getName());Method[] methods = eclz.getDeclaredMethods();for ( Method m:methods )&#123; System.out.println(\" method:\"+m.toString());&#125;#打印结果是method:public void com.frank.test.Erasure.add(java.lang.Object) 也就是说，如果你要在反射中找到 add 对应的 Method，你应该调用 getDeclaredMethod(“add”,Object.class) 否则程序会报错，提示没有这么一个方法，原因就是类型擦除的时候，T 被替换成 Object 类型了。 泛型中值得注意的地方泛型类或者泛型方法中，不接受 8 种基本数据类型。12345678// 这种是错误的使用方式List&lt;int&gt; li = new ArrayList&lt;&gt;();List&lt;boolean&gt; li = new ArrayList&lt;&gt;();// 需要使用它们对应的包装类List&lt;Integer&gt; li = new ArrayList&lt;&gt;();List&lt;Boolean&gt; li1 = new ArrayList&lt;&gt;();` 对泛型方法的困惑123public &lt;T&gt; T test(T t)&#123; return null;&#125; 有的同学可能对于连续的两个 T 感到困惑，其实 是为了说明类型参数，是声明,而后面的不带尖括号的 T 是方法的返回值类型。你可以相像一下，如果 test() 这样被调用: 123test(\"123\");// 那么实际上相当于public String test(String t); Java 不能创建具体类型的泛型数组这句话可能难以理解，用代码来说明： 12List&lt;Integer&gt;[] li2 = new ArrayList&lt;Integer&gt;[];List&lt;Boolean&gt; li3 = new ArrayList&lt;Boolean&gt;[]; 这两行代码是无法在编译器中编译通过的。原因还是类型擦除带来的影响。 List 和 List 在 jvm 中等同于List ，所有的类型信息都被擦除，程序也无法分辨一个数组中的元素类型具体是 List类型还是 List 类型。但是， 123List&lt;?&gt;[] li3 = new ArrayList&lt;?&gt;[10];li3[1] = new ArrayList&lt;String&gt;();List&lt;?&gt; v = li3[1]; 借助于无限定通配符却可以，前面讲过 ？ 代表未知类型，所以它涉及的操作都基本上与类型无关，因此 jvm 不需要针对它对类型作判断，因此它能编译通过，但是，只提供了数组中的元素因为通配符原因，它只能读，不能写。比如，上面的 v 这个局部变量，它只能进行 get() 操作，不能进行 add() 操作，这个在前面通配符的内容小节中已经讲过。 泛型，并不神奇我们可以看到，泛型其实并没有什么神奇的地方，泛型代码能做的非泛型代码也能做。 而类型擦除，是泛型能够与之前的 java 版本代码兼容共存的原因。 可量也正因为类型擦除导致了一些隐患与局限。 但，我还是要建议大家使用泛型，如官方文档所说的，如果可以使用泛型的地方，尽量使用泛型。 毕竟它抽离了数据类型与代码逻辑，本意是提高程序代码的简洁性和可读性，并提供可能的编译时类型转换安全检测功能。 类型擦除不是泛型的全部，但是它却能很好地检测我们对于泛型这个概念的理解程度。来源：blog.csdn.net/briblue/article/details/76736356","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"Centos 6.x 安装git","slug":"Centos-6-x-安装git","date":"2018-08-03T23:01:47.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/7226e685.html","link":"","permalink":"https://blog.ydstudio.net/post/7226e685.html","excerpt":"在Centos上安装软件时，我都是先更新一下系统的yum源，保持yum源是比较新的。","text":"在Centos上安装软件时，我都是先更新一下系统的yum源，保持yum源是比较新的。 1yum update 下面进入今日的主题，安装git： 1.下载源码包查看系统yum源中的git的版本，发现是比较老的版本，于是采用源码包编译安装。 12cd /usr/local/srcwget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.9.0.tar.gz 2.编译安装 123456cd /usr/local/srctar -zxvf git-2.9.0.tar.gz cd /usr/local/src/git-2.9.0#安装到 /usr/local/git./configure prefix=/usr/local/git make &amp;&amp; make instal 报错 12345[root@iZbp1fuxiq5o2qp7z60ydpZ git-2.9.0]# make &amp;&amp; make install CC credential-store.oIn file included from credential-store.c:1:0:cache.h:40:18: fatal error: zlib.h: No such file or directory #include &lt;zlib.h&gt; 解决方法： 12#安装依赖yum -y install zlib zlib-devel 再次执行make，仍然报错 12345/usr/bin/perl Makefile.PL PREFIX='/usr/local/git' INSTALL_BASE='' --localedir='/usr/local/git/share/locale'Can't locate ExtUtils/MakeMaker.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at Makefile.PL line 3.BEGIN failed--compilation aborted at Makefile.PL line 3.make[1]: *** [perl.mak] Error 2make: *** [perl/perl.mak] Error 2 解决办法： 12#安装下面的依赖yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker cpan 再次执行make &amp; make install，编译安装成功 3.创建git用户，并将/usr/local/git所属组和所属主修改成git 123useradd gitchown -R git:git /usr/local/git 4.将git加到系统环境变量里面 12export GIT_HOME=/usr/local/gitexport PATH=$GIT_HOME/bin:$PATH 5.初始化仓库 123456git init --bare mt-front.git#下面是几种克隆方式git clone git@xx.xx.xx.xx:/home/git/repository/mt-front.gitgit clone ssh://git@xx.xx.xx.xx:/home/git/repository/mt-front.gitgit clone http://git@xx.xx.xx.xx:/home/git/repository/mt-front.git 本地clone的时候会报错 提示git-upload-pack命令不存在123bash: git-upload-pack: command not found#解决ln -s /usr/local/git/bin/git-upload-pack /usr/bin/git-upload-pack 提示git-receive-pack命令不存在12bash: git-receive-pack: command not foundln -s /usr/local/git/bin/git-receive-pack /usr/bin/git-receive-pack 7.配置git记住密码，在git的全局配置文件gitconfig文件中添加下面的配置： 12345[credential] helper = store[user] name = nick email = nick@da.com","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"git","slug":"git","permalink":"https://blog.ydstudio.net/tags/git/"}]},{"title":"Maven跳过单元测试-Dmaven.test.skip和skipTests的区别","slug":"Maven跳过单元测试-Dmaven-test-skip和skipTests的区别","date":"2018-08-01T22:46:25.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/64d34904.html","link":"","permalink":"https://blog.ydstudio.net/post/64d34904.html","excerpt":"Maven中有两种方式跳过单元测试，其实这两种方式是有一点不同的，其具体不同如下： -DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。-Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。","text":"Maven中有两种方式跳过单元测试，其实这两种方式是有一点不同的，其具体不同如下： -DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。-Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。 使用Dmaven.test.skip，不但跳过单元测试的运行，也跳过测试代码的编译。1mvn package -Dmaven.test.skip=true 也可以在pom.xml文件中修改12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugin&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; 使用 mvn package -DskipTests 跳过单元测试，但是会继续编译；如果没时间修改单元测试的bug，或者单元测试编译错误。使用上面的，不要用这个。12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://blog.ydstudio.net/tags/maven/"}]},{"title":"Java学习系列文章第八篇：Java8中方法引用","slug":"Java学习系列文章第八篇：Java8中方法引用","date":"2018-07-30T22:15:58.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/bcbb06a2.html","link":"","permalink":"https://blog.ydstudio.net/post/bcbb06a2.html","excerpt":"方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。","text":"方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 下面，我们以定义了4个方法的Car这个类作为例子，区分Java中支持的4种不同的方法引用。 1234567891011121314151617public static class Car &#123; public static Car create( final Supplier&lt; Car &gt; supplier ) &#123; return supplier.get(); &#125; public static void collide( final Car car ) &#123; System.out.println( \"Collided \" + car.toString() ); &#125; public void follow( final Car another ) &#123; System.out.println( \"Following the \" + another.toString() ); &#125; public void repair() &#123; System.out.println( \"Repaired \" + this.toString() ); &#125;&#125; 第一种方法引用是构造器引用，它的语法是Class::new，或者更一般的Class&lt; T &gt;::new。请注意构造器没有参数。 12final Car car = Car.create( Car::new );final List&lt; Car &gt; cars = Arrays.asList( car ); 第二种方法引用是静态方法引用，它的语法是Class::static_method。请注意这个方法接受一个Car类型的参数。 1cars.forEach( Car::collide ); 第三种方法引用是特定类的任意对象的方法引用，它的语法是Class::method。请注意，这个方法没有参数。 1cars.forEach( Car::repair ); 最后，第四种方法引用是特定对象的方法引用，它的语法是instance::method。请注意，这个方法接受一个Car类型的参数 12final Car police = Car.create( Car::new );cars.forEach( police::follow ); 运行上面的Java程序在控制台上会有下面的输出（Car的实例可能不一样）： 123Collided com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197dRepaired com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197dFollowing the com.javacodegeeks.java8.method.references.MethodReferences$Car@7a81197d 关于方法引用的更多详情请参考官方文档。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"Java学习系列文章第七篇：Java8中接口的默认方法与静态方法","slug":"Java学习系列文章第七篇：Java8中接口的默认方法与静态方法","date":"2018-07-30T22:04:59.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/cca5e66b.html","link":"","permalink":"https://blog.ydstudio.net/post/cca5e66b.html","excerpt":"Java8用默认方法与静态方法这两个新概念来扩展接口的声明。默认方法使接口有点像Traits（Scala中特征(trait)类似于Java中的Interface，但它可以包含实现代码，也就是目前Java8新增的功能。PHP中也有trait这样一说，他是在不破坏类原有的继承、实现关系，给类新加相同的方法），但与传统的接口又有些不一样，它允许在已有的接口中添加新方法，而同时又保持了与旧版本代码的兼容性。","text":"Java8用默认方法与静态方法这两个新概念来扩展接口的声明。默认方法使接口有点像Traits（Scala中特征(trait)类似于Java中的Interface，但它可以包含实现代码，也就是目前Java8新增的功能。PHP中也有trait这样一说，他是在不破坏类原有的继承、实现关系，给类新加相同的方法），但与传统的接口又有些不一样，它允许在已有的接口中添加新方法，而同时又保持了与旧版本代码的兼容性。 默认方法与抽象方法不同之处在于抽象方法必须要求实现，但是默认方法则没有这个要求。相反，每个接口都必须提供一个所谓的默认实现，这样所有的接口实现者将会默认继承它（如果有必要的话，可以覆盖这个默认实现）。让我们看看下面的例子： 1234567891011121314151617private interface Defaulable &#123; // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() &#123; return \"Default implementation\"; &#125; &#125; private static class DefaultableImpl implements Defaulable &#123;&#125; private static class OverridableImpl implements Defaulable &#123; @Override public String notRequired() &#123; return \"Overridden implementation\"; &#125;&#125; Defaulable接口用关键字default声明了一个默认方法notRequired()，Defaulable接口的实现者之一DefaultableImpl实现了这个接口，并且让默认方法保持原样。Defaulable接口的另一个实现者OverridableImpl用自己的方法覆盖了默认方法。 Java8带来的另一个有趣的特性是接口可以声明（并且可以提供实现）静态方法。例如： 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; 下面的一小段代码片段把上面的默认方法与静态方法黏合到一起。 1234567public static void main( String[] args ) &#123; Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() );&#125; 这个程序的控制台输出如下： 12Default implementationOverridden implementation 在JVM中，默认方法的实现是非常高效的，并且通过字节码指令为方法调用提供了支持。默认方法允许继续使用现有的Java接口，而同时能够保障正常的编译过程。这方面好的例子是大量的方法被添加到java.util.Collection接口中去：stream()，parallelStream()，forEach()，removeIf()，…… 尽管默认方法非常强大，但是在使用默认方法时我们需要小心注意一个地方：在声明一个默认方法前，请仔细思考是不是真的有必要使用默认方法，因为默认方法会带给程序歧义，并且在复杂的继承体系中容易产生编译错误。更多详情请参考 官方文档","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"interface","slug":"interface","permalink":"https://blog.ydstudio.net/tags/interface/"}]},{"title":"Maven中的dependencyManagement和dependencies","slug":"Maven中的dependencyManagement和dependencies","date":"2018-07-28T22:19:50.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/c65e0153.html","link":"","permalink":"https://blog.ydstudio.net/post/c65e0153.html","excerpt":"最近公司的数据中心项目是使用Maven进行管理，在开发的过程中遇到了dependencyManagement和dependencies，不知道大家对这两个元素有什么想法？ Maven使用dependencyManagement元素来提供了一种管理依赖版本号的方式。通常会在一个组织或者项目的最顶层的父POM 中看到dependencyManagement 元素。使用pom.xml中的dependencyManagement元素能让所有在子项目中引用一个依赖而不用显式的列出版本号。Maven会沿着父子层次向上走，直到找到一个拥有dependencyManagement元素的项目，然后它就会使用在这个dependencyManagement 元素中指定的版本号。","text":"最近公司的数据中心项目是使用Maven进行管理，在开发的过程中遇到了dependencyManagement和dependencies，不知道大家对这两个元素有什么想法？ Maven使用dependencyManagement元素来提供了一种管理依赖版本号的方式。通常会在一个组织或者项目的最顶层的父POM 中看到dependencyManagement 元素。使用pom.xml中的dependencyManagement元素能让所有在子项目中引用一个依赖而不用显式的列出版本号。Maven会沿着父子层次向上走，直到找到一个拥有dependencyManagement元素的项目，然后它就会使用在这个dependencyManagement 元素中指定的版本号。 dependencyManagement例如，在父模块中的pom： 12345678910111213141516&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.dm&lt;/groupId&gt; &lt;artifactId&gt;mt-model&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dm&lt;/groupId&gt; &lt;artifactId&gt;mt-tool&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependencies&gt; &lt;/dependencyManagement&gt; 然后我们在子模块里就可以这样引用mt-model和mt-tool: 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.dm&lt;/groupId&gt; &lt;artifactId&gt;mt-model&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dm&lt;/groupId&gt; &lt;artifactId&gt;mt-tool&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 发现两者有什么区别了么？其实就是在子模块中引用pom没有添加版本号。 这样做的好处就是：如果有多个子项目都引用同一样依赖，则可以避免在每个使用的子项目里都声明一个版本号，这样当想升级或切换到另一个版本时，只需要在顶层父容器里更新，而不需要一个一个子项目的修改 ；另外如果某个子项目需要另外的一个版本，只需要声明version就可。dependencyManagement里只是声明依赖，并不实现引入，因此子项目需要显式的声明需要用的依赖。 dependencies相对于dependencyManagement，所有声明在dependencies里的依赖都会自动引入，并默认被所有的子项目继承。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://blog.ydstudio.net/tags/maven/"}]},{"title":"Spring Boot 1.x 使用Value注解给静态变量赋值","slug":"Spring-Boot-1-x-使用Value注解给静态变量赋值","date":"2018-07-18T22:18:41.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/54acd1d8.html","link":"","permalink":"https://blog.ydstudio.net/post/54acd1d8.html","excerpt":"昨天在使用@Value注解给静态变量赋值的时候，发现静态变量的值始终是null。后来搜索一下得知其中原因，Spring Boot 不允许/不支持把值注入到静态变量中。但是我们可以变通一下解决这个问题。因为Spring Boot支持set方法注入，我们可以利用非静态set方法注入静态变量。","text":"昨天在使用@Value注解给静态变量赋值的时候，发现静态变量的值始终是null。后来搜索一下得知其中原因，Spring Boot 不允许/不支持把值注入到静态变量中。但是我们可以变通一下解决这个问题。因为Spring Boot支持set方法注入，我们可以利用非静态set方法注入静态变量。 废话不多说，贴上我昨天写的代码： 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class CoverImageUtil &#123; private static String endpoint; private static String bucketName; @Value(\"$&#123;oss.endpoint&#125;\") private void setEndpoint(String name)&#123; endpoint = name; &#125; @Value(\"$&#123;oss.bucketName&#125;\") private void setBucketName(String name)&#123; bucketName = name; &#125; public static String getImage(String path)&#123; if (StringUtils.isEmpty(path))&#123; return null; &#125; // XXX的图片地址 https://oss.XXX.com/uploads/8F/70/8F70879210F08AAA6F4A04A3D42F3704.jpg if (path.contains(\"oss.XXX.com\"))&#123; return path; &#125; String[] str = path.split(\",\"); // mt的图片地址 // key = customer/coverImg/1002,FAFA5EFEAF3CBE3B23B2748D13E629A1,418530,image/jpeg // url = https://m-t-tesing.oss-cn-hangzhou.aliyuncs.com/customer/coverImg/1002 StringBuilder url = new StringBuilder(\"https://\"); url.append(bucketName) .append(\".\") .append(endpoint) .append(\"/\") .append(str[0]); return url.toString(); &#125;&#125; 注意 代码中需要@Component注解 set方法要是非静态的","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"}]},{"title":"Mybatis方法传多个参数（三种解决方案）","slug":"Mybatis方法传多个参数（三种解决方案）","date":"2018-07-01T22:17:31.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/98398c3d.html","link":"","permalink":"https://blog.ydstudio.net/post/98398c3d.html","excerpt":"Mybatis的Mapper接口的参数，一般是一个对象，但如果不是对象，并且有多个参数的时候我们应该怎样做呢？ 我们的第一个想法是把参数封装成一个java.util.Map类型，然后在方法的注释上面写上map的key是什么，但是，这样的做法明显不够直观，不能够清楚的看出方法的参数是什么，而且影响到了java的多态性（方法名相同，参数数量或类型不同）。","text":"Mybatis的Mapper接口的参数，一般是一个对象，但如果不是对象，并且有多个参数的时候我们应该怎样做呢？ 我们的第一个想法是把参数封装成一个java.util.Map类型，然后在方法的注释上面写上map的key是什么，但是，这样的做法明显不够直观，不能够清楚的看出方法的参数是什么，而且影响到了java的多态性（方法名相同，参数数量或类型不同）。 1.多个形参传递多参数Dao层的函数方法 1public User selectUser(String name,String area); 对应的Mapper.xml文件 123&lt;select id=\"selectUser\" resultMap=\"BaseResultMap\"&gt; select * from user_user where user_name = #&#123;0&#125; and user_area=#&#123;1&#125;&lt;/select&gt; 其中，#{0}代表接收的是dao层中的第一个参数，#{1}代表dao层中第二参数，更多参数以此类推即可。 2.采用Map传递多参数Dao层的函数方法 1public User selectUser(Map paramMap); 对应的Mapper.xml文件 123&lt;select id=\"selectUser\" resultMap=\"BaseResultMap\"&gt; select * from user_user where user_name = #&#123;userName,jdbcType=VARCHAR&#125; and user_area=#&#123;userArea,jdbcType=VARCHAR&#125;&lt;/select&gt; Service层调用 123456private User SelectUser()&#123; Map paramMap = new hashMap(); paramMap.put(“userName”,”对应具体的参数值”); paramMap.put(“userArea”,”对应具体的参数值”); User user = xxx.selectUser(paramMap); &#125; 这种方法不够直观，看到接口方法不能直接的知道需要传递的参数有哪些？ 3.使用@param注解Dao层的函数方法 1public User selectUser(@Param(“userName”)String name,@Param(“userArea”)String area); 对应的Mapper.xml文件 123&lt;select id=\"selectUser\" resultMap=\"BaseResultMap\"&gt; select * from user_user where user_name = #&#123;userName，jdbcType=VARCHAR&#125;and user_area=#&#123;userArea,jdbcType=VARCHAR&#125;&lt;/select&gt; 这种方法最好，能让开发者看到dao层方法就知道该传什么样的参数，在xml中也相比其他两种方法清楚。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://blog.ydstudio.net/tags/mybatis/"}]},{"title":"Java学习系列文章第六篇：项目开发利器-Maven","slug":"Java学习系列文章第六篇：项目开发利器-Maven","date":"2018-06-29T22:03:43.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/1c04f2f4.html","link":"","permalink":"https://blog.ydstudio.net/post/1c04f2f4.html","excerpt":"什么是MavenMaven是现在的Java程序员应该都会遇到或使用的一个工具。那Maven具体是什么？到底能干什么？ Maven是一个项目管理工具，用来管理项目的生命周期，如项目中各个项目之间的依赖管理，项目中使用到的jar包依赖管理，还有许多项目构建的插件等。使用Maven最大的好处就是不再需要我们手工维护项目中的各种jar包，及jar包需要依赖的其他jar包，也不再需要我们解决各种jar包之间的冲突，这一切maven帮我们都做好了。 目前Java开发中流行的集成开发工具Idea已经集成了Maven工具，打开Idea的设置选择Maven项，就可以看到自带的Maven的一些信息。我觉得Idea自带的Maven就挺好的，就没有去再安装一个。但是之前不知道Idea自带Maven工具，为此有次出现一个问题，就是因为两个Maven仓库的原因。在公司的电脑上我自己装了一个Maven，自己的电脑上没有装，直接使用Idea自带的Maven。","text":"什么是MavenMaven是现在的Java程序员应该都会遇到或使用的一个工具。那Maven具体是什么？到底能干什么？ Maven是一个项目管理工具，用来管理项目的生命周期，如项目中各个项目之间的依赖管理，项目中使用到的jar包依赖管理，还有许多项目构建的插件等。使用Maven最大的好处就是不再需要我们手工维护项目中的各种jar包，及jar包需要依赖的其他jar包，也不再需要我们解决各种jar包之间的冲突，这一切maven帮我们都做好了。 目前Java开发中流行的集成开发工具Idea已经集成了Maven工具，打开Idea的设置选择Maven项，就可以看到自带的Maven的一些信息。我觉得Idea自带的Maven就挺好的，就没有去再安装一个。但是之前不知道Idea自带Maven工具，为此有次出现一个问题，就是因为两个Maven仓库的原因。在公司的电脑上我自己装了一个Maven，自己的电脑上没有装，直接使用Idea自带的Maven。 Maven仓库使用 Maven 给我们带来的最直接的帮助，就是 jar 包得到了统一管理，那么这些 jar 包存放在哪里呢？它们就在您的 本地仓库 中，位于 C:\\Users\\用户名.m2 目录下（当然也可以修改这个默认地址）。 实际上可将本地仓库理解“缓存”，因为项目首先会从本地仓库中获取 jar 包，当无法获取指定 jar 包的时候，本地仓库会从 远程仓库（或 中央仓库） 中下载 jar 包，并放入本地仓库中以备将来使用。这个远程仓库是 Maven 官方提供的，可通过 http://search.maven.org/ 来访问。这样一来，本地仓库会随着项目的积累越来越大。通过下面这张图可以清晰地表达项目、本地仓库、远程仓库之间的关系。 Maven命令Maven执行命令有两种方式： Interactive Mode（交互模式） Batch Mode（批处理模式） 交互模式创建项目执行下面的命令 1mvn archetype:generate 接下来会出现下面的选项： 项目 Archetype Version（原型版本号）是什么？—— 可选择 1.0 版本 项目 groupId（组织名） 是什么？—— 可输入 net.ydstudio 项目 artifactId（构件名）是什么？—— 可输入 maven-demo 项目 version（版本号）是什么？—— 可输入 1.0 项目 package（包名）是什么？—— 可输入 net.ydstudio.demo 使用批处理模式创建项目1mvn archetype:generate -DinteractiveMode=false -DarchetypeArtifactId=maven-archetype-webapp -DgroupId=net.ydstudio -DartifactId=maven-demo -Dversion=1.0 创建项目这事我觉得还是用Idea来做，方便快捷。用命令创建的话，命令有时记得不全，不是很方便。 创建成功之后的项目中一般会有下面的几个目录，如果没有的话就自行创建。 src/main/java，主要代码存放的地方 src/test/java，测试代码存放的地方 src/main/resources，配置、资源文件存放的地方 src/main/webapp,Web应用相关代码存放的地方 还有一个重要的文件： pom.xml；pom.xml称为Project Object Model（项目对象模型），它用于描述整个Maven项目，所以也称为Maven描述文件。pom.xml 才是理解 Maven 的关键点，很有必要看看它到底长什么样。 pom文件打开生成的pom文件，内容如下： 1234567891011121314151617181920212223242526&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;net.ydstudio&lt;/groupId&gt; &lt;artifactId&gt;maven-demo&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;maven-demo Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;maven-demo&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 我们来解释一下： modelVersion:这个是pom的版本号，现在都是4.0.0的，必须得有，但不需要修改。 groupId、artifactId、version：分别表示 Maven 项目的组织名、构件名、版本号，它们三个合起来就是 Maven 坐标，根据这个坐标可以在 Maven 仓库中对应唯一的 Maven 构件。 packaging：表示该项目的打包方式，war 表示打包为 war 文件，默认为 jar，表示打包为 jar 文件。 name、url：表示该项目的名称与 URL 地址，意义不大，可以省略。 dependencies：定义该项目的依赖关系，其中每一个 dependency 对应一个 Maven 项目，可见 Maven 坐标再次出现，还多了一个 scope，表示作用域（下面会描述）。 build：表示与构建相关的配置，这里的 finalName 表示最终构建后的名称 maven-demo.war，这里的 finalName 还可以使用另一种方式来定义（下面会描述）。 我们可以在 pom.xml中定义一些列的项目依赖（构件包），每个构件包都会有一个 Scope（作用域），它表示该构件包在什么时候起作用，包括以下五种： compile：默认作用域，在编译、测试、运行时有效 test：对于测试时有效 runtime：对于测试、运行时有效 provided：对于编译、测试时有效，但在运行时无效 system：与 provided 类似，但依赖于系统资 Maven常见命令前面我们已经使用了几个 Maven 命令，例如：mvn archetype:generate，mvn tomcat7:run-war 等。其实，可使用两种不同的方式来执行 Maven 命令： mvn &lt;插件&gt;:&lt;目标&gt; [参数] mvn &lt;阶段&gt;现在我们接触到的都是第一种方式，而第二种方式才是我们日常中使用最频繁的，例如： mvn clean：清空输出目录（即 target 目录） mvn compile：编译源代码 mvn package：生成构件包（一般为 jar 包或 war 包） mvn install：将构件包安装到本地仓库 mvn deploy：将构件包部署到远程仓库 执行 Maven 命令需要注意的是：必须在Maven项目的根目录处执行，也就是当前目录下一定存在一个名为 pom.xml 的文件。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://blog.ydstudio.net/tags/maven/"}]},{"title":"Java学习系列文章第五篇：说说Java中的异常","slug":"Java学习系列文章第五篇：说说Java中的异常","date":"2018-06-29T22:00:54.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4b7e7a69.html","link":"","permalink":"https://blog.ydstudio.net/post/4b7e7a69.html","excerpt":"在正常的程序设计中，程序异常处理是非常关键和重要的一部分。试想一个项目中没有一个好的异常处理，这个项目会怎么样？","text":"在正常的程序设计中，程序异常处理是非常关键和重要的一部分。试想一个项目中没有一个好的异常处理，这个项目会怎么样？ 什么是异常异常其实是程序上的错误，包括程序逻辑错误和系统错误。比如数组下标越界、内存溢出等，这些都是意外的情况，错误在我们的程序的编写过程中会经常发生，包括编译期间和运行期间的错误。在编译期间出现的错误编译器会帮助我们修正，可是在运行期间的错误编译器就无能为力了，并且运行期间的错误往往是难以预料的。 程序出现了错误，我们不能不去处理，这样的程序的健壮性太差了。为了提高程序的健壮性我们要合理的解决这些错误！于是Java中提供了异常的处理机制，通过异常来处理程序运行期间中出现的错误。通过这一特性，我们可以很好的提高程序的健壮性。 Java是一个全面的面向对象语言，不像PHP那样，既支持过程式编程，也支持面向对象编程。Java中异常的父类是java.lang.Throwable类。在Java中定义很多的的异常类，比如OutOfMenoryError、NullPointerException、IndexOutOfBoundsException等。 Exception 类的层次所有的异常类是从 java.lang.Exception 类继承的子类。 Exception 类是 Throwable类的子类。除了Exception类外，Throwable还有一个子类Error 。Java 程序通常不捕获错误。错误一般发生在严重故障时，它们在Java程序处理的范畴之外。 Error 用来指示运行时环境发生的错误。例如，JVM 内存溢出。一般地，程序不会从错误中恢复。异常类有两个主要的子类：IOException 类和 RuntimeException 类。 Exception，也就是我们经常见到的一些异常情况，例如NullPointerException、IndexOutOfBoundsException等，这些异常时是我们可以处理的异常。 Exception类的异常包括checked exception和unchecked exception（unchecked exception也称作运行时异常RuntimeException，Exception类的异常都是在运行期间发生的），对于运行时异常，Java编译器不要求必须进行异常处理捕获处理或者抛出，这个由程序员自行决定。 checked exception（检查异常），也称为非运行时异常（运行时异常以外的异常就是非运行时异常），Java编译器强制程序员必须捕获处理，比如常见的IOException和SQLException。对于非运行时异常如果不进行捕获或者抛出处理，Java编译器都不会通过。 在网上找了一个图，能够很清楚的描述在Java中，异常类的结构层次（有些时候语言就略显苍白，不如图片或者视频表现力丰富）。 在Java中，所有的异常都是继承至java.lang.Throwable类。Error类是error类型异常的父类，Exception类是exception类型异常的父类，RuntimeException类是所有运行时异常的父类，RuntimeException以外的并且继承Exception的类是非运行时异常。 典型的RuntimeException包括NullPointerException、IndexOutOfBoundsException、IllegalArgumentException等。 典型的非RuntimeException包括IOException、SQLException等。 Java如何处理异常在Java中如果需要处理异常，必须先对异常进行捕获（这一点是和PHP是相同的）。使用try和catch关键字进行处理。具体的规则如下： 123456789try&#123; // 程序代码&#125;catch(异常类型1 异常的变量名1)&#123; // 程序代码&#125;catch(异常类型2 异常的变量名2)&#123; // 程序代码&#125;finally&#123; // 程序代码&#125; 来段实际的代码： 12345678910111213import java.io.*;public class ExcepTest&#123; public static void main(String args[])&#123; try &#123; File file = new File(\"/Users/sam/a.txt\"); if(!file.exists()) file.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 被try块包围的代码说明这段代码可能会发生异常，一旦发生异常，异常便会被catch捕获到，然后需要在catch块中进行异常处理。这是一种处理异常的方式。在Java中还提供了另一种异常处理方式即抛出异常，顾名思义，也就是说一旦发生异常，我把这个异常抛出去，让调用者去进行处理，自己不进行具体的处理，此时需要用到throw和throws关键字。 我们看下面的代码： 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; try &#123; createFile(); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125; public static void createFile() throws IOException&#123; File file = new File(\"/Users/sam/a.txt); if(!file.exists()) file.createNewFile(); &#125;&#125; 这段代码和上面一段代码的区别是，在实际的createFile方法中并没有捕获异常，而是用throws关键字声明抛出异常，即告知调用者此方法可能会抛出IOException，需要调用者进行捕获处理。那么在main方法中调用createFile方法的时候，采用try…catch块进行了异常捕获处理。 还可以使用throw关键字进行抛出异常。看下面的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package exception;/** * Created by Sam on 18/6/17. */public class Main &#123; public static void main(String[] args)&#123; People people = new People(\"Sam\",new Byte(\"25\")); people.sayAge(); &#125;&#125; class People &#123; private String name; private Byte age; public People(String name, Byte age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Byte getAge() &#123; return age; &#125; public void setAge(Byte age) &#123; this.age = age; &#125; public Byte sayAge()&#123; if (age &gt; Byte.MIN_VALUE)&#123; throw new MyException(\"年龄太大了\",\"100\" ); &#125; return age; &#125;&#125;public class MyException extends RuntimeException &#123; private String code; public MyException(String message, String code) &#123; super(message); this.code = code; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125;&#125; 上面就是利用throw关键字进行手动抛出异常。调用者可以捕获处理异常，也可以不用处理异常。下面我们就修改一下代码进行捕获处理： 1234567891011121314public class Main &#123; public static void main(String[] args)&#123; People people = new People(\"Sam\",new Byte(\"25\")); try &#123; people.sayAge(); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125;&#125;程序输出：exception.MyException: 年龄太大了 也就说在Java中进行异常处理的话，对于可能会发生异常的代码，可以选择三种方法来进行异常处理： 1、对代码块用try..catch进行异常捕获处理； 2、在该代码的方法体外用throws进行抛出声明，告知此方法的调用者这段代码可能会出现这些异常，你需要谨慎处理。此时有两种情况： 如果声明抛出的异常是非运行时异常，此方法的调用者必须显示地用try..catch块进行捕获或者继续向上层抛出异常。 如果声明抛出的异常是运行时异常，此方法的调用者可以选择地进行异常捕获处理。 3、在代码块用throw手动抛出一个异常对象，此时也有两种情况，跟2）中的类似： 如果抛出的异常对象是非运行时异常，此方法的调用者必须显示地用try..catch块进行捕获或者继续向上层抛出异常。 如果抛出的异常对象是运行时异常，此方法的调用者可以选择地进行异常捕获处理。（如果最终将异常抛给main方法，则相当于交给jvm自动处理，此时jvm会简单地打印异常信息） 关于Java的异常机制就暂时说到这里。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"exception","slug":"exception","permalink":"https://blog.ydstudio.net/tags/exception/"}]},{"title":"Java学习系列文章第四篇：说说Java的三大特性","slug":"Java学习系列文章第四篇：说说Java的三大特性","date":"2018-06-29T21:58:31.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/2b809338.html","link":"","permalink":"https://blog.ydstudio.net/post/2b809338.html","excerpt":"Java语言提供类、接口和继承等面向对象的特性，为了简单起见，只支持类之间的单继承，但支持接口之间的多继承，并支持类与接口之间的实现机制（关键字为implements）。Java语言全面支持动态绑定，而C++语言只对虚函数使用动态绑定。总之，Java语言是一个纯的面向对象程序设计语言。","text":"Java语言提供类、接口和继承等面向对象的特性，为了简单起见，只支持类之间的单继承，但支持接口之间的多继承，并支持类与接口之间的实现机制（关键字为implements）。Java语言全面支持动态绑定，而C++语言只对虚函数使用动态绑定。总之，Java语言是一个纯的面向对象程序设计语言。 说到面向对象编程，那就不得不提面向对象编程的三大特性：继承、封装和多态。那下面我们先来说一说封装。 封装隐藏了类的内部实现机制，可以在不想影响使用的情况下改变类的内部结构，同时也保护了数据。对外界也可以隐藏内部的细节，只暴露给外界访问的方法。 继承可以复用父类的代码。两个类之间若存在is-a的关系，就可以使用继承，从而达到代码的复用，同时也给多态的实现做了铺垫。 下面我们只要说说面向对象编程中的多态。所谓的多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序的运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在程序运行期间才能确定，这就是所谓的动态绑定（dynamic binding）。 既然多态那么重要，那么多态到底有什么好处呢？ 可替换性 消除类型之间的耦合关系 可扩充性 接口性 灵活性 简化性 Java实现多态有三个必要的条件：继承、重写、向上转型 继承：在多态中必须存在有继承关系的子类和父类。 重写：子类对父类中某些方法进行重写定义，在调用这些方法时就会调用子类的方法。 向上转型：在多态中需要将父类的引用指向子类，只有这样该引用才能够具备调用父类和子类的方法。 多态的实现方式 1. 继承重写12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class Animal &#123; abstract void eat(); abstract void work();&#125;public class Cat extends Animal &#123; @Override public void eat() &#123; System.out.println(\"吃鱼\"); &#125; @Override public void work() &#123; System.out.println(\"抓老鼠\"); &#125;&#125;public class Dog extends Animal &#123; @Override public void eat() &#123; System.out.println(\"吃骨头\"); &#125; @Override public void work() &#123; System.out.println(\"看家\"); &#125;&#125;public class Test &#123; public static void main(String[] args)&#123; Animal a = new Cat(); // 向上转型 a.eat(); // 调用的是 Cat 的 eat Animal b = new Dog(); // 向上转型 b.eat(); // 调用的是 Dog 的 eat &#125;&#125; 所以基于继承实现的多态可以总结如下：对于引用子类的父类类型，在处理该引用时，它适用于继承该父类的所有子类，子类对象的不同，对方法的实现也就不同，执行相同动作产生的行为也就不同。如果父类是抽象类，那么子类必须要实现父类中所有的抽象方法，这样该父类所有的子类一定存在统一的对外接口，但其内部的具体实现可以各异。这样我们就可以使用顶层类提供的统一接口来处理该层次的方法。 2.基于接口实现多态继承是通过重写父类的同一方法的几个不同子类来体现的，那么就可就是通过实现接口并覆盖接口中同一方法的几不同的类体现的。 在接口的多态中，指向接口的引用必须是指定这实现了该接口的一个类的实例程序，在运行时，根据对象引用的实际类型来执行对应的方法。 继承都是单继承，只能为一组相关的类提供一致的服务接口。但是接口可以是多继承多实现，它能够利用一组相关或者不相关的接口进行组合与扩充，能够对外提供一致的服务接口。所以它相对于继承来说有更好的灵活性。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"oop","slug":"oop","permalink":"https://blog.ydstudio.net/tags/oop/"}]},{"title":"Java学习系列文章第三篇：说说equals和==","slug":"Java学习系列文章第三篇：说说equals和","date":"2018-06-29T21:49:25.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/28107323.html","link":"","permalink":"https://blog.ydstudio.net/post/28107323.html","excerpt":"在上一篇文章中我们写过这样的代码 123456789101112// 直接赋值String str1 = \"hello world\";// 构造方法String str2 = new String(\"hello world\");String str3 = \"hello world\";String str4 = new String(\"hello world\");System.out.println(str1==str2);System.out.println(str1==str3);System.out.println(str2==str4); 我们现在都知道了它们的输出的结果，分别是false、true和false。","text":"在上一篇文章中我们写过这样的代码 123456789101112// 直接赋值String str1 = \"hello world\";// 构造方法String str2 = new String(\"hello world\");String str3 = \"hello world\";String str4 = new String(\"hello world\");System.out.println(str1==str2);System.out.println(str1==str3);System.out.println(str2==str4); 我们现在都知道了它们的输出的结果，分别是false、true和false。 ==是在比较什么在《think in java》这本书里有这样的一句话“关系操作符生成的是一个布尔的结果，它们计算的是操作数之间值的关系”。简单的说就是==号是用来比较值是否相等。 1234567891011121314151617181920public class Main &#123; public static void main(String[] args)&#123; int n = 30; int m = 30; System.out.println(n == m); String str = new String(\"hello world\"); String str1 = new String(\"hello world\"); String str2 = new String(\"hello world\"); System.out.println(str1 == str2); str1 = str; str2 = str; System.out.println(str1 == str2); &#125;&#125; 上面代码的输出结果可能大家都知道是true、false和true。也许会有人会有疑问，那我们来好好的解释一下： n == m结果为true，这个很容易理解，变量n和变量m存储的值都为3，肯定是相等的。而为什么str1和str2两次比较的结果不同？要理解这个其实只需要理解基本数据类型变量和非基本数据类型变量的区别。对于Java中的8中基本类型（4种整型byte、short、int、long，2种浮点型float、double，一个boolean型，还有一个字符型char）的变量，变量本身存储的就是值，关系操作符==进行比较时，比较的就是值本身。所以上面的 n == m的比较就是3 == 3，这个肯定结果是true啊！ 对于那些引用类型的变量如str1，变量存储的并不是值本身，而是其关联对象在内存的地址。所以变量str1中存储的是它指向的对象在内存中的存储地址，并不是“值”本身，也就是说并不是直接存储的字符串”hello world”。这里面的引用和C/C++中的指针很类似。因此在用==对str1和str2进行第一次比较时，得到的结果是false。因此它们分别指向的是不同的对象，也就是说它们实际存储的内存地址不同。而在第二次比较时，都让str1和str2指向了str指向的对象，那么得到的结果毫无疑问是true。 equals又是在比较什么equals方法是基类Object中的方法，因此对于所有继承Object的类都有该方法。先看一下下面的代码，猜猜输出的结果是什么 12345678910111213public class Main &#123; public static void main(String[] args)&#123;; Object object1 = new Object(); Object object2 = new Object(); Object object3 = object1; System.out.println(object1.equals(object2)); System.out.println(object1.equals(object3)); &#125;&#125; 上面代码的输出结果是false、true。我们来看看Object类中equals源码是什么样的： 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 在Object类中的equals方法是用来比较两个对象的引用是否相等，即是两个变量的引用是否指向同一个对象。 那下面的代码肯定会有人有疑问了，为啥输出的结果是true 123456789101112public class Main &#123; public static void main(String[] args)&#123;; String str1 = new String(\"hello\"); String str2 = new String(\"hello\"); System.out.println(str1.equals(str2)); &#125;&#125; 要想知道是为什么，我们查看一下String类的equals的源码就知道是怎么回事了！ 123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; String类对equals方法进行了重写，用来比较指向的字符串对象所存储的字符串是否相等。 Java中其他的类例如Double、Date、Integer等，都对equals进行重写，来比较指向的对象存储的内容是否相等。 我们来总结一下： 对于==，如果作用于基本数据类型的变量，则直接比较两操作数的值是否相等；如果作用于引用类型的变量，则比较的引用变量所指向的对象的地址。 对于equals，如果类对equals没有进行重写，则比较的是引用类型的变量所指向的对象地址；诸如String类对equals方法进行了重写，比较的则是引用变量所指向的对象的内容。 注意equals方法不能作用于基本数据类型的变量","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"String","slug":"String","permalink":"https://blog.ydstudio.net/tags/String/"}]},{"title":"Java学习系列文章第一篇：基本变量类型","slug":"Java学习系列文章第一篇：基本变量类型","date":"2018-06-29T21:48:24.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/c4de9814.html","link":"","permalink":"https://blog.ydstudio.net/post/c4de9814.html","excerpt":"Java有着丰富的变量类型，有8种基本数据类型，以及他们对应的包装类型，还有数组集合等众多变量类型。相比之下PHP的数据类型就相对少多了，PHP只有布尔类型（Boolean）、整型（Integer）、浮点型（Float）、数组（Array）、字符串（String）、对象（Object）、资源类型（Resource）和NULL。本文我们先以基本数据类型为主，其他的类型为辅。","text":"Java有着丰富的变量类型，有8种基本数据类型，以及他们对应的包装类型，还有数组集合等众多变量类型。相比之下PHP的数据类型就相对少多了，PHP只有布尔类型（Boolean）、整型（Integer）、浮点型（Float）、数组（Array）、字符串（String）、对象（Object）、资源类型（Resource）和NULL。本文我们先以基本数据类型为主，其他的类型为辅。 12type identifier [ = value][, identifier [= value] ...] ;格式说明：type为Java数据类型。identifier是变量名。可以使用逗号隔开来声明多个同类型变量。 下面我就简单的举几个变量声明的例子： 12345byte a,b,c;short e = g = 10;int f = 1000;boolean h = false;char i = 'a'; Java的两大数据类型： 内置数据类型 引用数据类型内置数据类型Java语言提供了八种基本数据类型。六种数字类型（四个整数型，两个浮点型），一种字符类型，还有一种是布尔型。Java中的数字类型都是无符号（unsigned）的，不像C语言和C++那样还提供有符号的类型。在后续的MySQL学习中，你会发现MySQL中字段的类型里面会有无符号这个属性，这样就会出现MySQL的字段映射成Java变量时，会有取值范围不同的问题。byte byte 占用一个字节的内存； 最小值是-128（-2^7)， 最大值是127（2^7-1）； 默认值是0，对应的包装类型是Byte,包装类型的默认值是null； 例子：byte a = 10； short short 占用两个字节的内存； 最小值是-32768（-2^15）， 最大值是32767（2^15-1） 默认值是0，对应的包装类型是Short,默认值是null； 例子：short a = 1200； char char 占用两个字节的内存，采用 Unicode 编码； 最小值是 \\u0000（即为0）； 最大值是 \\uffff（即为65,535）； char 可以储存任何字符（部分生僻的中文字符可能不行）； 例子：char letter = ‘A’;。 int int 占用四个字节的内存； 最小值是-2,147,483,648（-2^31）， 最大值是2,147,483,6478（2^31-1） 默认值是0，对应的包装类型是 Integer，默认值是null； 一般的整型变量默认为 int 类型 例子：int a = -10020； long long 占用八个字节的内存； 最小值是 -9,223,372,036,854,775,808（-2^63），最大值是 9,223,372,036,854,775,807（2^63-1），这种类型主要使用在需要比较大整数的系统上； 默认值是 0L，对应的包装类型是 Long，默认值是null； 例子：long a = 100000L，Long b = -200000L。“L”理论上不分大小写，但是若写成”l”容易与数字”1”混淆，不容易分辩。所以最好大写。 float float 占用四个字节的内存； 默认值是 0.0f；浮点数不能用来表示精确的值，如货币，存储货币推荐使用 BigDecimal；对应的包装类型是Float，默认值是null； 例子：float f1 = 234.58f； double double 占用八个字节的内存； 默认值是 0.0d；double不能用来表示精确的值，如货币，存储货币推荐使用BigDecimal；对应的包装类型是Double，默认值是null； 例子：double d1 = 234.05d；double d2 = 467.90;注意：不带任何标志的浮点型数据，系统默认是double类型。 boolean boolean(JVM规范没有明确规定其所占的空间大小； 只有两个取值，true和false; 默认值false,对应的包装类型是Boolean，默认值是null； 例子： boolean b = false; void 对应包装类型Void，不常用 byte、int、long和short还可以使用16进制和8进制的方式标识，默认都是使用10进制。 123int decimal = 100;int octal = 0144;int hexa = 0x64; 自动类型转换整型和字符型数据可以混合运算，不同的类型的数据先转化成同一类型，然后进行计算。 低———————————&gt;高 byte-&gt;short,char—&gt; int —&gt;float —&gt; long—&gt; double 数据类型转换必须满足下面的规则： 不能对boolean类型进行类型转换 不能把对象类型转换成不相干类的对象 把类型范围大的转换成类型范围小的时候必须使用强制类型转换 强制转换的过程中会出现溢出或损失精度 引用类型 在Java中引用类型变量指向一个对象，这种变量在定义的时候，被声明成特定的类型，比如 Man、Student等。变量类型一但确定之后类型就不能改变。这一点和动态脚本语言PHP有着很大的不同，PHP中的变量定义后仍能保存其他类型的变量； 所用引用类型的默认值都是null； 写于：2018-06-06 14:56 修改：2018-06-06 22:56","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"String","slug":"String","permalink":"https://blog.ydstudio.net/tags/String/"}]},{"title":"Java学习系列文章第二篇：字符串","slug":"Java学习系列文章第二篇：字符串","date":"2018-06-29T21:44:13.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/9d613e12.html","link":"","permalink":"https://blog.ydstudio.net/post/9d613e12.html","excerpt":"在众多的编程语言里面，字符串都被广泛的使用。在Java中字符串属于对象，语言提供了String类来创建和操作字符串。","text":"在众多的编程语言里面，字符串都被广泛的使用。在Java中字符串属于对象，语言提供了String类来创建和操作字符串。 字符串String简单知识Java提供两种方式来定义字符串，例如： 123456定义字符使用单引号，定义字符串使用双引号；// 直接赋值String str1 = \"hello world\";// 构造方法String str2 = new String(\"hello world\"); 通过对String源码的查看： 12345678910111213public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -6849794470754667710L; ……&#125; 从上面的代码我们可以得出两点结论： Java中的String类被final修饰。在Java中被final修饰的类不允许被继承，并且成员方法默认被final修饰。在早期的JVM的版本，被final修饰的方法会被转为内嵌调用借此来提升执行效率，但是从Java1.5/6之后，这种方式就被取消了。在之后的版本里，final修饰类只是为了不让类被继承。 String类是通过char数组保存字符串的。 对字符串的每一次操作，例如连接子串都会重新创建一个新的String对象。我们可以从String中的concat方法源码中可以看出这一点，代码如下： 12345678910public String concat(String str) &#123; int otherLen = str.length(); if (otherLen == 0) &#123; return this; &#125; int len = value.length; char buf[] = Arrays.copyOf(value, len + otherLen); str.getChars(buf, len); return new String(buf, true);&#125; 当被连接的子串的长度为0时，直接返回自身，连接一个长度不为0的子串，通过char数组的系列操作，重新生成一个新的String对象。所以在此要注意对String类对象的任何改变都不影响到原对象，相关的任何change操作都会生成新的对象。 深入理解字符串String上面写了两种定义字符串的方式，不知道大家知道这两种方式的区别和联系么？ 123456789101112// 直接赋值String str1 = \"hello world\";// 构造方法String str2 = new String(\"hello world\");String str3 = \"hello world\";String str4 = new String(\"hello world\");System.out.println(str1==str2);System.out.println(str1==str3);System.out.println(str2==str4); 你能直接说出上面的执行结果么？如果不能请继续往下看，能的话也请继续往下看。具体的结果如下： 123falsetruefalse 在class文件中有一部分来存储编译期间生成的字面常量以及符号引用，这部分叫做class文件常量池，在运行期间对应着方法区的运行时常量池。在上述的代码中String str1 = “hello world”;和String str2 = new String(“hello world”);都在编译期生成了字面常量和符号引用，运行期间字面常量”hello world”都被存储在运行时常量池。JVM执行引擎会在运行时常量池中查找是否存在相同的字面常量，若有则直接将引用指向已经存在的字面常量；否则在运行时常量池中开辟一个新的空间来存储该字面量，并将引用指向该字面常量，通过这种方式来把String对象跟引用绑定。 通过new关键字生成对象这个过程是在堆heap中进行的，而在堆进行对象生成过程中，不会有检查对象是否已经存在这个行为。因此通过new来创建对象，创建出来的一定是新的对象，即在内存中有着新的内存地址，但字符串的内容是相同的。 下面是Java中不同变量在内存中存放的位置： 变量 内存位置 new出来的对象 heap 堆 局部变量、基本数据类型 stack 栈 静态变量、字符串、常量 data segment 数据区 代码 code segment 代码区 String、StringBuffer、StringBuilder的区别为什么已经存在了String了，还会出现StringBuffer、StringBuilder？如果一个字符串需要连接10000次其他的字符串，实现代码如下： 1234567891011public class Main &#123; public static void main(String[] args)&#123; String string = \"\"; for(int i=0;i&lt;10000;i++)&#123; string = string.concat(\"hello\"); &#125; &#125;&#125; 上述代码不断的new字符串对象，前面已经说了重要的一点对String类对象的任何改变都不影响到原对象，相关的任何change操作都会生成新的对象。，这种代码将会有多大的内存消耗。这个时候想必大家已经有了点答案。我将上述的代码稍微的修改一下： 1234567891011public class Main &#123; public static void main(String[] args)&#123; String string = \"\"; for(int i=0;i&lt;10000;i++)&#123; string += \"hello\"; &#125; &#125;&#125; 两部分代码看似只有一点差异，其实两者的内存消耗有着天大的差别。我们通过javap命令来反编译.class文件。具体内容如下： 12345678910111213141516171819202122232425262728293031D:\\work\\javaLearn\\out\\production\\javaLearn&gt;javap -c MainCompiled from \"Main.java\"public class Main &#123; public Main(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #2 // String 2: astore_1 3: iconst_0 4: istore_2 5: iload_2 6: sipush 10000 9: if_icmpge 38 12: new #3 // class java/lang/StringBuilder 15: dup 16: invokespecial #4 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 19: aload_1 20: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 23: ldc #6 // String hello 25: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 28: invokevirtual #7 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 31: astore_1 32: iinc 2, 1 35: goto 5 38: return&#125; 从上面反编译出来的字节码中可以看出一点门道：string+=”hello”的操作事实上会自动被JVM优化成StringBuilder类的append操作。 那么有人会问既然有了StringBuilder类，为什么还需要StringBuffer类？查看源代码便一目了然，事实上，StringBuilder和StringBuffer类拥有的成员属性以及成员方法基本相同，区别是StringBuffer类的成员方法前面多了一个关键字：synchronized，不用多说，这个关键字是在多线程访问时起到安全保护作用的,也就是说StringBuffer是线程安全的。 我们来看下面的代码： 1234567891011public class Main &#123; public static void main(String[] args)&#123; String str1 = \"I \"+\"love \"+\"you\"; String str2 = \"I \"; String str3 = \"love \"; String str4 = \"you \"; String str5 = str2 + str3 + str4; &#125;&#125; 用javap命令来反编译.class文件： 1234567891011121314151617181920212223242526272829303132D:\\work\\javaLearn\\out\\production\\javaLearn&gt;javap -c MainCompiled from \"Main.java\"public class Main &#123; public Main(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #2 // String I love you 2: astore_1 3: ldc #3 // String I 5: astore_2 6: ldc #4 // String love 8: astore_3 9: ldc #5 // String you 11: astore 4 13: new #6 // class java/lang/StringBuilder 16: dup 17: invokespecial #7 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 20: aload_2 21: invokevirtual #8 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: aload_3 25: invokevirtual #8 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 28: aload 4 30: invokevirtual #8 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 33: invokevirtual #9 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 36: astore 5 38: return&#125; str1在编译之后就被直接赋值为”I love you”;str5却没有什么操作。综上所述我们可以得出一些结论： 对于直接通过加号相连字符串效率高，因为编译器直接确定了它的值。就像上面的”I “+”love “+”you”;的字符串相加，在编译期间就被优化成了”I love you“。 对于间接相加的，形如str2 + str3 + str4;编译期不会进行优化。 对于执行效率来说StringBuilder &gt; StringBuffer &gt; String，但这个也不是绝对的。比如String str = “hello”+ “world”的效率就比 StringBuilder st = new StringBuilder().append(“hello”).append(“world”)要高。但是，当字符串相加的操作或者字符改动的情况较少的时候，采用String肯定是比较好的；当字符串的操作较多的时候推荐使用StringBuilder，如果考虑到线程安全问题，无疑采用StringBuffer是最合适的。常见的字符串相关的面试题 下面的代码输出的结果是什么？123String a = \"hello2\"; String b = \"hello\" + 2; System.out.println((a == b)); 结果是true，它String b = “hello” + 2; 被编译器优化成了String b = “hello2”; 所以运行时字符串a和b指向同一个对象。 下面的代码输出的结果是什么？1234String a = \"hello2\"; String b = \"hello\"; String c = b + 2; System.out.println((a == c)); 输出结果为:false。由于有符号引用的存在，所以 String c = b + 2;不会在编译期间被优化，不会把b+2当做字面常量来处理的，通过StringBuilder生成了一个新的对象，因此这种方式生成的对象事实上是保存在堆上的。 下面的代码输出的结果是什么？1234String a = \"hello2\";final String b = \"hello\"; String c = b + 2; System.out.println((a == c)); 输出结果为：true。对于被final修饰的变量，会在class文件常量池中保存一个副本，也就是说不会通过连接而进行访问，对final变量的访问在编译期间都会直接被替代为真实的值。那么String c = b + 2;在编译期间就会被优化成：String c = “hello” + 2; 字符串的故事就暂时说到这里，后续有的话就继续更新。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"String","slug":"String","permalink":"https://blog.ydstudio.net/tags/String/"}]},{"title":"CentOS 6.x 下安装Zookeeper","slug":"CentOS-6-x-下安装Zookeeper","date":"2018-05-23T21:41:18.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/d229aadf.html","link":"","permalink":"https://blog.ydstudio.net/post/d229aadf.html","excerpt":"目前在研究dubbo这个国内流行的RPC框架，实现去中心话的微服务需要用到Zookeeper,所以今天来说说如何安装Zookeeper。Zookeeper的官方下载地址","text":"目前在研究dubbo这个国内流行的RPC框架，实现去中心话的微服务需要用到Zookeeper,所以今天来说说如何安装Zookeeper。Zookeeper的官方下载地址 查看Centos版本： 12345cat /etc/issue[root@iZwz99xkrnh5xy0cqp8aofZ tomcat]# cat /etc/issueCentOS release 6.9 (Final)Kernel \\r on an \\m 1.下载安装包到/usr/local/src/目录下，并创建安装目录/usr/local/zookeeper。 1234cd /usr/local/src/#这里使用3.4.10，没有使用较高的版本wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gzmkdir /usr/local/zookeeper 2.解压安装包,并将解压后的文件拷贝到/usr/local/zookeeper 12tar -zxvf zookeeper-3.4.10.tar.gzcp -R /usr/local/zookeeper/zookeeper-3.4.10/* /usr/local/zookeeper 3.添加系统变量到/etc/profile 123export ZOOKEEPER_HOME=/usr/local/zookeeperexport PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH 执行命令 source /etc/profile使配置文件立即生效 4.创建zookeeper配置文件,并作相应的配置 1234567891011121314151617181920cd /usr/local/zookeeper/conf/cp zoo_sample.cfg zoo.cfg#配置zookeeper#服务器与客户端之间交互的基本时间单元（ms）tickTime=2000#配置保存数据文件夹dataDir=/usr/local/zookeeper/data#配置保存日志文件夹，当此配置不存在时默认路径与dataDir一致dataLogDir=/var/log/zookeeper#客户端访问zookeeper的端口号clientPort=2181 5.zookeeper相关命令 1234启动服务：zkServer.sh start查看状态：zkServer.sh status关闭服务：zkServer.sh stop重启服务：zkServer.sh restart 至此，zookeeper安装完成","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.ydstudio.net/tags/zookeeper/"}]},{"title":"CentOS 6.x 下yum安装Tomcat8","slug":"CentOS-6-x-下yum安装Tomcat8","date":"2018-05-22T21:40:05.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/30e8c768.html","link":"","permalink":"https://blog.ydstudio.net/post/30e8c768.html","excerpt":"废话不多说，今天准备在Centos上安装tomcat，学java不会tomcat，那不就是白学Java么？查看Centos版本：","text":"废话不多说，今天准备在Centos上安装tomcat，学java不会tomcat，那不就是白学Java么？查看Centos版本： 12345cat /etc/issue[root@iZwz99xkrnh5xy0cqp8aofZ tomcat]# cat /etc/issueCentOS release 6.9 (Final)Kernel \\r on an \\m 通过yum好处其实很多，环境变量不用配置，配置文件放在大家都熟悉的地方，通过rpm -ql xxx可以知道全部文件的地方等等。 1.安装Tomcat自带的yum源里面的Tomcat版本过低，所以我准备安装Tomcat8。 12345678910111213cd /usr/local/src/// 下载脚本# git clone https://github.com/boundlessgeo/rpm-tomcat8.git &amp;&amp; cd rpm-tomcat8// 安装rpm打包工具# yum -y install rpmdevtools// 打包rpm包# ./make_rpm.sh// 安装依赖# yum install -y redhat-lsb-core// 安装Tomcat8# rpm -ivh rpmbuild/RPMS/noarch/boundless-server-tomcat8-8.0.47-5.noarch.rpm备注：主要是这个脚本https://github.com/boundlessgeo/rpm-tomcat8，想要哪个版本可以直接上去这里修改文件即可。 2.设置开机启动 1chkconfig tomcat8 on 3.常用的命令 12345678// 服务状态service tomcat8 status// 服务启动service tomcat8 start// 服务停止service tomcat8 stop// 服务重启service tomcat8 restart 4.卸载Tomcat 1yum -e boundless-server-tomcat8.noarch","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"tomcat","slug":"tomcat","permalink":"https://blog.ydstudio.net/tags/tomcat/"}]},{"title":"Spring Boot 1.x集成spring-boot-devtools开发时实现热部署","slug":"Spring-Boot-1-x集成spring-boot-devtools开发时实现热部署","date":"2018-05-13T21:38:16.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/e13b17d3.html","link":"","permalink":"https://blog.ydstudio.net/post/e13b17d3.html","excerpt":"热部署大家都知道在项目开发过程中，常常会改动页面数据或者修改数据结构，为了显示改动效果，往往需要重启应用查看改变效果，其实就是重新编译生成了新的Class文件，这个文件里记录着和代码等对应的各种信息，然后Class文件将被虚拟机的ClassLoader加载。而热部署正是利用了这个特点，它监听到如果有Class文件改动了，就会创建一个新的ClaassLoader进行加载该文件，经过一系列的过程，最终将结果呈现在我们眼前。","text":"热部署大家都知道在项目开发过程中，常常会改动页面数据或者修改数据结构，为了显示改动效果，往往需要重启应用查看改变效果，其实就是重新编译生成了新的Class文件，这个文件里记录着和代码等对应的各种信息，然后Class文件将被虚拟机的ClassLoader加载。而热部署正是利用了这个特点，它监听到如果有Class文件改动了，就会创建一个新的ClaassLoader进行加载该文件，经过一系列的过程，最终将结果呈现在我们眼前。 类加载机制Java中的类经过编译器可以把代码编译为存储字节码的Class文件，该Class文件存储了各种信息，最终要加载到虚拟机中运行使用。类加载机制（摘自《深入理解 Java 虚拟机》）虚拟机把描述类的数据从Class文件加载到内存中，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 Spring Boot实现热部署Spring Boot实现热部署有如下方式： 使用 Spring Loaded 使用 spring-boot-devtools Spring Loaded这种方式是以Maven插件的形式去加载，所以启动时使用通过Maven命令mvn spring-boot:run启动，而通过Application.run方式启动的会无效，因为通过应用程序启动时，已经绕开了Maven插件机制。pom集成方式： 123456789101112131415&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;version&gt;1.2.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; spring-boot-devtools这种方式无论怎么启动应用，都可以达到修改文件后重启应用。pom集成： 123456&lt;!-- 热部署模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt; 集成注意 如果发现没有热部署效果，则需要检查IDE配置中有没有打开自动编译。 如果使用Thymeleaf模板引擎，需要把模板默认缓存设置为false12#禁止thymeleaf缓存（建议：开发环境设置为false，生成环境设置为true）spring.thymeleaf.cache=false 针对devtools的可以指定目录或者排除目录来进行热部署1234#添加那个目录的文件需要restartspring.devtools.restart.additional-paths=src/main/java#排除那个目录的文件不需要restartspring.devtools.restart.exclude=static/**,public/** 设置idea让他实现文件修改自动重启项目 找到idea的Preferences -&gt; Build, Execution, Deployment -&gt; Compiler，勾选Build project automatically 回到idea正常界面，Mac使用快捷键shift+option+command+/，window上的快捷键是Shift+Ctrl+Alt+/，打开Registry，勾选compiler.automake.allow.when.app.runningcompiler.automake.allow.when.app.running 通过以上的设置就可以在不重启服务的情况下加载html，但如果修改java文件，服务在几秒后会自动重启，如果不希望服务重启需要在application.properties或application.yml中添加spring.devtools.reatart.enable=false","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"},{"name":"spring-boot-devtools","slug":"spring-boot-devtools","permalink":"https://blog.ydstudio.net/tags/spring-boot-devtools/"}]},{"title":"Maven项目出现“请使用 -source 8 或更高版本以启用 lambda 表达式”","slug":"Maven项目出现“请使用-source-8-或更高版本以启用-lambda-表达式”","date":"2018-05-09T21:36:34.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/db29c21a.html","link":"","permalink":"https://blog.ydstudio.net/post/db29c21a.html","excerpt":"今天在编译项目的时候出现“请使用 -source 8 或更高版本以启用 lambda 表达式”的问题。这个问题是怎么出现的呢？其实是自己Maven的默认JDK的版本过低的原因，貌似JDK的版本默认为JDK1.5。知道问题的所在，我们就可以着手解决了。","text":"今天在编译项目的时候出现“请使用 -source 8 或更高版本以启用 lambda 表达式”的问题。这个问题是怎么出现的呢？其实是自己Maven的默认JDK的版本过低的原因，貌似JDK的版本默认为JDK1.5。知道问题的所在，我们就可以着手解决了。 在Maven中指定JDK的版本1234567891011121314151617&lt;project xmlns=\"...\"&gt; ... &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ...&lt;/project&gt; 在Maven的settings.xml里面指定全局JDK编译版本右键点击项目找到Maven，找到关于settings.xml选项，打开settings.xml文件，写入下面的内容：1234567891011121314&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 然后重新编译就可以了","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://blog.ydstudio.net/tags/maven/"}]},{"title":"Spring Boot 1.x 整合mybatis,并自动生成mapper和实体","slug":"Spring-Boot-1-x-整合mybatis-并自动生成mapper和实体","date":"2018-05-07T21:35:19.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/e5912e16.html","link":"","permalink":"https://blog.ydstudio.net/post/e5912e16.html","excerpt":"最近一直都在学习Java，发现目前Java招聘中，mybatis出现的频率挺高的，可能是目前Java开发中使用比较多的数据库ORM框架。于是我准备研究下Spring Boot 1.x 和mybatis的整合。","text":"最近一直都在学习Java，发现目前Java招聘中，mybatis出现的频率挺高的，可能是目前Java开发中使用比较多的数据库ORM框架。于是我准备研究下Spring Boot 1.x 和mybatis的整合。 1.在pom.xml文件中添加下面的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.29&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 这个是官方的mybatis依赖，这个你不加没法用噻 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 这个是自动生成mapper等的依赖，必须得加--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;!--这个是自动生成mapper等的依赖，必须得加 https://mvnrepository.com/artifact/org.mybatis.generator/mybatis-generator-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;!--配置文件存放的地址--&gt; &lt;!--&lt;configurationFile&gt;src/main/resources/mybatis-generator/generatorConfig.xml&lt;/configurationFile&gt;--&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2.在application.properties配置文件中进行数据库和mybatis扫描的配置 1234567891011121314151617spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/yddy?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTCspring.datasource.username=rootspring.datasource.password=123456mybatis.config-locations=classpath:mybatis-config.xml# mapper文件mybatis.mapper-locations=classpath:mapper/*.xml #这里直接写*，对后面自定义sql，编写xxxExt.xml有好处，自动扫描到这些文件，不用再改配置了mybatis.type-aliases-package=com.dameiweb.learn.modellogging.level.com.dameiweb.learn.dao=debug#mybatis.config = mybatis 配置文件名称#mybatis.mapperLocations = mapper xml 文件地址#mybatis.typeAliasesPackage = 实体类包路径#mybatis.typeHandlersPackage = type handlers 处理器包路径#mybatis.check-config-location = 检查 mybatis 配置是否存在，一般命名为 mybatis-config.xml#mybatis.executorType = 执行模式。默认是 SIMPLE 3.mybatis的配置和自动生成mapper的配置在resource目录下新建一个generatorConfig.xml和mybatis-config.xml。内容如下：generatorConfig.xml内容 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;classPathEntry location=\"C:\\Users\\nick\\.m2\\repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar\"/&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接地址账号密码--&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/yddy?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;serverTimezone=UTC\" userId=\"root\" password=\"123456\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!--生成Model类存放位置--&gt; &lt;javaModelGenerator targetPackage=\"com.dameiweb.learn.model\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name=\"trimStrings\" value=\"false\"/&gt; &lt;/javaModelGenerator&gt; &lt;!--生成映射文件存放位置--&gt; &lt;sqlMapGenerator targetPackage=\"mapper\" targetProject=\"src/main/resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!--生成Dao类存放位置--&gt; &lt;!-- 客户端代码，生成易于使用的针对Model对象和XML配置文件 的代码 type=\"ANNOTATEDMAPPER\",生成Java Model 和基于注解的Mapper对象 type=\"MIXEDMAPPER\",生成基于注解的Java Model 和相应的Mapper对象 type=\"XMLMAPPER\",生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.dameiweb.learn.dao\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; mybatis-config.xml的内容： 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name=\"callSettersOnNulls\" value=\"true\"/&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"true\"/&gt; &lt;setting name=\"multipleResultSetsEnabled\" value=\"true\"/&gt; &lt;setting name=\"useColumnLabel\" value=\"true\"/&gt; &lt;setting name=\"useGeneratedKeys\" value=\"false\"/&gt; &lt;setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/&gt; &lt;setting name=\"defaultExecutorType\" value=\"SIMPLE\"/&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;setting name=\"localCacheScope\" value=\"SESSION\"/&gt; &lt;setting name=\"jdbcTypeForNull\" value=\"NULL\"/&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias alias=\"Integer\" type=\"java.lang.Integer\" /&gt; &lt;typeAlias alias=\"Long\" type=\"java.lang.Long\" /&gt; &lt;typeAlias alias=\"HashMap\" type=\"java.util.HashMap\" /&gt; &lt;typeAlias alias=\"LinkedHashMap\" type=\"java.util.LinkedHashMap\" /&gt; &lt;typeAlias alias=\"ArrayList\" type=\"java.util.ArrayList\" /&gt; &lt;typeAlias alias=\"LinkedList\" type=\"java.util.LinkedList\" /&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 这样我们就配置好了Spring Boot和mybatis与mybatis自动生成mapper和实体的功能。这样我们要生成某个表的实体和mapper的时候，只需要在generatorConfig.xml中javaClientGenerator标签之后添加下面的内容即可。此处我们已yd_movies表为例(主要数据库表名字不要用复数，这个表名肯定是我之前脑子抽了，搞个复数的名字) 12345678910111213 &lt;!--生成对应表及类名--&gt; &lt;table tableName=\"yd_movies\" domainObjectName=\"Movie\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt; &lt;columnOverride column=\"cover_photos\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"cover_photos_loc\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"pubdates\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"photographs_origin\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"photographs_origin_loc\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"languages\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"awards\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;columnOverride column=\"summary\" javaType=\"java.lang.String\" jdbcType=\"VARCHAR\" /&gt; &lt;/table&gt;&lt;!--columnOverride使用这个标签是为了防止数据库字段类型为text时候，mybatis会生成xxxxWithBLOBs文件。--&gt; 然后点击idea右侧Maven projects，就可以看到mybatis-generate下的mybatis-generate：generate，双击mybatis-generate：generate即可。 generator 注意点，也可以说是BUG就是在生成的时候，在第二次生成的时候，dao 和entity 都会直接覆盖，而Mapper.xml 会直接追加，导致运行报错，而且很难找。 4.mybatis自定义sql当我们需要自定义sql的时候，我们不能把这些也放到mapper文件中。不然，当数据库表的字段有更新需要重新生成mapper的时候，这样我们自定义的sql不就被覆盖没了么！所以我们需要在MovieMapper.xml的同级目录里，新建一个MovieMapperExt.xml文件，把自定义的sql放到这里，例子如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344MovieMapperExt.xml文件内容&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.dameiweb.learn.dao.MovieMapper\" &gt; &lt;select id=\"selectByCondition\" resultMap=\"BaseResultMap\" parameterType=\"com.dameiweb.learn.dto.MovieRequest\"&gt; SELECT yd_movies.* FROM yd_movies LEFT JOIN yd_r_movie_countries ON yd_movies.id = yd_r_movie_countries.movie_id LEFT JOIN yd_countries cou ON yd_r_movie_countries.country_id = cou.id LEFT JOIN yd_r_movie_category ON yd_movies.id = yd_r_movie_category.movie_id LEFT JOIN yd_category cat ON yd_r_movie_category.category_id = cat.id LEFT JOIN yd_r_movie_actor ON yd_movies.id = yd_r_movie_actor.movie_id LEFT JOIN yd_actors a ON yd_r_movie_actor.actor_id = a.id WHERE yd_movies.status = 1 &lt;if test=\"movieRequest.title != null\"&gt; AND yd_movies.title LIKE \"%\"#&#123;movieRequest.title&#125;\"%\" &lt;/if&gt; &lt;if test=\"movieRequest.country != null\"&gt; AND cou.id = #&#123;movieRequest.country&#125; &lt;/if&gt; &lt;if test=\"movieRequest.category != null\"&gt; AND cat.id = #&#123;movieRequest.category&#125; &lt;/if&gt; &lt;if test=\"movieRequest.year != null\"&gt; AND year = #&#123;movieRequest.year&#125; &lt;/if&gt; &lt;if test=\"movieRequest.rate != null\"&gt; AND rate &gt;= #&#123;movieRequest.rate&#125; &lt;/if&gt; &lt;if test=\"movieRequest.rate != null\"&gt; AND rate &amp;lt; (#&#123;movieRequest.rate&#125;+1) &lt;/if&gt; &lt;if test=\"movieRequest.subtype != null\"&gt; AND yd_movies.subtype = #&#123;movieRequest.subtype&#125; &lt;/if&gt; GROUP BY yd_movies.id ORDER BY updated_at DESC, year &lt;/select&gt;&lt;/mapper&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"}]},{"title":"Spring Boot框架中读取配置的几种方式","slug":"Spring-Boot框架中读取配置的几种方式","date":"2018-05-04T21:33:18.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/28da4df8.html","link":"","permalink":"https://blog.ydstudio.net/post/28da4df8.html","excerpt":"现在开发的主力语言已经从PHP转向Java，目前参与或负责公司的几个项目都是使用Spring Boot框架。用了Java之后，对比PHP就一个感觉：繁琐，Java比PHP繁琐的很！由于自己平时也在努力学习Java中，今天趁着有空闲来总结一下Spring Boot中读取配置的几种方式，加深一下自己的印象。","text":"现在开发的主力语言已经从PHP转向Java，目前参与或负责公司的几个项目都是使用Spring Boot框架。用了Java之后，对比PHP就一个感觉：繁琐，Java比PHP繁琐的很！由于自己平时也在努力学习Java中，今天趁着有空闲来总结一下Spring Boot中读取配置的几种方式，加深一下自己的印象。 读取application文件在application.yml或者properties文件中添加： 123info.address=RPCinfo.company=Springinfo.degree=high 1.@Value注解读取方式 123456789101112131415161718192021222324252627282930313233343536import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;@Componentpublic class InfoConfig &#123; @Value(\"$&#123;info.address&#125;\") private String address; @Value(\"$&#123;info.company&#125;\") private String company; @Value(\"$&#123;info.degree&#125;\") private String degree; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getCompany() &#123; return company; &#125; public void setCompany(String company) &#123; this.company = company; &#125; public String getDegree() &#123; return degree; &#125; public void setDegree(String degree) &#123; this.degree = degree; &#125;&#125; 2.@ConfigurationProperties注解读取方式 12345678910111213141516171819202122232425262728293031@Component@ConfigurationProperties(prefix = \"info\")public class InfoConfig &#123; private String address; private String company; private String degree; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getCompany() &#123; return company; &#125; public void setCompany(String company) &#123; this.company = company; &#125; public String getDegree() &#123; return degree; &#125; public void setDegree(String degree) &#123; this.degree = degree; &#125;&#125; 读取指定文件资源目录下建立config/db-config.properties: db.username=rootdb.password=123456 @PropertySource+@Value注解读取方式 1234567891011121314151617181920212223242526@Component@PropertySource(value = &#123; \"config/db-config.properties\"&#125;)public class DBConfig1 &#123; @Value(\"$&#123;db.username&#125;\") private String username; @Value(\"$&#123;db.password&#125;\") private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 注意：@PropertySource不支持yml文件读取。 @PropertySource+@ConfigurationProperties注解读取方式 1234567891011121314151617181920212223@Component@ConfigurationProperties(prefix = \"db\")@PropertySource(value = &#123;\"config/db-config.properties\"&#125;)public class DBConfig2 &#123; private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; Environment读取方式 1234@Autowiredprivate Environment environment;environment.getProperty(\"info.degree\"); 从以上示例来看，Spring Boot可以通过@PropertySource,@Value,@Environment,@ConfigurationProperties的相互配合来读取配置文件的内容，读取单个的配置Environment无疑是最霸道的方法。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"}]},{"title":"解决Java异常java.security.InvalidKeyException: Illegal key size","slug":"解决Java异常java-security-InvalidKeyException-Illegal-key-size","date":"2018-04-26T23:41:54.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4770bec.html","link":"","permalink":"https://blog.ydstudio.net/post/4770bec.html","excerpt":"最近公司准备对接马蜂窝的接口，今天在开发的过程中出现了下面的问题： 1java.security.InvalidKeyException: Illegal key size","text":"最近公司准备对接马蜂窝的接口，今天在开发的过程中出现了下面的问题： 1java.security.InvalidKeyException: Illegal key size 通过仔细阅读马蜂窝的demo时发现，他们在demo里写了下面一段话： 123456说明：异常java.security.InvalidKeyException:illegal Key Size的解决方案在官方网站下载JCE无限制权限策略文件（JDK7的下载地址： http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.html下载后解压，可以看到local_policy.jar和US_export_policy.jar以及readme.txt如果安装了JRE，将两个jar文件放到%JRE_HOME%\\lib\\security目录下覆盖原来的文件如果安装了JDK，将两个jar文件放到%JDK_HOME%\\jre\\lib\\security目录下覆盖原来文件 后来百度得知这里面还有其他原因：如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size 异常. 因为密钥长度是受限制的, java运行时环境读到的是受限的policy文件. 文件位于${java_home}/jre/lib/security, 这种限制是因为美国对软件出口的控制. 由于现在我用的是Java8，所以我把解决办法整理如下： 123在官方网站下载JCE无限制权限策略文件JDK7的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.htmlJDK8的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html 下载后解压，可以看到local_policy.jar和US_export_policy.jar以及readme.txt如果安装了JRE，将两个jar文件放到%JRE_HOME%\\lib\\security目录下覆盖原来的文件如果安装了JDK，还要将两个jar文件也放到%JDK_HOME%\\jre\\lib\\security目录下覆盖原来文件","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"什么是缓存雪崩和缓存穿透","slug":"什么是缓存雪崩和缓存穿透","date":"2018-03-13T23:39:32.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/d9968bcf.html","link":"","permalink":"https://blog.ydstudio.net/post/d9968bcf.html","excerpt":"1. 缓存雪崩 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。","text":"1. 缓存雪崩 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。 解决办法 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存。 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。 2. 缓存穿透 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。 解决办法 对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。还有最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 也可以采用一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://blog.ydstudio.net/tags/redis/"}]},{"title":"MySQL中真正意义上的UTF8编码","slug":"MySQL中真正意义上的UTF8编码","date":"2018-02-22T23:37:26.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/451d6526.html","link":"","permalink":"https://blog.ydstudio.net/post/451d6526.html","excerpt":"总所周知，目前的软件体系中运用最广泛的是Unicode字符集，而其中运用最多的编码规则就是UTF-8。用UTF-8有什么好处呢？简单的来说有一下几种好处： 乱码不会扩散, GB2312在丢失一字节等情况下会造成后续所有文字变成乱码。 不会产生错误的搜索结果, GB2312在搜索的时候相邻两个中文会拼出一个新的字符，导致出现错误的搜索结果。 更大的字符集。 很多语言直接支持 UTF-8，部分语言存储字符串到内存时直接使用UTF-8编码。 与 GB2312/GB18030相比, UTF-8是一个通用解决方案。 Unicode 一直有人维护，而 GB18030 下一次更新不知道会是什么时候了。另对于中文, UTF-8和GB2312在gzip压缩后都差不多，所以用来做网页对带宽影响很小。","text":"总所周知，目前的软件体系中运用最广泛的是Unicode字符集，而其中运用最多的编码规则就是UTF-8。用UTF-8有什么好处呢？简单的来说有一下几种好处： 乱码不会扩散, GB2312在丢失一字节等情况下会造成后续所有文字变成乱码。 不会产生错误的搜索结果, GB2312在搜索的时候相邻两个中文会拼出一个新的字符，导致出现错误的搜索结果。 更大的字符集。 很多语言直接支持 UTF-8，部分语言存储字符串到内存时直接使用UTF-8编码。 与 GB2312/GB18030相比, UTF-8是一个通用解决方案。 Unicode 一直有人维护，而 GB18030 下一次更新不知道会是什么时候了。另对于中文, UTF-8和GB2312在gzip压缩后都差不多，所以用来做网页对带宽影响很小。 MySQL中也有UTF-8编码，他还有另外一个称呼叫做utf8mb3，该字符集每个字符最多使用三个字节。三个字节的UTF-8最大能编码的 Unicode字符是0xffff，也就是Unicode中的基本多文种平面（BMP）。也就是说，任何不在基本多文本平面的 Unicode字符，都无法使用MySQL的UTF-8编码存储。包括Emoji表情（Emoji是一种特殊的Unicode 编码，常见于ios和 android手机上），和很多不常用的汉字，以及任何新增的 Unicode字符等等。这样的话就会出现一些特殊字符无法保存到MySQL中。接下来我们就来解决这个编码的问题！ 随着Unicode的字符集的规范确定，以及他的广泛应用，MySQL官方自己也发现了这个问题，于是乎官方在MySQL5.5.3的时候推出了utf8mb4编码，（他才是真正意义上的UTF-8编码）mb4就是most bytes 4的意思，专门用来兼容四字节的unicode。utf8mb4是utf8的超集，除了将编码改为utf8mb4外不需要做其他转换。 对于新增的utf8mb4编码官方有个小建议如下： 123Tip: To save space with utf8mb4, use VARCHAR instead of CHAR. Otherwise, MySQL must reserve four bytes for each character in a CHAR CHARACTER SET utf8mb4 column because that is the maximum possible length. For example, MySQL must reserve 40 bytes for a CHAR(10) CHARACTER SET utf8mb4 column.大意如下：为了节省空间 utf8mb4，请使用 VARCHAR而不是CHAR。否则，MySQL必须为CHAR CHARACTER SET utf8mb4列中的每个字符保留四个字节，因为这是最大可能的长度。例如，MySQL必须为一CHAR(10) CHARACTER SET utf8mb4 列保留40个字节。 那如何设置MySQL的编码呢？ 查看数据库服务器的版本，低于5.5.3则不支持utf8mb4。 1234567select VERSION();+-----------+| VERSION() |+-----------+| 5.5.53 |+-----------+ 查看数据库的编码 1234567891011121314mysql&gt; show variables like &apos;character%&apos;;+--------------------------+-----------------------------------+| Variable_name | Value |+--------------------------+-----------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | C:\\phpStudy\\MySQL\\share\\charsets\\ |+--------------------------+-----------------------------------+ 将上述utf8全部修改成utf8mb4，编辑mysql的配置文件/etc/my.cnf（具体还可以参照文章Centos6.9上搭建lnmp环境） 123456789101112131415161718192021222324252627282930313233343536vi /etc/my.cnf[mysqld]character-set-server=utf8mb4 collation-server=utf8_general_ci sql_mode='NO_ENGINE_SUBSTITUTION'[mysql]default-character-set = utf8mb4[mysql.server]default-character-set = utf8mb4[mysqld_safe]default-character-set = utf8mb4[client]default-character-set = utf8mb4#重启mysqlservice mysqld restart#再次查看mysql&gt; show variables like 'character%';+--------------------------+-----------------------------------+| Variable_name | Value |+--------------------------+-----------------------------------+| character_set_client | utf8mb4 || character_set_connection | utf8mb4 || character_set_database | utf8mb4 || character_set_filesystem | binary || character_set_results | utf8mb4 || character_set_server | utf8mb4 || character_set_system | utf8mb4 || character_sets_dir | C:\\phpStudy\\MySQL\\share\\charsets\\ |+--------------------------+-----------------------------------+ 这样我们的数据库就编码就全都设置成了utf8mb4,一些特殊的中文字符和Emoji表情符就可以成功的保存在数据库中了","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.ydstudio.net/tags/mysql/"}]},{"title":"PHP如何通过开启Opcache来提高性能","slug":"PHP如何通过开启Opcache来提高性能","date":"2018-02-09T23:35:09.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/924aacb8.html","link":"","permalink":"https://blog.ydstudio.net/post/924aacb8.html","excerpt":"在开启Opcache之前，我们先了解一下什么是Opcache: 12OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。PHP 5.5.0 及后续版本中已经绑定了 OPcache 扩展。 对于 PHP 5.2，5.3 和 5.4 版本可以使用 » PECL 扩展中的 OPcache 库。","text":"在开启Opcache之前，我们先了解一下什么是Opcache: 12OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。PHP 5.5.0 及后续版本中已经绑定了 OPcache 扩展。 对于 PHP 5.2，5.3 和 5.4 版本可以使用 » PECL 扩展中的 OPcache 库。 下面来说说如何安装Opcache,不同的PHP版本安装的方法稍有不同： 12345OPcache 只能编译为共享扩展。 如果你使用 --disable-all 参数 禁用了默认扩展的构建， 那么必须使用 --enable-opcache 选项来开启 OPcache。编译之后，就可以使用 zend_extension 指令来将 OPcache 扩展加载到 PHP 中。在非 Windows 平台使用 zend_extension=/full/path/to/opcache.so，Windows平台使用 zend_extension=C:\\path\\to\\php_opcache.dllPHP 5.2,5.3和 5.4版本中没有和PHP捆绑，需要自行安装，这里不做说明。 官方出了一个推荐配置如下： 123456789使用下列推荐设置来获得较好的 性能：opcache.memory_consumption=128opcache.interned_strings_buffer=8opcache.max_accelerated_files=4000opcache.revalidate_freq=60opcache.fast_shutdown=1opcache.enable_cli=1你也可以禁用 opcache.save_comments 并且启用 opcache.enable_file_override。 需要提醒的是，在生产环境中使用上述配置之前，必须经过严格测试。 因为上述配置存在一个已知问题，它会引发一些框架和应用的异常， 尤其是在存在文档使用了备注注解的时候。 配置扩展的时候注意以下问题 123在php.ini中增加opcache时需要使用zend_extension，而不是extension，不然会得到以下WARNINGPHP Warning: PHP Startup: Invalid library (appears to be a Zend Extension, try loading using zend_extension=opcache.so from php.ini) in Unknown on line 0 由于我自己的服务器安装的PHP7，已经安装了Opcache，所以我只需在php.ini文件中配置以下内容 123456789101112131415161718192021zend_extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20151012/opcache.so[opcache];开关打开opcache.enable=1;设置共享内存大小, 单位为：Mbopcache.memory_consumption=128opcache.interned_strings_buffer=8opcache.max_accelerated_files=4000opcache.revalidate_freq=60opcache.fast_shutdown=1opcache.enable_cli=1本次涉及到的有两个参数revalidate_freq，默认2检查脚本时间戳是否有更新的周期，以秒为单位。 设置为 0 会导致针对每个请求， OPcache 都会检查脚本更新validate_timestamps，默认1如果启用，那么 OPcache 会每隔 opcache.revalidate_freq 设定的秒数 检查脚本是否更新。 如果禁用此选项，你必须使用 opcache_reset() 或者 opcache_invalidate() 函数来手动重置 OPcache，也可以 通过重启 Web 服务器来使文件系统更改生效。 最后重启Nginx和PHP即可 下面是OPcache 可用的配置指令完整列表： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126; Determines if Zend OPCache is enabled;opcache.enable=0; Determines if Zend OPCache is enabled for the CLI version of PHP;opcache.enable_cli=0; The OPcache shared memory storage size.;opcache.memory_consumption=64; The amount of memory for interned strings in Mbytes.;opcache.interned_strings_buffer=4; The maximum number of keys (scripts) in the OPcache hash table.; Only numbers between 200 and 1000000 are allowed.;opcache.max_accelerated_files=2000; The maximum percentage of \"wasted\" memory until a restart is scheduled.;opcache.max_wasted_percentage=5; When this directive is enabled, the OPcache appends the current working; directory to the script key, thus eliminating possible collisions between; files with the same name (basename). Disabling the directive improves; performance, but may break existing applications.;opcache.use_cwd=1; When disabled, you must reset the OPcache manually or restart the; webserver for changes to the filesystem to take effect.;opcache.validate_timestamps=1; How often (in seconds) to check file timestamps for changes to the shared; memory storage allocation. (\"1\" means validate once per second, but only; once per request. \"0\" means always validate);opcache.revalidate_freq=2; Enables or disables file search in include_path optimization;opcache.revalidate_path=0; If disabled, all PHPDoc comments are dropped from the code to reduce the; size of the optimized code.;opcache.save_comments=1; If enabled, a fast shutdown sequence is used for the accelerated code; Depending on the used Memory Manager this may cause some incompatibilities.;opcache.fast_shutdown=0; Allow file existence override (file_exists, etc.) performance feature.;opcache.enable_file_override=0; A bitmask, where each bit enables or disables the appropriate OPcache; passes;opcache.optimization_level=0xffffffff;opcache.inherited_hack=1;opcache.dups_fix=0; The location of the OPcache blacklist file (wildcards allowed).; Each OPcache blacklist file is a text file that holds the names of files; that should not be accelerated. The file format is to add each filename; to a new line. The filename may be a full path or just a file prefix; (i.e., /var/www/x blacklists all the files and directories in /var/www; that start with 'x'). Line starting with a ; are ignored (comments).;opcache.blacklist_filename=; Allows exclusion of large files from being cached. By default all files; are cached.;opcache.max_file_size=0; Check the cache checksum each N requests.; The default value of \"0\" means that the checks are disabled.;opcache.consistency_checks=0; How long to wait (in seconds) for a scheduled restart to begin if the cache; is not being accessed.;opcache.force_restart_timeout=180; OPcache error_log file name. Empty string assumes \"stderr\".;opcache.error_log=; All OPcache errors go to the Web server log.; By default, only fatal errors (level 0) or errors (level 1) are logged.; You can also enable warnings (level 2), info messages (level 3) or; debug messages (level 4).;opcache.log_verbosity_level=1; Preferred Shared Memory back-end. Leave empty and let the system decide.;opcache.preferred_memory_model=; Protect the shared memory from unexpected writing during script execution.; Useful for internal debugging only.;opcache.protect_memory=0; Allows calling OPcache API functions only from PHP scripts which path is; started from specified string. The default \"\" means no restriction;opcache.restrict_api=; Mapping base of shared memory segments (for Windows only). All the PHP; processes have to map shared memory into the same address space. This; directive allows to manually fix the \"Unable to reattach to base address\"; errors.;opcache.mmap_base=; Enables and sets the second level cache directory.; It should improve performance when SHM memory is full, at server restart or; SHM reset. The default \"\" disables file based caching.;opcache.file_cache=; Enables or disables opcode caching in shared memory.;opcache.file_cache_only=0; Enables or disables checksum validation when script loaded from file cache.;opcache.file_cache_consistency_checks=1; Implies opcache.file_cache_only=1 for a certain process that failed to; reattach to the shared memory (for Windows only). Explicitly enabled file; cache is required.;opcache.file_cache_fallback=1; Enables or disables copying of PHP code (text segment) into HUGE PAGES.; This should improve performance, but requires appropriate OS configuration.;opcache.huge_code_pages=0; Validate cached file permissions.; opcache.validate_permission=0; Prevent name collisions in chroot'ed environment.; opcache.validate_root=0","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"}]},{"title":"Spring Boot的三种启动方式","slug":"Spring-Boot的三种启动方式","date":"2018-01-19T23:33:49.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/9de93e14.html","link":"","permalink":"https://blog.ydstudio.net/post/9de93e14.html","excerpt":"Spring Boot有以下三种启动方式，最后一种我们可以很好的设置不同环境使用不同的配置文件。 1.IDE 运行Application这个类的main方法 123456789101112package com.dameiweb.girl;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GirlApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GirlApplication.class, args); &#125;&#125;","text":"Spring Boot有以下三种启动方式，最后一种我们可以很好的设置不同环境使用不同的配置文件。 1.IDE 运行Application这个类的main方法 123456789101112package com.dameiweb.girl;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class GirlApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GirlApplication.class, args); &#125;&#125; 2.在springboot的应用的根目录下运行mvn spring-boot:run 12345678910111213141516171819202122232425262728293031323334$ mvn spring-boot:run[INFO] Scanning for projects...Downloading: http://maven.aliyun.com/nexus/content/groups/public/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.pomDownloaded: http://maven.aliyun.com/nexus/content/groups/public/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.pom (0 B at 0 B/s)Downloading: http://maven.aliyun.com/nexus/content/groups/public/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.jarDownloaded: http://maven.aliyun.com/nexus/content/groups/public/org/apache/maven/plugins/maven-help-plugin/2.2/maven-help-plugin-2.2.jar (0 B at 0 B/s)Downloading: http://maven.aliyun.com/nexus/content/groups/public/org/codehaus/codehaus-parent/3/codehaus-parent-3.pomDownloaded: http://maven.aliyun.com/nexus/content/groups/public/org/codehaus/codehaus-parent/3/codehaus-parent-3.pom (0 B at 0 B/s)[INFO][INFO] ------------------------------------------------------------------------[INFO] Building girl 0.0.1-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; spring-boot-maven-plugin:1.5.9.RELEASE:run (default-cli) &gt; test-compile @ girl &gt;&gt;&gt;[INFO][INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ girl ---[INFO] Using 'UTF-8' encoding to copy filtered resources.[INFO] Copying 3 resources[INFO] Copying 0 resource[INFO][INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ girl ---[INFO] Nothing to compile - all classes are up to date[INFO][INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ girl ---[INFO] Using 'UTF-8' encoding to copy filtered resources.[INFO] skip non existing resourceDirectory D:\\work\\girl\\src\\test\\resources[INFO][INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ girl ---[INFO] Nothing to compile - all classes are up to date[INFO][INFO] &lt;&lt;&lt; spring-boot-maven-plugin:1.5.9.RELEASE:run (default-cli) &lt; test-compile @ girl &lt;&lt;&lt;[INFO][INFO][INFO] --- spring-boot-maven-plugin:1.5.9.RELEASE:run (default-cli) @ girl --- 3.在springboot的应用的根目录下 mvn install 生成jar后运行 123456789101112先执行 mvn install再执行 java -jar target/girl-0.0.1-SNAPSHOT.jar --spring.profile.active=prodjava -jar target/girl-0.0.1-SNAPSHOT.jar --spring.profile.active=prod . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.5.9.RELEASE)","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://blog.ydstudio.net/tags/spring-boot/"}]},{"title":"Java里有哪些语法糖","slug":"Java里有哪些语法糖","date":"2018-01-09T23:36:33.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/1f95052d.html","link":"","permalink":"https://blog.ydstudio.net/post/1f95052d.html","excerpt":"语法糖（Syntactic Sugar），也称糖衣语法，指在计算机语言中添加的某种语法，这种语法对语言本身功能来说没有什么影响，只是为了方便程序员的开发，提高开发效率。说白了，语法糖就是对现有语法的一个封装。","text":"语法糖（Syntactic Sugar），也称糖衣语法，指在计算机语言中添加的某种语法，这种语法对语言本身功能来说没有什么影响，只是为了方便程序员的开发，提高开发效率。说白了，语法糖就是对现有语法的一个封装。 Java作为一种与平台无关的高级语言，当然也含有语法糖，这些语法糖并不被虚拟机所支持，在编译成字节码阶段就自动转换成简单常用语法。语法糖的大概有三个特性： 提高程序开发效率 程序性能不受影响 规避coder可能因手误而出现的错误 那Java有哪些语法糖呢？Java大概有如下6个语法糖： 泛型与类型擦除 自动装箱与拆箱 变长参数 增强for循环 内部类 枚举类","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"Java出现错误Implicit super constructor  **  is undefined for default constructor. Must define an explicit constructor","slug":"Java出现错误Implicit-super-constructor-is-undefined-for-default-constructor-Must-define-an-explicit-constructor","date":"2018-01-05T23:32:03.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/7764f1f8.html","link":"","permalink":"https://blog.ydstudio.net/post/7764f1f8.html","excerpt":"公司开展新的项目，要求使用Java，给一个月的学习时间。(南京一些比较大的公司也开始转向Java，语言环境发了改变，学习Java也是大势所趋。2018年1月26日修改)，只好开始学习Java！说好有系统的培训，结果我现在在自学！在学习java的时候，遇到了下面的问题： 1Implicit super constructor People() is undefined for default constructor. Must define an explicit constructor","text":"公司开展新的项目，要求使用Java，给一个月的学习时间。(南京一些比较大的公司也开始转向Java，语言环境发了改变，学习Java也是大势所趋。2018年1月26日修改)，只好开始学习Java！说好有系统的培训，结果我现在在自学！在学习java的时候，遇到了下面的问题： 1Implicit super constructor People() is undefined for default constructor. Must define an explicit constructor 大致的意思是父类没有定义默认的无参数的构造方法，父类必须定义一个无参的构造方法。经过一番研究得知，Java中有一下的规则： 因为你的父类已经定义了一个有参的构造函数并且父类中没有默认的无参构造方法，此时编译器不会为你调用默认的构造函数， 当子类继承时，必须在自己的构造函数显式调用父类的构造函数，自己才能确保子类在初始化前父类会被实例化， 如果你父类中有无参的构造函数，子类就不会强制要求调用，即你写的那个就可以通过， 编译器会默认帮你调用父类的构造函数。 修改后的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//父类package dmw;public abstract class People &#123; public String name; protected int age; protected String gender; public People()&#123;&#125; public People(int age,String name,String gender)&#123; this.age = age; this.name =name; this.gender=gender; &#125; public int getAge()&#123; return this.age; &#125; public String getGender()&#123; return this.gender; &#125; public abstract boolean setAge(int age); public abstract boolean setGender(String gender);&#125;//子类package dmw;public class Student extends People &#123; public Student(int age, String name, String gender) &#123; super(age, name, gender); // TODO Auto-generated constructor stub &#125; @Override public boolean setAge(int age) &#123; this.age = age; return false; &#125; @Override public boolean setGender(String gender) &#123; this.gender = gender; return false; &#125; &#125; eclipse的maven配置","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"使用java和javac命令来编译运行Java","slug":"使用java和javac命令来编译运行Java","date":"2018-01-01T23:31:03.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/5d2bd789.html","link":"","permalink":"https://blog.ydstudio.net/post/5d2bd789.html","excerpt":"废话不多说，直奔主题!","text":"废话不多说，直奔主题! 1.先创建一个Test.java的文件，里面保存的内容如下： 1234567class Test&#123; public static void main(String[] args)&#123; System.out.println(\"hello world!\"); &#125;&#125;` 2.使用javac编译Test.java文件，编译通过会生成一个Test.class的文件 1234C:\\Users\\nick\\Desktop&gt;javac Test.javaC:\\Users\\nick\\Desktop&gt; 3.使用java Test命令执行Test.class文件 1234C:\\Users\\nick\\Desktop&gt;java Testhello world!C:\\Users\\nick\\Desktop&gt;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.ydstudio.net/tags/java/"}]},{"title":"Centos6.9安装ElasticSearch2.x","slug":"Centos6-9安装ElasticSearch2-x","date":"2017-12-25T23:29:35.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/971cda27.html","link":"","permalink":"https://blog.ydstudio.net/post/971cda27.html","excerpt":"我这里安装的是ElasticSearch2.x系列。ElasticSearch官方文档1.检查系统是否已经安装了jdk","text":"我这里安装的是ElasticSearch2.x系列。ElasticSearch官方文档1.检查系统是否已经安装了jdk 1yum list installed |grep java 若有自带安装的JDK，如何卸载CentOS系统自带Java环境? 12卸载JDK相关文件输入：yum -y remove java-1.7.0-openjdk*卸载tzdata-java输入：yum -y remove tzdata-java.noarch 注：“*”表示卸载掉java 1.7.0的所有openjdk相关文件2.查看yum库中的Java安装包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849yum -y list java*[root@iZwz99xkrnh5xy0cqp8aofZ ~]# yum -y list java*Loaded plugins: securityInstalled Packagesjava-1.8.0-openjdk.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-debug.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-demo.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-demo-debug.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-devel.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-devel-debug.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-headless.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-headless-debug.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-javadoc.noarch 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-javadoc-debug.noarch 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-src.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesjava-1.8.0-openjdk-src-debug.x86_64 1:1.8.0.151-1.b12.el6_9 @updatesAvailable Packagesjava-1.5.0-gcj.x86_64 1.5.0.0-29.1.el6 base java-1.5.0-gcj-devel.x86_64 1.5.0.0-29.1.el6 base java-1.5.0-gcj-javadoc.x86_64 1.5.0.0-29.1.el6 base java-1.5.0-gcj-src.x86_64 1.5.0.0-29.1.el6 base java-1.6.0-openjdk.x86_64 1:1.6.0.41-1.13.13.1.el6_8 base java-1.6.0-openjdk-demo.x86_64 1:1.6.0.41-1.13.13.1.el6_8 base java-1.6.0-openjdk-devel.x86_64 1:1.6.0.41-1.13.13.1.el6_8 base java-1.6.0-openjdk-javadoc.x86_64 1:1.6.0.41-1.13.13.1.el6_8 base java-1.6.0-openjdk-src.x86_64 1:1.6.0.41-1.13.13.1.el6_8 base java-1.7.0-openjdk.x86_64 1:1.7.0.161-2.6.12.0.el6_9 updates java-1.7.0-openjdk-demo.x86_64 1:1.7.0.161-2.6.12.0.el6_9 updates java-1.7.0-openjdk-devel.x86_64 1:1.7.0.161-2.6.12.0.el6_9 updates java-1.7.0-openjdk-javadoc.noarch 1:1.7.0.161-2.6.12.0.el6_9 updates java-1.7.0-openjdk-src.x86_64 1:1.7.0.161-2.6.12.0.el6_9 updates java-clearsilver.i686 0.10.5-16.el6 epel java-dirq.noarch 1.4-1.el6 epel java-dirq-javadoc.noarch 1.4-1.el6 epel java-service-wrapper.x86_64 3.2.5-23.el6 epel java-service-wrapper-javadoc.noarch 3.2.5-23.el6 epel java-sleep.noarch 2.1-6.el6 epel java-sleep-javadoc.noarch 2.1-6.el6 epel java_cup.x86_64 1:0.10k-5.el6 base java_cup-javadoc.x86_64 1:0.10k-5.el6 base java_cup-manual.x86_64 1:0.10k-5.el6 base javacc.x86_64 4.1-0.5.el6 base javacc-demo.x86_64 4.1-0.5.el6 base javacc-manual.x86_64 4.1-0.5.el6 base javassist.noarch 3.9.0-6.el6 base javassist-javadoc.noarch 3.9.0-6.el6 base javastroke.x86_64 0.5.1-33.el6 epel javatar.noarch 2.5-5.el6 epel javatar-javadoc.noarch 以yum库中的java-1.8为例，将java-1.8.0的所有相关Java程序都安装上。 1yum -y install java-1.8.0-openjdk* 3.查看刚安装的Java版本信息 12345java -version 可查看Java版本[root@iZwz99xkrnh5xy0cqp8aofZ ~]# java -versionopenjdk version \"1.8.0_151\"OpenJDK Runtime Environment (build 1.8.0_151-b12)OpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode) 4.通过rpm安装ElasticSearch 123456789先下载并安装公共签名密钥rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch再安装rpm的repository[elasticsearch-2.x]name=Elasticsearch repository for 2.x packagesbaseurl=https://packages.elastic.co/elasticsearch/2.x/centosgpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 安装ElasticSearch 12345678910111213sudo yum install elasticsearch sudo dnf install elasticsearch sudo zypper install elasticsearch使用yum在CentOS和旧的基于Red Hat分发使用dnf的Fedora和其他新的Red Hat分发使用zypper基于分布的OpenSUSE如果你嫌麻烦可以之前使用下面的方法安装：wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.4.2/elasticsearch-2.4.2.rpmsha1sum elasticsearch-5.6.5.rpmsudo rpm --install elasticsearch-5.6.5.rpm 5.使用chkconfig命令将Elasticsearch配置为在系统启动时自动启动 123456sudo chkconfig --add elasticsearch下面的命令启动或者关闭elasticsearch服务sudo -i service elasticsearch startsudo -i service elasticsearch stop 6.启动elasticsearch服务报错 123456789[root@iZwz99xkrnh5xy0cqp8aofZ src]# service elasticsearch startStarting elasticsearch: OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=NOpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000085330000, 2060255232, 0) failed; error='Cannot allocate memory' (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 2060255232 bytes for committing reserved memory.# An error report file with more information is saved as:# /tmp/hs_err_pid23700.log [FAILED] 这是因为机器的内存不足，可用内存少于1G,解决方法如下： 1234567vim /etc/elasticsearch/jvm.options ##启用如下两项 -Xms4g -Xmx4g##关闭如下两项##-Xms2g ##-Xmx2g 7.配置外网可用访问 123修改配置文件vim/etc/elasticsearch/elasticsearch.yml修改成：network.host: 0.0.0.0 至此，elasticsearch的基本配置完成！","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"elasticSearch","slug":"elasticSearch","permalink":"https://blog.ydstudio.net/tags/elasticSearch/"}]},{"title":"Centos6安装Mongodb","slug":"Centos6安装Mongodb","date":"2017-12-06T23:27:40.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/ab77d2e6.html","link":"","permalink":"https://blog.ydstudio.net/post/ab77d2e6.html","excerpt":"1.运行下面命令查看服务器中是否存在Mongodb的源","text":"1.运行下面命令查看服务器中是否存在Mongodb的源 1yum info mongo-10gen 结果提示没有相关匹配的信息 ，说明系统中的yum源不包含MongoDB的相关资源，所以要在使用yum命令安装MongoDB前需要增加yum源。2.配置包管理系统（yum）创建一个/etc/yum.repos.d/mongodb-org-3.6.repo文件，以便您可以直接使用安装MongoDB yum。写入一下内容： 123456[mongodb-org-3.6]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 3.安装MongoDB包要安装最新的稳定版本的MongoDB，请发出以下命令： 1yum install -y mongodb-org 要安装特定版本的MongoDB，请分别指定每个组件包，并将版本号附加到包名称，如下例所示： 1yum install -y mongodb-org-3.6.0 mongodb-org-server-3.6.0 mongodb-org-shell-3.6.0 mongodb-org-mongos-3.6.0 mongodb-org-tools-3.6.0 4.在阿里云上安全组添加一条规则,并在Centos中的iptables添加一条记录 12345678#阿里云安全组规则允许 自定义 TCP 27017/27017 地址段访问 0.0.0.0/0#iptables-A INPUT -p tcp -m tcp --dport 27017 -j ACCEPT #重启iptables/etc/init.d/iptables restart 5.开机自启动,执行下面命令： 1chkconfig mongod on 6.Mongodb启动、关闭和重启命令 123456#启动service mongod start#关闭service mongod stop#restartservice mongod restart END Mongodb安装结束","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"mongodb","slug":"mongodb","permalink":"https://blog.ydstudio.net/tags/mongodb/"}]},{"title":"Nginx出现The plain HTTP request was sent to HTTPS port","slug":"Nginx出现The-plain-HTTP-request-was-sent-to-HTTPS-port","date":"2017-12-05T23:26:28.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/38efc407.html","link":"","permalink":"https://blog.ydstudio.net/post/38efc407.html","excerpt":"Nginx突然出现了下面的问题： 1The plain HTTP request was sent to HTTPS port 在博客配置ssl证书的时候，博客的https地址和http地址是都能访问，不过，今天突然发现博客访问出现上面的问题，经过百度找到了问题的解决办法，在此记录一下。","text":"Nginx突然出现了下面的问题： 1The plain HTTP request was sent to HTTPS port 在博客配置ssl证书的时候，博客的https地址和http地址是都能访问，不过，今天突然发现博客访问出现上面的问题，经过百度找到了问题的解决办法，在此记录一下。 解决办法： 删掉ssl on; 并在 listen 443; 443后加上ssl即可。Nginx最新配置文件内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061server &#123; listen 80; listen 443 ssl; server_name www.ydstudio.net ydstudio.net; set $my_server_name $scheme://$server_name; root html; if ($host = 'ydstudio.net') &#123; rewrite ^ https://www.ydstudio.net$request_uri? permanent; &#125; #防止ip访问，如http://xxx.xxx.xxx.xxx或者https://xxx.xxx.xxx.xxx if ( $host ~* \"\\d+\\.\\d+\\.\\d+\\.\\d+\" ) &#123; rewrite ^ https://$server_name; &#125; if ( $my_server_name != https://$server_name ) &#123; return 301 https://$server_name$request_uri; #rewrite ^ https://$server_name$request_uri? permanent; &#125; location / &#123; try_files $uri $uri/ /index.php$is_args$args; index index.php index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 location ~ \\.php$ &#123; #root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME html/typecho/$fastcgi_script_name; include fastcgi_params; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; #expires指令设置浏览器缓存过期时间 #可以在http、server、location三个作用域中设置 #缓存图片或视频30天 expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; #缓存js/css 1小时 expires 1h; &#125; #ssl on; ssl_certificate cert/214353452860792.pem; ssl_certificate_key cert/214353452860792.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on;&#125;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"}]},{"title":"PHP出现Deprecated Automatically populating  is deprecated and will be removed in a future version","slug":"PHP出现Deprecated-Automatically-populating-is-deprecated-and-will-be-removed-in-a-future-version","date":"2017-12-05T23:24:30.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/96d1bc5c.html","link":"","permalink":"https://blog.ydstudio.net/post/96d1bc5c.html","excerpt":"本地新搭建的PHP环境，出现下面的问题： 12Deprecated Automatically populating $HTTP_RAW_POST_DATA is deprecated and will be removed in a future version. To avoid this warning set 'always_populate_raw_post_data' to '-1' in php.ini and use the php://input stream instead. in Unknown on line 0Warning: Cannot modify header information - headers already sent in Unknown on line 0","text":"本地新搭建的PHP环境，出现下面的问题： 12Deprecated Automatically populating $HTTP_RAW_POST_DATA is deprecated and will be removed in a future version. To avoid this warning set 'always_populate_raw_post_data' to '-1' in php.ini and use the php://input stream instead. in Unknown on line 0Warning: Cannot modify header information - headers already sent in Unknown on line 0 这个问题和PHP版本有关系，PHP 5.6已经废弃了$HTTP_RAW_POST_DATA。解决方法：修改php.ini 1always_populate_raw_post_data = -1 重启PHP即可","categories":[],"tags":[{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"}]},{"title":"PHP出现以下错误Cannot find module (IP-MIB)","slug":"PHP出现以下错误Cannot-find-module-IP-MIB","date":"2017-12-05T23:22:45.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/82ed83ea.html","link":"","permalink":"https://blog.ydstudio.net/post/82ed83ea.html","excerpt":"查看PHP版本的时候出现下面的问题： 1234567891011121314151617181920212223242526php -vMIB search path: c:/usr/share/snmp/mibsCannot find module (IP-MIB): At line 0 in (none)Cannot find module (IF-MIB): At line 0 in (none)Cannot find module (TCP-MIB): At line 0 in (none)Cannot find module (UDP-MIB): At line 0 in (none)Cannot find module (HOST-RESOURCES-MIB): At line 0 in (none)Cannot find module (SNMPv2-MIB): At line 0 in (none)Cannot find module (SNMPv2-SMI): At line 0 in (none)Cannot find module (NOTIFICATION-LOG-MIB): At line 0 in (none)Cannot find module (UCD-SNMP-MIB): At line 0 in (none)Cannot find module (UCD-DEMO-MIB): At line 0 in (none)Cannot find module (SNMP-TARGET-MIB): At line 0 in (none)Cannot find module (NET-SNMP-AGENT-MIB): At line 0 in (none)Cannot find module (DISMAN-EVENT-MIB): At line 0 in (none)Cannot find module (SNMP-VIEW-BASED-ACM-MIB): At line 0 in (none)Cannot find module (SNMP-COMMUNITY-MIB): At line 0 in (none)Cannot find module (SNMP-FRAMEWORK-MIB): At line 0 in (none)Cannot find module (SNMP-MPD-MIB): At line 0 in (none)Cannot find module (SNMP-USER-BASED-SM-MIB): At line 0 in (none)Cannot find module (SNMP-NOTIFICATION-MIB): At line 0 in (none)Cannot find module (SNMPv2-TM): At line 0 in (none)PHP 7.0.12 (cli) (built: Oct 13 2016 11:04:07) ( NTS )Copyright (c) 1997-2016 The PHP GroupZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies","text":"查看PHP版本的时候出现下面的问题： 1234567891011121314151617181920212223242526php -vMIB search path: c:/usr/share/snmp/mibsCannot find module (IP-MIB): At line 0 in (none)Cannot find module (IF-MIB): At line 0 in (none)Cannot find module (TCP-MIB): At line 0 in (none)Cannot find module (UDP-MIB): At line 0 in (none)Cannot find module (HOST-RESOURCES-MIB): At line 0 in (none)Cannot find module (SNMPv2-MIB): At line 0 in (none)Cannot find module (SNMPv2-SMI): At line 0 in (none)Cannot find module (NOTIFICATION-LOG-MIB): At line 0 in (none)Cannot find module (UCD-SNMP-MIB): At line 0 in (none)Cannot find module (UCD-DEMO-MIB): At line 0 in (none)Cannot find module (SNMP-TARGET-MIB): At line 0 in (none)Cannot find module (NET-SNMP-AGENT-MIB): At line 0 in (none)Cannot find module (DISMAN-EVENT-MIB): At line 0 in (none)Cannot find module (SNMP-VIEW-BASED-ACM-MIB): At line 0 in (none)Cannot find module (SNMP-COMMUNITY-MIB): At line 0 in (none)Cannot find module (SNMP-FRAMEWORK-MIB): At line 0 in (none)Cannot find module (SNMP-MPD-MIB): At line 0 in (none)Cannot find module (SNMP-USER-BASED-SM-MIB): At line 0 in (none)Cannot find module (SNMP-NOTIFICATION-MIB): At line 0 in (none)Cannot find module (SNMPv2-TM): At line 0 in (none)PHP 7.0.12 (cli) (built: Oct 13 2016 11:04:07) ( NTS )Copyright (c) 1997-2016 The PHP GroupZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies 解决办法： 123#关掉snmp扩展#windows注释掉 extension=php_snmp.dll","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"}]},{"title":"MySQL出现1267的错误","slug":"MySQL出现1267的错误","date":"2017-12-04T23:21:47.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/75a1fb40.html","link":"","permalink":"https://blog.ydstudio.net/post/75a1fb40.html","excerpt":"执行SQL的时候，MySQL出现了下面的1267的错误，提示与字符集有关系。 11267 - Illegal mix of collations (utf8_unicode_ci,IMPLICIT) and (utf8_general_ci,IMPLICIT) for operation '='","text":"执行SQL的时候，MySQL出现了下面的1267的错误，提示与字符集有关系。 11267 - Illegal mix of collations (utf8_unicode_ci,IMPLICIT) and (utf8_general_ci,IMPLICIT) for operation '=' 查找问题的时候，发现有一张表是从其他地方拷贝过来的，这个表和我们目前项目中的表，稍微有点不同。数据表中字符串类型的字段，不仅有字符集这个属性，还有一个排序规则的属性。拷贝过来的表的字符串类型的字段的排序规则是utf8_unicode_ci，而我们的项目中的是utf8_general_ci，修改之后再次执行上述的SQL，就没有出现上面的错误！下面是问题的简单总结： 1234ci(caseinsensitive大小写不敏感)utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别。utf8_general_ci校对速度快，但准确度稍差。utf8_unicode_ci准确度高，但校对速度稍慢。 如果你的应用有德语、法语或者俄语，请一定使用utf8_unicode_ci。一般用utf8_general_ci就够了，到现在也没发现问题。。。 详细总结： 1、对于一种语言仅当使用utf8_unicode_ci排序做的不好时，才执行与具体语言相关的utf8字符集校对规则。例如，对于德语和法语，utf8_unicode_ci工作的很好，因此不再需要为这两种语言创建特殊的utf8校对规则。2、utf8_general_ci也适用与德语和法语，除了‘?’等于‘s’，而不是‘ss’之外。如果你的应用能够接受这些，那么应该使用 utf8_general_ci，因为它速度快。否则，使用utf8_unicode_ci，因为它比较准确。用一句话概况上面这段话：utf8_unicode_ci比较准确，utf8_general_ci速度比较快。通常情况下 utf8_general_ci的准确性就够我们用的了，在我看过很多程序源码后，发现它们大多数也用的是utf8_general_ci，所以新建数据 库时一般选用utf8_general_ci就可以了。 如何在MySQL5.0中使用UTF8在 my.cnf中增加下列参数复制代码代码如下: 1234[mysqld]init_connect='SET NAMES utf8'default-character-set=utf8default-collation = utf8_general_ci 执行查询 mysql&gt; show variables; 相关如下: 123456789character_set_client | utf8 character_set_connection | utf8 character_set_database | utf8 character_set_results | utf8 character_set_server | utf8 character_set_system | utf8collation_connection | utf8_general_ci collation_database | utf8_general_ci collation_server | utf8_general_ci 个人见解，对于数据库的使用，utf8_general 已经足够的准确，并且相较与 utf8_unicode速度上有优势，固可放心采用之","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.ydstudio.net/tags/mysql/"}]},{"title":"修改ssh的默认22端口","slug":"修改ssh的默认22端口","date":"2017-12-04T23:20:41.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/68417c42.html","link":"","permalink":"https://blog.ydstudio.net/post/68417c42.html","excerpt":"在国外买的vps防止别人扫描端口，于是我把ssh默认的22端口修改一下。1.修改配置文件：/etc/ssh/sshd_config ，找到","text":"在国外买的vps防止别人扫描端口，于是我把ssh默认的22端口修改一下。1.修改配置文件：/etc/ssh/sshd_config ，找到 1#port 22 2.先将Port 22 前面的 # 号去掉，并另起一行。如定义SSH端口号为33322，则输入 1Port 33322 自定义端口选择建议在万位的端口（如：10000-65535之间）也许您会问为什么要先把port 22前面的 # 去掉呢？因为在配置文件中，# 是Linux的注释字符。注释字符后的代码程序是不会执行的。SSH默认的（即非手动指定）端口为22，所以配置文件在默认的情况下以注释字符出现。当需要指定其它端口或多端口同时访问时，就要删掉注释符号，告知程序按照您的意愿来执行响应操作。以上操作，手动指定SSH端口为22和33322（双端口号），保留22是为了防止个别防火墙屏蔽了其它端口导致无法连接VPS（如没单独指定22，新指定的33322端口防火墙也没放行，那么可能无法通过SSH连接VPS或服务器）。为了防止不必要问题的产生，所以要给自己保留条“后路”。3、修改完毕后，重启SSH服务，并退出当前连接的SSH端口。（如图） 1service sshd restart CentOS下SSH默认端口22修改成其他端口4.重启完毕，尝试使用新端口登陆连接成功，需要重新添加SSH-RSA验证，点击是（或Yes）即可。5.若能正常访问，返回第一步，根据第二步的操作将原port 22整段注释或删掉，再按第三步重启SSH即可。以上步骤重启后使用默认22号端口无法进入SSH，达到目的。【请注意】：如果您启用了防火墙iptables，那么必须先添加新开的33322端口补充：iptables开放端口端示例为了方便举例说明，就直接拿来一段我的现有服务器上运行的防火墙iptables内容。 请注意：后面的注释说明文字： 1234567891011121314151617vim /etc/sysconfig/iptables# Firewall configuration written by system-config-firewall# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT # （ssh端口）-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT # （web端口）-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT # （ftp端口）-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT 修改完防火墙iptables后，需要重新启动： 123/etc/init.d/iptables restart# 或者service iptables restart 注意：iptables配置文件存放位置是：/etc/sysconfig/iptables保存命令：service iptables save使用命令：iptables -L -n 可以查看当前iptables的开放端口情况。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"}]},{"title":"迅搜(xunsearch) 多值属性的处理","slug":"迅搜-xunsearch-多值属性的处理","date":"2017-12-04T23:18:36.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/10379547.html","link":"","permalink":"https://blog.ydstudio.net/post/10379547.html","excerpt":"我之前使用Yii2框架做了一个电影网站dy360.net,网站的搜索是通过MySQL的like实现，搜索的条件很多，担心以后数据越来越多，会拖垮网站的速度，于是想通过搜索引擎来解决！ 开始准备使用sphinx，研究发现不太好使。后发现迅搜(xunsearch)，文档比较清楚，上手比较简单，并且有Yii2的composer包，于是决定使用迅搜。","text":"我之前使用Yii2框架做了一个电影网站dy360.net,网站的搜索是通过MySQL的like实现，搜索的条件很多，担心以后数据越来越多，会拖垮网站的速度，于是想通过搜索引擎来解决！ 开始准备使用sphinx，研究发现不太好使。后发现迅搜(xunsearch)，文档比较清楚，上手比较简单，并且有Yii2的composer包，于是决定使用迅搜。 使用的过程中遇到这样一个问题：一部电影有多个演员，出品国家或地区，其实就是文档的多值属性的新建、搜索的问题。我研究了一下，最终结局方案如下： 123456789101112131415161718192021222324252627282930313233343536#项目的配置文件project.name = yddyproject.default_charset = utf-8server.index = 8383server.search = 8384[id]type = idphrase = yes[summary]type = bodycutlen=900[year]type = numericphrase = yesindex = self [actors_text]type = stringindex = selftokenizer = split(/)[category_id]type = stringindex = selftokenizer = split(,)[country_id]type = stringindex = selftokenizer = split(,)phrase = yes 其实就是使用迅搜的tokenizer分词器，文档上具体的语法如下： 1234567891011tokenizer 分词器默认为 default 采用内置的功能强大的 scws 分词，适合绝大多数字符串字段。也可以指定自定义分词器， 格式为 name 或 name(arg) 两种形式，其中 name 是分词器名称，arg 则是传递给分词器构造函数的参数。 自定义分词器需要在 lib/ 目录下编写名为 XSTokenizerName 的分词类并实现接口 XSTokenizer， 内置支持的分词器有以下几种：full 表示本字段的值整体作为一个检索词，像各种 ID 都适合这种情况none 表示本字段没有任何词汇用于索引split([ ]) 表示根据参数分割内容，默认参数为空格，若参数以 / 开头并以 / 结尾则 内部调用 preg_split(arg, ..) 来分割取词，以支持正则或其它特殊字符分割xlen([2]) 表示根据指定参数长度分段取词，如 ABCDEF =&gt; AB + CD + EFxstep([2]) 表示根据指定参数步长逐段取词，如 ABCDEF =&gt; AB + ABCD + ABCDEFscws([3]) 表示采用指定参数为复合等级的 scws 分词，（若无特殊复合需求，无需指定）tokenizer = default 然后，根据不同情况使用不同的分割参数，譬如，有的使用’/‘，有的使用’,’。最后，搜索代码如下： 12345678910111213141516171819202122232425262728293031323334353637public static function search($params)&#123; $db = Yii::$app-&gt;xunsearch-&gt;getDatabase('yddy'); $xs = $db-&gt;xs; $search = $xs-&gt;getSearch(); $keywords = $params['word']; if(empty($keywords))&#123; $keywords =''; &#125; $search = $search-&gt;setQuery($keywords); if($category=$params['category'])&#123; $search-&gt;addQueryTerm('category_id',$category); &#125; if($country=$params['country'])&#123; $search-&gt;addQueryTerm('country_id',$country); &#125; if( (empty($params['other']) ) &amp;&amp; ($year = intval($params['year'])) &amp;&amp; is_numeric($params['year']))&#123; $search-&gt;addQueryTerm('year',$year); &#125;elseif(($params['other'] == 'ago') &amp;&amp; ($year = intval($params['year'])) )&#123; //$search-&gt;addRange('year',1900,1978); $search-&gt;addRange('year',1900,$year); &#125; if( $rating=intval($params['rating']))&#123; $search-&gt;addQueryTerm('rate', $rating); &#125; $search-&gt;addQueryTerm('subtype',$params['subtype']); //$search-&gt;addQueryTerm('status',1); //echo $search-&gt;getQuery(); return $search; &#125;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"xunsearch","slug":"xunsearch","permalink":"https://blog.ydstudio.net/tags/xunsearch/"}]},{"title":"Centos6.9上搭建lnmp环境","slug":"Centos6-9上搭建lnmp环境","date":"2017-11-29T23:17:13.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/123335f3.html","link":"","permalink":"https://blog.ydstudio.net/post/123335f3.html","excerpt":"我准备把之前做的www.dy360.net重新搞起来，就在vultr上买了vps，于是乎有了下面这篇文章。在vps上系统是Centos6.9，至于为什么使用Centos，那是因为我个人比较熟悉Centos！","text":"我准备把之前做的www.dy360.net重新搞起来，就在vultr上买了vps，于是乎有了下面这篇文章。在vps上系统是Centos6.9，至于为什么使用Centos，那是因为我个人比较熟悉Centos！ yum安装Nginx1.执行下面的yum命令安装Nginx 1yum install nginx 如果上面命令没有执行成功，说明系统中yum源中没有Nginx的源，因此我们需要手动添加Nginx的源，步骤如下： 123456789101112vi /etc/yum.repos.d/nginx.repo输入一下内容：[nginx]name=nginx repobaseurl=http://nginx.org/packages/mainline/centos/6/$basearch/gpgcheck=0enabled=1保存之后执行下面的命令更新源yum clean allyum update 2.启动Nginx 1service nginx start 现在Nginx已经启动了，直接访问服务器就能看到Nginx欢迎页面了的。如果还无法访问，则需配置一下Linux防火墙。3.配置防火墙,开放80端口 12345678vim /etc/sysconfig/iptables-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT#复制上面一行，将22改成80,保存即可-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT#最好重启一下防火墙service iptables restart 注意：如果是阿里云的ecs,你可能需要在阿里云的主机管理后台，添加安全组规则，方可开启80端口4.设置开机启动 12chkconfig --list | grep nginxchkconfig nginx on END：Nginx安装配置完成 yum 安装MySQL5.6参考: https://www.cnblogs.com/007sx/p/7083143.html1.检查系统是否安装其他版本的MYSQL数据 12yum list installed | grep mysqlyum -y remove mysql-libs.x86_64 2.配置MySQL源 123wget http://repo.mysql.com/mysql-community-release-el6-5.noarch.rpmrpm -ivh mysql-community-release-el6-5.noarch.rpmyum repolist all | grep mysql 3.安装MYSQL数据库 1yum install mysql-community-server -y 4.设置为开机启动(2、3、4都是on代表开机自动启动) 12chkconfig --list | grep mysqldchkconfig mysqld on5.启动mysql 1234567891011121314151617181920212223242526272829303132333435363738 service mysqld start # 显示如图（部分） PLEASE REMEMBER TO SET A PASSWORD FOR THE MySQL root USER !To do so, start the server, then issue the following commands: /usr/bin/mysqladmin -u root password 'new-password' /usr/bin/mysqladmin -u root -h vultr password 'new-password'Alternatively you can run: /usr/bin/mysql_secure_installationwhich will also give you the option of removing the testdatabases and anonymous user created by default. This isstrongly recommended for production servers.See the manual for more instructions.Please report any problems at http://bugs.mysql.com/The latest information about MySQL is available on the web at http://www.mysql.comSupport MySQL by buying support/licenses at http://shop.mysql.comNote: new default config file not created.Please make sure your config file is currentWARNING: Default config file /etc/my.cnf exists on the systemThis file will be read by default by the MySQL serverIf you do not want to use this, either remove it, or use the--defaults-file argument to mysqld_safe when starting the server [ OK ]Starting mysqld: [ OK ]6.设置mysql密码 1/usr/bin/mysqladmin -u root password 'xxxxx' 安全处理,看不懂英文直接一路yes就行 1/usr/bin/mysql_secure_installation[注意]2017/12/24更新： 12345678910111213141516171819202122今日安装MySQL执行上面的命令的时候出现下面的话In order to log into MySQL to secure it, we'll need the currentpassword for the root user. If you've just installed MySQL, andyou haven't set the root password yet, the password will be blank,so you should just press enter here.Enter current password for root (enter for none): OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MySQLroot user without the proper authorisation.You already have a root password set, so you can safely answer 'n'.Change the root password? [Y/n] YNew password: Re-enter new password: Password updated successfully!Reloading privilege tables.. ... Success!意思是root用户设置密码，之前我们已经设置过了，这个地方输入“no”即可，不然你还要重新设置root用户密码。 7.设置utf-8编码 1234567891011121314查看mysql原本编码：mysql&gt; show variables like 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+ 编辑mysql的配置文件/etc/my.cnf 123456789101112131415161718192021222324252627282930313233343536373839vi /etc/my.cnf[mysqld]character-set-server=utf8 collation-server=utf8_general_ci sql_mode='NO_ENGINE_SUBSTITUTION'[mysql]default-character-set = utf8[mysql.server]default-character-set = utf8[mysqld_safe]default-character-set = utf8[client]default-character-set = utf8#重启mysqlservice mysqld restart#再次查看mysql&gt; show variables like 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+ END:到此MySQL安装配置成功 编译安装PHP7.0.26参考： https://segmentfault.com/a/1190000005005068 http://blog.csdn.net/tomspcc/article/details/71080991 1.安装PHP支持库 1yum install gcc gcc-c++ libmcrypt-devel mhash-devel libxslt-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel libidn libidn-devel openssl openssl-devel php-mcrypt ####2.下载PHP7.0.26源码包 1wget http://sg2.php.net/distributions/php-7.0.26.tar.gz 3.编译安装PHP 12345678910111213141516171819202122232425262728293031323334353637383940414243444546./configure \\--prefix=/usr/local/php \\--exec-prefix=/usr/local/php \\--bindir=/usr/local/php/bin \\--with-fpm-user=www \\--with-fpm-group=www \\--sbindir=/usr/local/php/sbin \\--includedir=/usr/local/php/include \\--libdir=/usr/local/php/lib/php \\--mandir=/usr/local/php/php/man \\--with-config-file-path=/usr/local/php/etc \\--with-mcrypt=/usr/include \\--with-mhash \\--with-openssl \\--with-mysqli=shared,mysqlnd \\--with-pdo-mysql=shared,mysqlnd \\--with-gd \\--with-iconv \\--with-zlib \\--enable-zip \\--enable-inline-optimization \\--disable-debug \\--disable-rpath \\--enable-shared \\--enable-xml \\--enable-bcmath \\--enable-shmop \\--enable-sysvsem \\--enable-mbregex \\--enable-mbstring \\--enable-ftp \\--enable-gd-native-ttf \\--enable-pcntl \\--enable-sockets \\--with-xmlrpc \\--enable-soap \\--without-pear \\--with-gettext \\--enable-session \\--with-curl \\--with-jpeg-dir \\--with-freetype-dir \\--enable-opcache \\--enable-fpm \\--without-gdbm \\--disable-fileinfo 编译报下面的错误 123checking for stdarg.h... (cached) yeschecking for mcrypt support... yesconfigure: error: mcrypt.h not found. Please reinstall libmcrypt. 执行下面的命令安装libmcrypet 1yum install libmcrypt-devel -y 若上面的方法解决不了，可以编译安装libmcrypet 1234567cd /usr/local/srcwget http://softlayer.dl.sourceforge.net/sourceforge/mcrypt/libmcrypt-2.5.8.tar.gztar -zxvf libmcrypt-2.5.8.tar.gzcd /usr/local/src/libmcrypt-2.5.8./configure --prefix=/usr/localmakemake install 上面的方法要是还是不行，那用下面的方法： 12345安装第三方yum源wget http://www.atomicorp.com/installers/atomicsh ./atomicyum install libmcrypt-devel -y 4.最后执行下面的命令，完成PHP的安装 12make make install 5.配置PHP-FPM 增加用户&amp;用户组 12groupadd wwwuseradd -g www www 拷贝php-fpm.conf文件 1cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf 拷贝php-fpm include文件 1cp usr/local/php/etc/php-fpm.d/www.conf.default www.conf 从源码包里拷贝php.ini 1cp /usr/local/src/php-7.0.26/php.ini-production /usr/local/php/etc/php.ini 6.将PHP加入环境变量 1234vi /etc/profileexport PATH=$PATH:/usr/local/php/binsource /etc/profile 7.php-fpm自启动 从源码包里拷贝启动脚本1cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm 加入系统启动项1chkconfig php-fpm on 8.重启PHP 1service php-fpm restart END:PHP安装配置完成 编译安装git参考:http://www.cnblogs.com/fazo/p/5578644.html 1.安装依赖的包 1yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 2.下载源码包 123wget https://github.com/git/git/archive/v2.9.0.zipunzip v2.9.0.zipcd git-2.9.0 3.编译安装 12make prefix=/usr/local/git allmake prefix=/usr/local/git install 4.加入系统变量 12vi /etc/profile export PATH=/usr/local/git/bin:$PATH 5.配置git 123git config --global user.name 'vultr'git config --global user.email 'vultr@dy360.net' 'vultr@dy360.net'git config --global credential.helper store #保存密码 6.生成ssh密钥,执行下面的命令，一路回车即可，即可用密钥克隆项目。 1ssh-keygen -t rsa -C 'vultr@dy360.net' END:git安装配置成功 最后，终于环境搭建好了！自己搭建lnmp环境少说也有十几次了，可是每次都有新感觉！因为每次出现的问题，都不太一样！最近两次都出现了Nginx安装后，通过ip不能访问的问题，结果发现都是防火墙的问题，没有开启80端口。坑的要命！","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"git","slug":"git","permalink":"https://blog.ydstudio.net/tags/git/"},{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"},{"name":"mysql","slug":"mysql","permalink":"https://blog.ydstudio.net/tags/mysql/"}]},{"title":"tar 分卷压缩和解压","slug":"tar-分卷压缩和解压","date":"2017-11-27T23:16:14.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/4aac2ff2.html","link":"","permalink":"https://blog.ydstudio.net/post/4aac2ff2.html","excerpt":"tar 本身为一个打包工具，可以把目录打包成一个文件，它的好处是它把所有文件整合成一个大文件整体，方便拷贝或者移动。","text":"tar 本身为一个打包工具，可以把目录打包成一个文件，它的好处是它把所有文件整合成一个大文件整体，方便拷贝或者移动。 123456789101112131415161718192021语法：tar [-zjxcvfpP] filename,tar命令有多个选项，其中不常用的做了标注。“-z” : 同时用gzip压缩“-j” : 同时用bzip2压缩“-x” : 解包或者解压缩“-t” : 查看tar包里面的文件“-c” : 建立一个tar包或者压缩文件包“-v” : 可视化“-f” : 后面跟文件名，压缩时跟 “-f 文件名”，意思是压缩后的文件名为filename, 解压时跟 “-f 文件名”，意思是解压filename. 请注意，如果是多个参数组合的情况下带有 “-f”，请把 “-f” 写到最后面。“-p” : 使用原文件的属性，压缩前什么属性压缩后还什么属性。（不常用）“-P” : 可以使用绝对路径。（不常用）--exclude filename : 在打包或者压缩时，不要将filename文件包括在内。（不常用） 那如何分卷解压缩呢？ 假如要将目录logs打包压缩并分割成多个1M的文件，可以用下面的命令： 12345678910111213141516tar cjf - logs/ |split -b 1m - logs.tar.bz2完成后会产生下列文件：logs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac要解压的时候只要执行下面的命令就可以了：cat logs.tar.bz2.a* | tar xj再举例：要将文件test.pdf分包压缩成500 bytes的文件：tar czf - test.pdf | split -b 500 - test.tar.gz最后要提醒但是那两个\"-\"不要漏了，那是tar的ouput和split的input的参数。tar cjf - logs/ |split -b 1m - logs.tar.bz2.完成后会产生下列文件：logs.tar.bz2.aa, logs.tar.bz2.ab, logs.tar.bz2.ac要解压的时候只要执行下面的命令就可以了：cat logs.tar.bz2.a* | tar xj","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"}]},{"title":"如何强制全站https访问","slug":"如何强制全站https访问","date":"2017-11-23T23:12:52.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/773d918c.html","link":"","permalink":"https://blog.ydstudio.net/post/773d918c.html","excerpt":"今天在阿里云上搞了一个免费的https证书，于是就在自己的服务器上安装了一下，配置好证书之后，如何强制全站https访问呢？其实方法有很多，这里只给出两个比较简单的方法：","text":"今天在阿里云上搞了一个免费的https证书，于是就在自己的服务器上安装了一下，配置好证书之后，如何强制全站https访问呢？其实方法有很多，这里只给出两个比较简单的方法： 12345#在自己的虚拟主机配置server节点中添加下面的代码，使用其一即可。#方法一rewrite ^ https://$server_name$request_uri? permanent;#方法二return 301 https://$server_name$request_uri; 我用的是第一个方法，大家可以根据自己的喜好，来决定使用哪中方法。下面贴出我自己网站的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253server &#123; listen 443; listen 80; server_name www.ydstudio.net; set $my_server_name $scheme://$server_name; #防止ip访问，如http://xxx.xxx.xxx.xxx或者https://xxx.xxx.xxx.xxx if ( $host ~* \"\\d+\\.\\d+\\.\\d+\\.\\d+\" ) &#123; rewrite ^ https://$server_name; &#125; if ( $my_server_name != https://$server_name ) &#123; rewrite ^ https://$server_name$request_uri? permanent; &#125; location / &#123; root /usr/share/nginx/html/typecho/; try_files $uri $uri/ /index.php$is_args$args; index index.php index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 location ~ \\.php$ &#123; #root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html/typecho/$fastcgi_script_name; include fastcgi_params; &#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one #location ~ /\\.ht &#123; # deny all; #&#125; ssl on; ssl_certificate /etc/nginx/cert/214353452860792.pem; ssl_certificate_key /etc/nginx/cert/214353452860792.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on;&#125;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"}]},{"title":"Linux下chkconfig命令详解","slug":"Linux下chkconfig命令详解","date":"2017-11-19T23:11:31.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/a5b69b88.html","link":"","permalink":"https://blog.ydstudio.net/post/a5b69b88.html","excerpt":"简介chkconfig命令检查、设置系统的各种服务。这是Red Hat公司遵循GPL规则所开发的程序，它可查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。","text":"简介chkconfig命令检查、设置系统的各种服务。这是Red Hat公司遵循GPL规则所开发的程序，它可查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。 使用方法1234567891011121314[root@iZwz99xkrnh5xy0cqp8aofZ ~]# chkconfig --helpchkconfig version 1.3.49.5 - Copyright (C) 1997-2000 Red Hat, Inc.This may be freely redistributed under the terms of the GNU Public License.usage: chkconfig [--list] [--type &lt;type&gt;] [name] chkconfig --add &lt;name&gt; chkconfig --del &lt;name&gt; chkconfig --override &lt;name&gt; chkconfig [--level &lt;levels&gt;] [--type &lt;type&gt;] &lt;name&gt; &lt;on|off|reset|resetpriorities&gt;[root@iZwz99xkrnh5xy0cqp8aofZ ~]# --add：增加所指定的系统服务，让chkconfig指令得以管理它，并同时在系统启动的叙述文件内增加相关数据； --del：删除所指定的系统服务，不再由chkconfig指令管理，并同时在系统启动的叙述文件内删除相关数据； --level&lt;等级代号&gt;：指定读系统服务要在哪一个执行等级中开启或关毕。 level等级代号解释如下： 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 需要说明的是，level选项可以指定要查看的运行级而不一定是当前运行级。对于每个运行级，只能有一个启动脚本或者停止脚本。当切换运行级时，init不会重新启动已经启动的服务，也不会再次去停止已经停止的服务。 运行级文件：每个被chkconfig管理的服务需要在对应的init.d下的脚本加上两行或者更多行的注释。第一行告诉chkconfig缺省启动的运行级以及启动和停止的优先级。如果某服务缺省不在任何运行级启动，那么使用-代替运行级。第二行对服务进行描述，可以用\\跨行注释。如下： 123# chkconfig: 2345 20 80# description: Saves and restores system entropy pool for \\# higher quality random number generation. 实例： 12345678chkconfig --list #列出所有的系统服务。 chkconfig --add httpd #增加httpd服务。 chkconfig --del httpd #删除httpd服务。 chkconfig --level httpd 2345 on #设置httpd在运行级别为2、3、4、5的情况下都是on（开启）的状态。 chkconfig --list #列出系统所有的服务启动情况。 chkconfig --list mysqld #列出mysqld服务设置情况。 chkconfig --level 35 mysqld on #设定mysqld在等级3和5为开机运行服务，--level 35表示操作只在等级3和5执行，on表示启动，off表示关闭。 chkconfig mysqld on #设定mysqld在各等级为on，“各等级”包括2、3、4、5等级。 如何增加一个服务： 123服务脚本必须存放在/etc/ini.d/目录下；chkconfig --add servicename在chkconfig工具服务列表中增加此服务，此时服务会被在/etc/rc.d/rcN.d中赋予K/S入口了；chkconfig --level 35 mysqld on修改服务的默认启动等级。 注意 此命令只能在Centos7以下使用，因为Centos7中已由systemctl替代chkconfig命令","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"}]},{"title":"Mycat 数据库分库分表中的安装与使用","slug":"Mycat-数据库分库分表中的安装与使用","date":"2017-11-19T23:02:47.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/56117af9.html","link":"","permalink":"https://blog.ydstudio.net/post/56117af9.html","excerpt":"Mycat需要jdk的支持，而我的Mac中的jdk已经安装好了，所以此步骤省略，需要安装jdk的童鞋请自行安装jdk。","text":"Mycat需要jdk的支持，而我的Mac中的jdk已经安装好了，所以此步骤省略，需要安装jdk的童鞋请自行安装jdk。 安装Mycat:直接下载解压到/usr/local/mycat目录即可，我下载的是最新版1.6。 运行linux： ./mycat start 启动 ./mycat stop 停止 ./mycat console 前台运行 ./mycat install 添加到系统自动启动（暂未实现） ./mycat remove 取消随系统自动启动（暂未实现） ./mycat restart 重启服务 ./mycat pause 暂停 ./mycat status 查看启动状态 win： 直接运行startup_nowrap.bat，如果出现闪退，在cmd 命令行运行，查看出错原因 内存配置：启动前，一般需要修改JVM配置参数，打开conf/wrapper.conf文件，如下行的内容为2G和2048，可根据本机配置情况修改为512M或其它值。 以下配置跟jvm参数完全一致，可以根据自己的jvm参数调整。 1234567891011121314151617181920212223242526272829303132333435363738394041Java Additional Parameterswrapper.java.additional.1=wrapper.java.additional.1=-DMYCAT_HOME=.wrapper.java.additional.2=-serverwrapper.java.additional.3=-XX:MaxPermSize=64Mwrapper.java.additional.4=-XX:+AggressiveOptswrapper.java.additional.5=-XX:MaxDirectMemorySize=100mwrapper.java.additional.6=-Dcom.sun.management.jmxremotewrapper.java.additional.7=-Dcom.sun.management.jmxremote.port=1984wrapper.java.additional.8=-Dcom.sun.management.jmxremote.authenticate=falsewrapper.java.additional.9=-Dcom.sun.management.jmxremote.ssl=falsewrapper.java.additional.10=-Xmx100mwrapper.java.additional.11=-Xms100mwrapper.java.additional.12=-XX:+UseParNewGCwrapper.java.additional.13=-XX:+UseConcMarkSweepGCwrapper.java.additional.14=-XX:+UseCMSCompactAtFullCollectionwrapper.java.additional.15=-XX:CMSFullGCsBeforeCompaction=0wrapper.java.additional.16=-XX:CMSInitiatingOccupancyFraction=70以下配置作废：wrapper.java.initmemory=3wrapper.java.maxmemory=64 Mycat连接测试：测试mycat与测试mysql完全一致，mysql怎么连接，mycat就怎么连接。 推荐先采用命令行测试： 123456789101112131415sammac:local Sam$ mysql -uroot -p -P8066 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 339Server version: 5.5.48-log MySQL Community Server (GPL)Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; 如果采用工具连接，1.4,1.3目前部分工具无法连接，会提示database not selected，建议采用高版本，navicat测试。1.5已经修复了部分工具连接 注 文章部分内容转自Mycat官网","categories":[],"tags":[{"name":"mycat","slug":"mycat","permalink":"https://blog.ydstudio.net/tags/mycat/"},{"name":"database","slug":"database","permalink":"https://blog.ydstudio.net/tags/database/"}]},{"title":"实现MySQL主从复制","slug":"实现MySQL主从复制","date":"2017-11-17T22:28:06.000Z","updated":"2020-03-15T06:10:35.000Z","comments":true,"path":"post/34c3deb2.html","link":"","permalink":"https://blog.ydstudio.net/post/34c3deb2.html","excerpt":"实验准备：在Pc上安装两个MySQL，分别监听3307和3308端口，在centos7上也安装一个MySQL，这样我们就有三个slave！首先我们要保证4个MySQL上的数据一致，并且配置好各个的日志，这样即使出错了，也容易找出错误。","text":"实验准备：在Pc上安装两个MySQL，分别监听3307和3308端口，在centos7上也安装一个MySQL，这样我们就有三个slave！首先我们要保证4个MySQL上的数据一致，并且配置好各个的日志，这样即使出错了，也容易找出错误。 Slave1：MySQL3307 Slave2：MySQL3308 Slave3：Centos7上的MySQL Master: 运行在3306端口的MySQL 修改Master的配置1234567891011[mysqld]server-id=1 //[必须]服务器唯一ID，默认是1，可以随便配置，只要不重复即可binlog-do-db = xxx // 同步的数据库名，如有多个写多行binlog-ignore-db =mysql // 不需要备份的数据库，如有多个写多行read-only =0 // 主机，读写都可以log-bin=mysql-bin //[必须]启用二进制日志 binlog-format =mixed // bin的格式relay-log=mysql-relay // 中继日志文件名expire-logs-days=20 // 日志最长保存时间max_binlog_size = 100M // 日志最大容量slave-skip-errors=all // 跳过所有错误 修改Slave的配置1234567891011121314151617181920#MySQL3307 [mysqld] log-bin=mysql-bin //[不是必须]启用二进制日志 server-id=3307 //[必须]服务器唯一ID，默认是1，可以随便配置，只要不重复即可 replicate-do-db =test // 复制某个库,如有多个写多行 replicate-ignore-db=mysql // 不复制某个库,如有多个写多行#MySQL3308[mysqld] log-bin=mysql-bin //[不是必须]启用二进制日志 server-id=3308 //[必须]服务器唯一ID，默认是1，可以随便配置，只要不重复即可 replicate-do-db =test // 复制某个库,如有多个写多行 replicate-ignore-db=mysql // 不复制某个库,如有多个写多行#Centos7[mysqld] log-bin=mysql-bin //[不是必须]启用二进制日志 server-id=3 //[必须]服务器唯一ID，默认是1，可以随便配置，只要不重复即可 replicate-do-db =test // 复制某个库,如有多个写多行 replicate-ignore-db=mysql // 不复制某个库,如有多个写多行 保存修改后重启4个MySQL服务在Master创建3个MySQL用户1234567grant replication client,replication slave on *.* to slave3307@'%' identified by 'slave3307';grant replication client,replication slave on *.* to slave3308@'%' identified by 'slave3308';grant replication client,replication slave on *.* to centos7@'%' identified by 'centos7'; flush privileges; 登录Master执行命令查看log_pos和log_file123456show master status; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000062 | 8233| | | +------------------+----------+--------------+------------------+ 注意 执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化 配置从服务器Slave，下面的命令分别在3个MySQL上执行：1234567891011121314change master to master_host=&apos;192.168.19.254&apos;,master_port=3306,master_user=&apos;slave3307&apos;,master_password=&apos;slave3307&apos;,master_log_file=&apos;mysql-bin.000062&apos;,master_log_pos=8233;start slave #启动从服务器复制功能change master to master_host=&apos;192.168.19.254&apos;,master_port=3306,master_user=&apos;slave3308&apos;,master_password=&apos;slave3308&apos;,master_log_file=&apos;mysql-bin.000062&apos;,master_log_pos=8233;start slave #启动从服务器复制功能change master to master_host=&apos;192.168.19.254&apos;,master_port=3306,master_user=&apos;centos7&apos;,master_password=&apos;centos7&apos;,master_log_file=&apos;mysql-bin.000087&apos;,master_log_pos=8233;start slave #启动从服务器复制功能 检查Slave复制功能的状态1show slave status\\G 注意 Slave_IO及Slave_SQL进程必须正常运行，即YES状态，否则都是错误的状态(如：其中一个NO或者出现Connection)。有时候是server-id配置错误、防火墙拦截或账户没有权限，仔细检查各个的错误日志，就能很快找到问题所在。 END 以上操作过程，主从服务器配置完成附1234#在Windows上注册MySQL添加服务C:\\phpStudy\\MySQL3307\\bin\\mysqld install mysql3307 --defaults-file=\"C:\\phpStudy\\MySQL3307\\my.ini\"C:\\phpStudy\\MySQL3308\\bin\\mysqld install mysql3308 --defaults-file=\"C:\\phpStudy\\MySQL3308\\my.ini\" MySQL主从复制跳过错误两种方式： 12345678910111.跳过指定数量的事务：mysql&gt;stop slave ;mysql&gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1; #跳过一个事务mysql&gt;start slave;2.修改mysql的配置文件，通过slave_skip_errors参数来跳所有错误或指定类型的错误vi /etc/my.cnf[mysqld]slave-skip-errors=1062,1053,1146 #跳过指定error no类型的错误slave-skip-errors=all #跳过所有错误 2018年10月3号更新：注意：如果你是直接复制MySQL的安装目录，而你的MySQL的版本又是5.6及以后的版本，那你有可能出现下面的问题： 1Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work. mysql 5.6的复制引入了uuid的概念，各个复制结构中的server_uuid得保证不一样，但是查看到直接复制data文件夹后server_uuid是相同的 1show variables like &apos;%server_uuid%&apos;; 解决方法：找到data文件夹下的auto.cnf文件，修改里面的uuid值，保证各个db的uuid不一样，重启db即可 附一个正确slave status的信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 127.0.0.1 Master_User: slave3307 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000007 Read_Master_Log_Pos: 602 Relay_Log_File: mysql-relay.000005 Relay_Log_Pos: 765 Relay_Master_Log_File: mysql-bin.000007 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 602 Relay_Log_Space: 1384 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: fe1b230d-6ee9-11e8-b0c6-9c5c8e103115 Master_Info_File: C:\\phpStudy\\MySQL3307\\data\\master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.00 sec) 2020年03月15号更新: binlog_do_db是指定binlog日志记录那些库的二进制日志。replicate_do_db则在slave库中指定同步那些库的binlog日志。在主从互备环境中，有没有必要每个服务器都同时配置binlog_do_db和replicate_do_db?理由是什么？ binlog-do-db：指定mysql的binlog日志记录哪个dbreplicate_do_db：参数是在slave上配置，指定slave要复制哪个库 在master上设置binlog_do_弊端：1、过滤操作带来的负载都在master上2、无法做基于时间点的复制（利用binlog） 如何删除日志?利用 RESET MASTER 或者 purge reset master ：删除所有的binglog日志文件，并将日志索引文件清空，重新开始所有新的日志文件。用于第一次进行搭建主从库时，进行主库binlog初始化工作 注意reset master 不同于 purge binary log的两处地方 reset master 将删除日志索引文件中记录的所有binlog文件，创建一个新的日志文件起始值从000001 开始，然而purge binary log 命令并不会修改记录binlog的顺序的数值 reset master 不能用于有任何slave 正在运行的主从关系的主库。因为在slave 运行时刻 reset master 命令不被支持，reset master 将master 的binlog从000001 开始记录,slave 记录的master log 则是reset master 时主库的最新的binlog,从库会报错无法找的指定的binlog文件 purge使用事例 123456# 清除mysql-bin.010日志purge master logs to 'mysql-bin.010’; # 清除2016-02-28 13:00:00前的日志purge master logs before '2016-02-28 13:00:00'; # 清除3天前的bin日志purge master logs before date_sub(now(), interval 3 day);","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://blog.ydstudio.net/tags/mysql/"}]},{"title":"Linux Crontab 安装使用详细说明","slug":"Linux-Crontab-安装使用详细说明","date":"2017-11-15T23:28:38.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/6933ee4e.html","link":"","permalink":"https://blog.ydstudio.net/post/6933ee4e.html","excerpt":"crontab命令常见于Unix和Linux的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。通常，crontab储存的指令被守护进程激活。crond 常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。","text":"crontab命令常见于Unix和Linux的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。通常，crontab储存的指令被守护进程激活。crond 常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。 安装12yum -y install vixie-cronyum -y install crontabs 说明：vixie-cron 软件包是 cron 的主程序；crontabs 软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。 配置cron是linux的内置服务，但它不自动起来，可以用以下的方法启动、关闭这个服务：12345service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看crontab服务状态 在CentOS系统中加入开机自动启动:1chkconfig --level 345 crond on crontab 命令 功能：设置计时器。 语法：crontab[-u &lt;用户名称&gt;][配置文件] 或 crontab [-u &lt;用户名称&gt;][-elr]解释：cron 是一个常驻服务，它提供计时器的功能，让用户在特定的时间得以执行预设的指令或程序。只要用户会编辑计时器的配置文件，就可以使 用计时器的功能。其配置文件格式如下：Minute Hour Day Month DayOFWeek Command 参数：-e 编辑该用户的计时器设置。-l 列出该用户的计时器设置。-r 删除该用户的计时器设置。-u&lt;用户名称&gt; 指定要设定计时器的用户名称。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849格式:* * * * * command分 时 日 月 周 命令第1列表示分钟1～59 每分钟用*或者 */1表示第2列表示小时1～23（0表示0点）第3列表示日期1～31第4列表示月份1～12第5列标识号星期0～6（0表示星期天）第6列要运行的命令``` 例子：```bash*/5 * * * * root ab -n 2000 http://60.217.229.252/250k.jpg上面例子表示每5分钟模拟用户访问http://60.217.229.252/250k.jpg 2000次 30 21 * * * /usr/local/etc/rc.d/lighttpd restart上面的例子表示每晚的21:30重启apache。45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart上面的例子表示每月1、10、22日的4 : 45重启apache。10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart上面的例子表示每周六、周日的1 : 10重启apache。0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart上面的例子表示每星期六的11 : 00 pm重启apache。* */1 * * * /usr/local/etc/rc.d/lighttpd restart每一小时重启apache* 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart晚上11点到早上7点之间，每隔一小时重启apache0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart每月的4号与每周一到周三的11点重启apache0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart一月一号的4点重启apache*/30 * * * * /usr/sbin/ntpdate 210.72.145.44每半小时同步一下时间","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"},{"name":"crontab","slug":"crontab","permalink":"https://blog.ydstudio.net/tags/crontab/"}]},{"title":"PHP目前比较常见的五大运行模式","slug":"PHP目前比较常见的五大运行模式","date":"2017-11-15T23:10:03.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/fa0692b8.html","link":"","permalink":"https://blog.ydstudio.net/post/fa0692b8.html","excerpt":"关于PHP目前比较常见的五大运行模式： CGI（通用网关接口 / Common Gateway Interface） FastCGI（常驻型CGI / Long-Live CGI） CLI（命令行运行 / Command Line Interface） Web模块模式（Apache等Web服务器运行的模式） ISAPI（Internet Server Application Program Interface）","text":"关于PHP目前比较常见的五大运行模式： CGI（通用网关接口 / Common Gateway Interface） FastCGI（常驻型CGI / Long-Live CGI） CLI（命令行运行 / Command Line Interface） Web模块模式（Apache等Web服务器运行的模式） ISAPI（Internet Server Application Program Interface） 备注：在PHP5.3以后，PHP不再有ISAPI模式，安装后也不再有php5isapi.dll这个文件。要在IIS6上使用高版本PHP，必须安装FastCGI 扩展，然后使IIS6支持FastCGI。 CGI模式 CGI即通用网关接口（Common Gateway Interface），它是一段程序，通俗的讲CGI就象是一座桥，把网页和Web服务器中的执行程序连接起来，它把HTML接收的指令传递给服务器的执行程序，再把服务器执行程序的结果返还给HTML页。CGI 的跨平台性能极佳，几乎可以在任何操作系统上实现。 CGI已经是比较老的模式了，这几年都很少用了。 每有一个用户请求，都会先要创建CGI的子进程，然后处理请求，处理完后结束这个子进程，这就是Fork-And-Execute模式。 当用户请求数量非常多时，会大量挤占系统的资源如内存，CPU时间等，造成效能低下。所以用CGI方式的服务器有多少连接请求就会有多少CGI子进程，子进程反复加载是CGI性能低下的主要原因。 如果不想把 PHP 嵌入到服务器端软件（如 Apache）作为一个模块安装的话，可以选择以 CGI 的模式安装。或者把 PHP 用于不同的 CGI 封装以便为代码创建安全的 chroot 和 setuid 环境。这样每个客户机请求一个PHP文件，Web服务器就调用php.exe（win下是php.exe,linux是php）去解释这个文件，然后再把解释的结果以网页的形式返回给客户机。 这种安装方式通常会把 PHP 的可执行文件安装到 web 服务器的 cgi-bin 目录。CERT 建议书 CA-96.11 建议不要把任何的解释器放到 cgi-bin 目录。 这种方式的好处是把Web Server和具体的程序处理独立开来，结构清晰，可控性强，同时缺点就是如果在高访问需求的情况下，CGI的进程Fork就会成为很大的服务器负担，想 象一下数百个并发请求导致服务器Fork出数百个进程就明白了。这也是为什么CGI一直背负性能低下，高资源消耗的恶名的原因。 FastCGI模式 FastCGI是CGI的升级版本，FastCGI像是一个常驻 (long-live)型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去 Fork 一次 （这是 CGI 最为人诟病的 fork-and-execute 模式）。 FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等，同时，FastCGI也被许多脚本语言所支持，其中就有PHP。 FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 原理 Web Server启动时载入FastCGI进程管理器（IIS ISAPI或Apache Module)； FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (可见多个php-cgi.exe或php-cig)并等待来自Web Server的连接； 当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi； FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回WebServer。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在WebServer中）的下一个连接。在正常的CGI模式中，php-cgi.exe在此便退出了。在CGI模式中，你可以想象CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部dll扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接（Persistent database connection）可以工作。 备注：PHP的FastCGI进程管理器是PHP-FPM（PHP-FastCGI Process Manager） 优点 从稳定性上看，FastCGI是以独立的进程池来运行CGI，单独一个进程死掉，系统可以很轻易的丢弃，然后重新分配新的进程来运行逻辑； 从安全性上看，FastCGI支持分布式运算。FastCGI和宿主的Server完全独立，FastCGI怎么down也不会把Server搞垮； 从性能上看，FastCGI把动态逻辑的处理从Server中分离出来，大负荷的IO处理还是留给宿主Server，这样宿主Server可以一心一意作IO，对于一个普通的动态网页来说, 逻辑处理可能只有一小部分，大量的是图片等静态。 缺点 说完了好处，也来说说缺点。从我的实际使用来看，用FastCGI模式更适合生产环境的服务器。但对于开发用机器来说就不太合适。因为当使用ZendStudio调试程序时，由于FastCGI会认为PHP进程超时，从而在页面返回500错误。这一点让人非常恼火，所以我在开发机器上还是换回了ISAPI模式。对某些服务器的新版本支持不好，对分布式负载均衡没要求的模块化安装是否是更好的选择。目前的FastCGI和Server沟通还不够智能，一个FastCGI进程如果执行时间过长会被当成是死进程杀掉重起，这样在处理长时间任务的时候很麻烦，这样做也使得FastCGI无法允许联机调试。因为是多进程，所以比CGI多线程消耗更多的服务器内存，PHP-CGI解释器每进程消耗7至25兆内存，将这个数字乘以50或100就是很大的内存数。 CLI模式 PHP-CLI是PHP Command Line Interface的简称，如同它名字的意思，就是PHP在命令行运行的接口，区别于在Web服务器上运行的PHP环境（PHP-CGI，ISAPI等）。 也就是说，PHP不单可以写前台网页，它还可以用来写后台的程序。PHP的CLIShell脚本适用于所有的PHP优势，使创建要么支持脚本或系统甚至与GUI应用程序的服务端，在Windows和Linux下都是支持PHP-CLI模式的。 优点 使用多进程，子进程结束以后，内核会负责回收资源； 使用多进程，子进程异常退出不会导致整个进程Thread退出，父进程还有机会重建流程； 一个常驻主进程，只负责任务分发，逻辑更清楚。我们在Linux下经常使用”php–m”查找PHP安装了那些扩展就是PHP命令行运行模式；有兴趣的同学可以输入”php –h”去深入研究该运行模式。 模块模式 模块模式是以mod_php5模块的形式集成，此时mod_php5模块的作用是接收Apache传递过来的PHP文件请求，并处理这些请求，然后将处理后的结果返回给Apache。如果我们在Apache启动前在其配置文件中配置好了PHP模块（mod_php5）， PHP模块通过注册apache2的ap_hook_post_config挂钩，在Apache启动的时候启动此模块以接受PHP文件的请求。 除了这种启动时的加载方式，Apache的模块可以在运行的时候动态装载，这意味着对服务器可以进行功能扩展而不需要重新对源代码进行编译，甚至根本不需要停止服务器。我们所需要做的仅仅是给服务器发送信号HUP或者AP_SIG_GRACEFUL通知服务器重新载入模块。但是在动态加载之前，我们需要将模块编译成为动态链接库。此时的动态加载就是加载动态链接库。 Apache中对动态链接库的处理是通过模块mod_so来完成的，因此mod_so模块不能被动态加载，它只能被静态编译进Apache的核心。这意味着它是随着Apache一起启动的。 Apache是如何加载模块的呢？我们以前面提到的mod_php5模块为例。首先我们需要在Apache的配置文件httpd.conf中添加一行：LoadModule php5_module modules/mod_php5.so 这里我们使用了LoadModule命令，该命令的第一个参数是模块的名称，名称可以在模块实现的源码中找到。第二个选项是该模块所处的路径。如果需要在服务器运行时加载模块，可以通过发送信号HUP或者AP_SIG_GRACEFUL给服务器，一旦接受到该信号，Apache将重新装载模块，而不需要重新启动服务器。 该运行模式是我们以前在windows环境下使用apache服务器经常使用的，而在模块化（DLL）中，PHP是与Web服务器一起启动并运行的。（它是apache在CGI的基础上进行的一种扩展，加快PHP的运行效率）。 ISAPI模式 ISAPI（Internet Server Application Program Interface）是微软提供的一套面向Internet服务的API接口，一个ISAPI的DLL，可以在被用户请求激活后长驻内存，等待用户的另一个请求，还可以在一个DLL里设置多个用户请求处理函数，此外，ISAPI的DLL应用程序和WWW服务器处于同一个进程中，效率要显著高于CGI。（由于微软的排他性，只能运行于windows环境）PHP作为Apache模块，Apache服务器在系统启动后，预先生成多个进程副本驻留在内存中，一旦有请求出现，就立即使用这些空余的子进程进行处理，这样就不存在生成子进程造成的延迟了。这些服务器副本在处理完一次HTTP请求之后并不立即退出，而是停留在计算机中等待下次请求。对于客户浏览器的请求反应更快，性能较高。","categories":[],"tags":[{"name":"php","slug":"php","permalink":"https://blog.ydstudio.net/tags/php/"}]},{"title":"解决git默认不区分文件名大小写的问题","slug":"解决git默认不区分文件名大小写的问题","date":"2017-11-13T22:46:50.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/8598d574.html","link":"","permalink":"https://blog.ydstudio.net/post/8598d574.html","excerpt":"当你创建一个文件后,叫 readme.md 写入内容后 提交到线上代码仓库.然后你在本地修改文件名为 Readme.md 接着你去提交,发现代码没有变化.","text":"当你创建一个文件后,叫 readme.md 写入内容后 提交到线上代码仓库.然后你在本地修改文件名为 Readme.md 接着你去提交,发现代码没有变化. 1git status 你会无任何提示信息,其实 git 默认对于文件名大小写是不敏感的,所以上面你修改了首字母大写,但是git 并没有发现代码任何改动.那么如何才能让 git 识别文件名大小写变化. 一 配置git 使其对文件名大小写敏感 1git config core.ignorecase false 二 从git 本地仓库删除此文件,然后添加再提交(1) 删除 1git rm readme.md (2) 重新添加 1git add Readme.md (3)提交 1git commit -m 'Readme.md' 这样git不区分文件名大小写的问题就解决了！","categories":[],"tags":[]},{"title":"隐藏Nginx或Apache以及PHP的版本号","slug":"隐藏Nginx或Apache以及PHP的版本号","date":"2017-11-13T22:40:48.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/adb014f8.html","link":"","permalink":"https://blog.ydstudio.net/post/adb014f8.html","excerpt":"当你配置完一台服务器后，并不是就可以高枕无忧了，由于软件难免会有漏洞，防止因为漏洞导致一些损失，所以说经常关注安全公告并及时升级服务器也是必要的。一般来说，黑客攻击服务器的首要步骤就是收集信息，比如说你的软件版本，这些将成为下一步有针对性攻击的依据。所以说一定程度的隐藏这些信息就显得非常有必要了，本文将简单介绍如何在网络上隐藏Nginx版本号以及PHP的版本号。","text":"当你配置完一台服务器后，并不是就可以高枕无忧了，由于软件难免会有漏洞，防止因为漏洞导致一些损失，所以说经常关注安全公告并及时升级服务器也是必要的。一般来说，黑客攻击服务器的首要步骤就是收集信息，比如说你的软件版本，这些将成为下一步有针对性攻击的依据。所以说一定程度的隐藏这些信息就显得非常有必要了，本文将简单介绍如何在网络上隐藏Nginx版本号以及PHP的版本号。 我们用命令测试一下，显示服务器上版本信息，命令如下： 1curl -I http://127.0.0.1/phpinfo.php 结果显示了如下内容： 1234567HTTP/1.1 200 OKServer: nginx/1.5.0Date: Thu, 18 Jun 2015 02:39:32 GMTContent-Type: text/htmlConnection: keep-aliveVary: Accept-EncodingX-Powered-By: PHP/5.3.1 可以看到我们的服务器nginx和php版本都暴露了。那该如何隐藏版本号呢？ 1.先说隐藏Nginx版本号，Nginx的版本号主要在两个地方会有，一个是HTTP header，有个Server:nginx/1.x.x类似会暴露Web服务器所用软件名称以及版本号，这个也是大多数Web服务器最容易暴露版本号的地方，第二个地方是Nginx出错页面，比如404页面没有找到等，这是如果用户没有指定页面的话，那么Nginx自己的页面会有版本戳记。 在nginx配置文件中http节的配置,加入以下代码： 1234http &#123; # ...省略一些配置 server_tokens off; &#125; 最后别忘了使用命令nginx -s reload刷新当前配置。完成后你可以查看所有页面的响应头或者错误页，看看是不是只看到nginx字样而看不到版本号？什么？你想连nginx也改掉？呵呵，这个恐怕就麻烦了，需要改动Nginx源代码然后重新编译，感兴趣的童鞋可以研究下！在apache配置文件httpd.conf中,加入以下代码： 12ServerTokens ProdServerSignature Off 记得保存后重启一下apache! 2.隐藏PHP的版本号，PHP容易暴露的版本号在什么地方呢？其实也是在HTTP头，以类似X-Powered-By: PHP/5.2.11这种形式存在。 其实这个是在PHP的配置文件php.ini里改动，打开php.ini，找到下面叙述： 123456; Decides whether PHP may expose the fact that it is installed on the server; (e.g. by adding its signature to the Web server header). It is no security; threat in any way, but it makes it possible to determine whether you use PHP; on your server or not.; http://php.net/expose-phpexpose_php = On expose_php = On改为expose_php = Off就搞定了，当然，对于apache服务器还有另外一个方法可以直接尝试在.htaccess文件中Header unset X-Powered-By，删除X-Powered-By节，不过我还是建议改动php.ini的expose_php。","categories":[],"tags":[]},{"title":"如何正确的修改Python的pip自带的源","slug":"如何正确的修改Python的pip自带的源","date":"2017-11-13T22:06:56.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/cf179e51.html","link":"","permalink":"https://blog.ydstudio.net/post/cf179e51.html","excerpt":"Python中的pip安装依赖包时默认访问https://pypi.python.org/simple/，但是经常出现不稳定以及访问速度非常慢的情况，国内厂商提供的pipy镜像目前可用的有： 1.http://pypi.douban.com/ 豆瓣2.http://pypi.mirrors.ustc.edu.cn/simple/ 中国科学技术大学","text":"Python中的pip安装依赖包时默认访问https://pypi.python.org/simple/，但是经常出现不稳定以及访问速度非常慢的情况，国内厂商提供的pipy镜像目前可用的有： 1.http://pypi.douban.com/ 豆瓣2.http://pypi.mirrors.ustc.edu.cn/simple/ 中国科学技术大学 有两种方式使用我们自己指定的镜像源，第一种是手动指定： 1pip -i http://pypi.douban.com/simple install Flask -- trusted-host pypi.douban.com 不过这种方式在每次安装时都要手动指定，所以第二种方法更加方便，在当前用户目录下创建.pip文件夹中，代码如下： 1234567891011121314import osini=\"\"\"[global]index-url = https://pypi.doubanio.com/simple/[install]trusted-host=pypi.doubanio.com\"\"\"pippath=os.environ[\"USERPROFILE\"]+\"\\\\pip\\\\\"if not os.path.exists(pippath): os.mkdir(pippath)with open(pippath+\"pip.ini\",\"w+\") as f: f.write(ini) 个人觉得第二种方法最佳，一次执行终身无忧！","categories":[],"tags":[]},{"title":"Linux文件时间详解 ctime、mtime和atime","slug":"Linux文件时间详解-ctime、mtime和atime","date":"2017-11-10T23:01:09.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/6652f017.html","link":"","permalink":"https://blog.ydstudio.net/post/6652f017.html","excerpt":"Linux系统文件有三个主要的时间属性，分别是 ctime(change time), atime(access time), mtime(modify time)。这三个时间很容易混淆，准备深入了解Linux的童鞋请区分这三者的区别。","text":"Linux系统文件有三个主要的时间属性，分别是 ctime(change time), atime(access time), mtime(modify time)。这三个时间很容易混淆，准备深入了解Linux的童鞋请区分这三者的区别。 atime：Access time，是在读取文件或者执行文件时更改，即文件最后一次被读取的时间。说明： st_atime 12Time when file data was last accessed. Changed by the following functions: creat(), mknod(), pipe(), utime(2), and read(2). mtime：Modified time，是在写入文件时随文件内容的更改而更改，是指文件内容最后一次被修改的时间。说明： st_mtime 12Time when data was last modified. Changed by the following functions: creat(), mknod(), pipe(), utime(), and write(2). ctime：Change time，是在写入文件、更改所有者、权限或链接设置时随 Inode 的内容更改而更改，即文件状态最后一次被改变的时间。说明： st_ctime 12Time when file status was last changed. Changed by the following functions: chmod(), chown(), creat(), link(2), mknod(), pipe(), unlink(2), utime(), and write(). 很多人把它理解成create time，包括很多误导人的书籍也是这么写。实际上ctime是指change time。注意：1、修改是文本本身的内容发生了变化（mtime）改变是文件的索引节点发生了改变（ctime）2、如果修改了文件内容，则同时更新ctime和mtime3、如果只改变了文件索引节点，比如修改权限，则只是改变了ctime4、如果使用ext3文件系统的时候，在mount的时候使用了noatime参数则不会更新atime的信息，即访问文件之后atime不会被修改，而这个不代表真实情况小知识：这三个 time stamp 都放在 inode 中。若mtime,atime修改, inode 就一定会改,相应的inode改了,那ctime 也就跟着要改了，之所以在mount option中使用 noatime, 就是不想 file system 做太多的修改, 从而改善读取性能.查看文件的 atime、ctime 和 mtime。 12345678910# ls -lc filename 列出文件的 ctime# ls -lu filename 列出文件的 atime# ls -l filename 列出文件的 mtime#例子1： # echo \"Hello World\" &gt;&gt; myfile atime不变,同时改变了ctime和mtime2： # cat myfile ctime和mtime不变，只改变atime# ls myfilectime和mtime以及atime都不改变3： # chmod u+x myfile mtime和atime不变，只改变ctime4： # mv myfile ../ mtime和atime不变，只改变ctime 其他扩展：relatime属性从kernel2.6.29开始，默认集成了一个 relatime的属性。使用这个特性来挂装文件系统后，只有当mtime比atime更新的时候，才会更新atime。使用场景：在文件读操作很频繁的系统中，atime更新所带来的开销很大，所以在挂装文件系统的时候使用noatime属性来停止更新atime。但是有些程序需要根据atime进行一些判断和操作，这个时候relatime特性就派上用场了。其实在事实上，这个时候atime和mtime已经是同一个time，所以可以理解这个选项就是为了实现对atime的兼容才推出的，并不是一个新的时间属性。使用方法： 1# mount -o relatime /dir##挂载目录的时候加relatime参数","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ydstudio.net/tags/linux/"}]},{"title":"apache出现no input file specified.的完美解决方案","slug":"apache出现no-input-file-specified-的完美解决方案","date":"2017-11-10T22:53:58.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/ff626742.html","link":"","permalink":"https://blog.ydstudio.net/post/ff626742.html","excerpt":"启用rewrite的伪静态功能的时候，首页可以访问，而访问内页的时候，就提示：“No input file specified.”原因在于使用的PHP是fast_cgi模式，而在某些情况下，不能正确识别path_info所造成的错误，Wordpress的伪静态也有一样的问题。","text":"启用rewrite的伪静态功能的时候，首页可以访问，而访问内页的时候，就提示：“No input file specified.”原因在于使用的PHP是fast_cgi模式，而在某些情况下，不能正确识别path_info所造成的错误，Wordpress的伪静态也有一样的问题。 Wordpress程序默认的.htaccess里面的规则： 12345RewriteEngine OnRewriteBase /RewriteCond %&#123;REQUEST_FILENAME&#125; !-fRewriteCond %&#123;REQUEST_FILENAME&#125; !-dRewriteRule ^(.*)$ /index.php/$1 [L] 其实“No input file specified.”，是没有得到有效的文件路径造成的。修改伪静态规则，如下： 12345RewriteEngine OnRewriteBase /RewriteCond %&#123;REQUEST_FILENAME&#125; !-fRewriteCond %&#123;REQUEST_FILENAME&#125; !-dRewriteRule ^(.*)$ /index.php?/$1 [L] 有没有发现不同？其实就是在正则结果“/$1”前面多加了一个“?”号，问题也就随之解决了。","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.ydstudio.net/tags/nginx/"}]},{"title":"git pull操作失败的问题","slug":"git-pull操作失败的问题","date":"2017-11-10T22:53:13.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/a774f745.html","link":"","permalink":"https://blog.ydstudio.net/post/a774f745.html","excerpt":"使用git版本控制，提交代码到测试环境，发现代码没有更新，直接在服务器上用命令行操作的时候出现下面的错误：","text":"使用git版本控制，提交代码到测试环境，发现代码没有更新，直接在服务器上用命令行操作的时候出现下面的错误： 123456789101112www@iZ23oqentptZ:~/develop.dameiweb.com/webroot$ git pullerror: Cannot update the ref 'refs/remotes/origin/develop': unable to append to .git/logs/refs/remotes/origin/develop: Permission deniedFrom git.dameiweb.com:dm/www.dameiweb.com ! 3fa3fb3..297aa33 develop -&gt; origin/develop (unable to update local ref)error: Cannot update the ref 'refs/remotes/origin/master': unable to append to .git/logs/refs/remotes/origin/master: Permission denied ! 0eadc3f..d8ad757 master -&gt; origin/master (unable to update local ref) 通过查看文件的权限，发现.git文件夹下文件的权限不对，有的文件不属于git账号（git的用户是www），出现这个情况可能是用不同的账号去执行git命令，譬如我们这就是使用root账号操作过。 解决办法就是用root账户修改.git文件的权限,.git文件的所有者和所属组都是www,于是执行命令： 12#文件的所有者和所属组修改成wwwchown -R www:www .git 执行完命令之后，查看文件的权限修改成功后，再切换成www用户，执行git pull，更新成功！ 大家切记，linux下权限很重要，不用乱用不用的用户，这样会导致文件的所有者和所属组发生改变！","categories":[],"tags":[]},{"title":"git的.gitignore规则不生效的解决办法","slug":"git的-gitignore规则不生效的解决办法","date":"2017-11-10T22:51:42.000Z","updated":"2019-12-09T15:03:26.000Z","comments":true,"path":"post/8b084705.html","link":"","permalink":"https://blog.ydstudio.net/post/8b084705.html","excerpt":"在git中如果想忽略掉某个文件，不让这个文件提交到版本库中，可以使用修改根目录中 .gitignore 文件的方法（如无，则需自己手工建立此文件）。这个文件每一行保存了一个匹配的规则例如：","text":"在git中如果想忽略掉某个文件，不让这个文件提交到版本库中，可以使用修改根目录中 .gitignore 文件的方法（如无，则需自己手工建立此文件）。这个文件每一行保存了一个匹配的规则例如： 123456# 此为注释 – 将被 Git 忽略*.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 规则很简单，不做过多解释，但是有时候在项目开发过程中，突然心血来潮想把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效，原因是.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交： 123git rm -r --cached .git add .git commit -m 'update .gitignore' 这样git的忽略规则不生效的问题就解决了！","categories":[],"tags":[]}]}